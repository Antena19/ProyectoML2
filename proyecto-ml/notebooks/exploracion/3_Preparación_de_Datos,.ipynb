{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d6b798",
   "metadata": {},
   "source": [
    "# Preparación de Datos\n",
    "**Proyecto Machine Learning:** Limpieza y Preparación de Datos de Nacimientos y Defunciones\n",
    "\n",
    "Este notebook implementa la limpieza y preparación de los datasets identificados en el análisis exploratorio, enfocándose en:\n",
    "1. Limpieza crítica del dataset `defunciones_filtradas`\n",
    "2. Estandarización de nombres de columnas\n",
    "3. Validación de rangos de edad\n",
    "4. Integración de datasets\n",
    "5. Validación de consistencia\n",
    "6. Preparación para modelado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef41646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# 1. Importación de librerías y configuración\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración general\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Opciones de pandas para mejor visualización\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\" Librerías importadas correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0a0ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos cargados correctamente\n",
      "Dataset defunciones_filtradas: 1,250,062 registros\n"
     ]
    }
   ],
   "source": [
    "# 2. Carga de datos\n",
    "\n",
    "# Definir rutas de los archivos\n",
    "ruta_por_sexo = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\dataset_nacimiento-defuncion_por_sexo.csv\"\n",
    "ruta_defunciones_filtradas = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\datos_filtrados_2014_2023.csv\"\n",
    "ruta_por_edad_madre = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\nacimiento_rango_edad_madre.csv\"\n",
    "ruta_por_edad_fallecido = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\rango_edad_fallecido.csv\"\n",
    "ruta_setdedatos = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\setdedatos.csv\"\n",
    "\n",
    "# Función para cargar CSV con diferentes separadores\n",
    "def cargar_csv(ruta):\n",
    "    \"\"\"\n",
    "    Carga un archivo CSV probando primero con ',' y luego con ';' como separador\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(ruta)\n",
    "    except:\n",
    "        return pd.read_csv(ruta, sep=\";\")\n",
    "\n",
    "# Cargar todos los datasets\n",
    "por_sexo = cargar_csv(ruta_por_sexo)\n",
    "defunciones_filtradas = cargar_csv(ruta_defunciones_filtradas)\n",
    "por_edad_madre = cargar_csv(ruta_por_edad_madre)\n",
    "por_edad_fallecido = cargar_csv(ruta_por_edad_fallecido)\n",
    "setdedatos = cargar_csv(ruta_setdedatos)\n",
    "\n",
    "print(\"Archivos cargados correctamente\")\n",
    "print(f\"Dataset defunciones_filtradas: {defunciones_filtradas.shape[0]:,} registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13711102",
   "metadata": {},
   "source": [
    "## 3. Limpieza Crítica del Dataset `defunciones_filtradas`\n",
    "\n",
    "Este es el dataset más problemático identificado en el EDA. Requiere limpieza antes de cualquier análisis posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6188bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS INICIAL DE DEFUNCIONES_FILTRADAS ===\n",
      " Dimensiones: (1250062, 10)\n",
      " Columnas: ['AÑO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_TIPO', 'EDAD_CANT', 'COD_COMUNA', 'COMUNA', 'NOMBRE_REGION', 'CAPITULO_DIAG1', 'GLOSA_CAPITULO_DIAG1']\n",
      "\n",
      "=== VALORES NULOS POR COLUMNA ===\n",
      "FECHA_DEF        19\n",
      "COD_COMUNA        4\n",
      "COMUNA            4\n",
      "NOMBRE_REGION     4\n",
      "dtype: int64\n",
      "\n",
      "=== DUPLICADOS ===\n",
      "Registros duplicados: 3,844\n",
      "\n",
      "=== PRIMERAS FILAS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_TIPO</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COD_COMUNA</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>NOMBRE_REGION</th>\n",
       "      <th>CAPITULO_DIAG1</th>\n",
       "      <th>GLOSA_CAPITULO_DIAG1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13127.0</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8203.0</td>\n",
       "      <td>Cañete</td>\n",
       "      <td>Del Bíobío</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13303.0</td>\n",
       "      <td>Tiltil</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>13119.0</td>\n",
       "      <td>Maipú</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13115.0</td>\n",
       "      <td>Lo Barnechea</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AÑO   FECHA_DEF SEXO_NOMBRE  EDAD_TIPO  EDAD_CANT  COD_COMUNA  \\\n",
       "0  2015  2015-01-11       Mujer        2.0          4     13127.0   \n",
       "1  2016  2016-01-31      Hombre        1.0         20      8203.0   \n",
       "2  2019  2019-08-08      Hombre        1.0         18     13303.0   \n",
       "3  2015  2015-02-17      Hombre        1.0         19     13119.0   \n",
       "4  2015  2015-01-03      Hombre        1.0         18     13115.0   \n",
       "\n",
       "         COMUNA              NOMBRE_REGION CAPITULO_DIAG1  \\\n",
       "0      Recoleta  Metropolitana de Santiago        S00-T98   \n",
       "1        Cañete                 Del Bíobío        S00-T98   \n",
       "2        Tiltil  Metropolitana de Santiago        S00-T98   \n",
       "3         Maipú  Metropolitana de Santiago        S00-T98   \n",
       "4  Lo Barnechea  Metropolitana de Santiago        S00-T98   \n",
       "\n",
       "                                GLOSA_CAPITULO_DIAG1  \n",
       "0  Traumatismos, envenenamientos y algunas otras ...  \n",
       "1  Traumatismos, envenenamientos y algunas otras ...  \n",
       "2  Traumatismos, envenenamientos y algunas otras ...  \n",
       "3  Traumatismos, envenenamientos y algunas otras ...  \n",
       "4  Traumatismos, envenenamientos y algunas otras ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.1 Análisis inicial del dataset defunciones_filtradas\n",
    "\n",
    "print(\"=== ANÁLISIS INICIAL DE DEFUNCIONES_FILTRADAS ===\")\n",
    "print(f\" Dimensiones: {defunciones_filtradas.shape}\")\n",
    "print(f\" Columnas: {list(defunciones_filtradas.columns)}\")\n",
    "print(\"\\n=== VALORES NULOS POR COLUMNA ===\")\n",
    "nulos_por_columna = defunciones_filtradas.isnull().sum()\n",
    "print(nulos_por_columna[nulos_por_columna > 0])\n",
    "\n",
    "print(\"\\n=== DUPLICADOS ===\")\n",
    "duplicados = defunciones_filtradas.duplicated().sum()\n",
    "print(f\"Registros duplicados: {duplicados:,}\")\n",
    "\n",
    "print(\"\\n=== PRIMERAS FILAS ===\")\n",
    "display(defunciones_filtradas.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4da0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ELIMINACIÓN DE DUPLICADOS ===\n",
      "Registros antes de eliminar duplicados: 1,250,062\n",
      "Registros después de eliminar duplicados: 1,246,218\n",
      "Registros eliminados: 3,844\n",
      "Duplicados restantes: 0\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Eliminación de registros duplicados\n",
    "\n",
    "print(\"=== ELIMINACIÓN DE DUPLICADOS ===\")\n",
    "print(f\"Registros antes de eliminar duplicados: {defunciones_filtradas.shape[0]:,}\")\n",
    "\n",
    "# Crear una copia del dataset para trabajar\n",
    "defunciones_limpio = defunciones_filtradas.copy()\n",
    "\n",
    "# Eliminar duplicados manteniendo la primera ocurrencia\n",
    "defunciones_limpio = defunciones_limpio.drop_duplicates(keep='first')\n",
    "\n",
    "print(f\"Registros después de eliminar duplicados: {defunciones_limpio.shape[0]:,}\")\n",
    "print(f\"Registros eliminados: {defunciones_filtradas.shape[0] - defunciones_limpio.shape[0]:,}\")\n",
    "\n",
    "# Verificar que no quedan duplicados\n",
    "duplicados_restantes = defunciones_limpio.duplicated().sum()\n",
    "print(f\"Duplicados restantes: {duplicados_restantes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d8996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MANEJO DE VALORES NULOS EN INFORMACIÓN GEOGRÁFICA ===\n",
      "Valores nulos en columnas geográficas:\n",
      "COD_COMUNA       4\n",
      "COMUNA           4\n",
      "NOMBRE_REGION    4\n",
      "dtype: int64\n",
      "\n",
      "Registros con valores nulos en información geográfica: 4\n",
      "\n",
      "Ejemplos de registros con valores nulos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COD_COMUNA</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>NOMBRE_REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159454</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166415</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193568</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248759</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AÑO   FECHA_DEF SEXO_NOMBRE  EDAD_CANT  COD_COMUNA COMUNA  \\\n",
       "1159454  2024  2024-02-28      Hombre         83         NaN    NaN   \n",
       "1166415  2024  2024-04-26       Mujer         52         NaN    NaN   \n",
       "1193568  2024  2024-04-11      Hombre          1         NaN    NaN   \n",
       "1248759  2024  2024-06-26       Mujer          2         NaN    NaN   \n",
       "\n",
       "        NOMBRE_REGION  \n",
       "1159454           NaN  \n",
       "1166415           NaN  \n",
       "1193568           NaN  \n",
       "1248759           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registros después de eliminar nulos geográficos: 1,246,214\n",
      "Registros eliminados por nulos geográficos: 4\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Manejo de valores nulos en información geográfica\n",
    "\n",
    "print(\"=== MANEJO DE VALORES NULOS EN INFORMACIÓN GEOGRÁFICA ===\")\n",
    "\n",
    "# Verificar valores nulos en columnas geográficas críticas\n",
    "columnas_geograficas = ['COD_COMUNA', 'COMUNA', 'NOMBRE_REGION']\n",
    "nulos_geograficos = defunciones_limpio[columnas_geograficas].isnull().sum()\n",
    "print(\"Valores nulos en columnas geográficas:\")\n",
    "print(nulos_geograficos)\n",
    "\n",
    "# Mostrar registros con valores nulos en información geográfica\n",
    "registros_nulos_geo = defunciones_limpio[defunciones_limpio[columnas_geograficas].isnull().any(axis=1)]\n",
    "print(f\"\\nRegistros con valores nulos en información geográfica: {len(registros_nulos_geo)}\")\n",
    "\n",
    "if len(registros_nulos_geo) > 0:\n",
    "    print(\"\\nEjemplos de registros con valores nulos:\")\n",
    "    display(registros_nulos_geo[['AÑO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_CANT'] + columnas_geograficas].head())\n",
    "\n",
    "# Eliminar registros con valores nulos en información geográfica crítica\n",
    "# La información geográfica es esencial para análisis regionales\n",
    "defunciones_limpio = defunciones_limpio.dropna(subset=columnas_geograficas)\n",
    "\n",
    "print(f\"\\nRegistros después de eliminar nulos geográficos: {defunciones_limpio.shape[0]:,}\")\n",
    "print(f\"Registros eliminados por nulos geográficos: {len(registros_nulos_geo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68ab4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MANEJO DE VALORES NULOS EN FECHA_DEF ===\n",
      "Valores nulos en FECHA_DEF: 19\n",
      "\n",
      "Registros con valores nulos en FECHA_DEF: 19\n",
      "\n",
      "Ejemplos de registros con fecha nula:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COMUNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>33</td>\n",
       "      <td>Temuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>44</td>\n",
       "      <td>Temuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>35</td>\n",
       "      <td>Ercilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39420</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>62</td>\n",
       "      <td>Gorbea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55107</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>81</td>\n",
       "      <td>Temuco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AÑO FECHA_DEF SEXO_NOMBRE  EDAD_CANT   COMUNA\n",
       "5893   2016       NaN      Hombre         33   Temuco\n",
       "7953   2015       NaN      Hombre         44   Temuco\n",
       "8144   2014       NaN      Hombre         35  Ercilla\n",
       "39420  2016       NaN      Hombre         62   Gorbea\n",
       "55107  2014       NaN      Hombre         81   Temuco"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IMPUTACIÓN DE FECHAS NULAS ===\n",
      "Año 2016: 3 registros imputados con fecha 2016-07-03\n",
      "Año 2015: 6 registros imputados con fecha 2015-07-05\n",
      "Año 2014: 3 registros imputados con fecha 2014-07-04\n",
      "Año 2018: 1 registros imputados con fecha 2018-07-05\n",
      "Año 2019: 1 registros imputados con fecha 2019-07-04\n",
      "Año 2020: 3 registros imputados con fecha 2020-07-05\n",
      "Año 2021: 2 registros imputados con fecha 2021-06-27\n",
      "\n",
      "Valores nulos restantes en FECHA_DEF: 0\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Manejo de valores nulos en FECHA_DEF\n",
    "\n",
    "print(\"=== MANEJO DE VALORES NULOS EN FECHA_DEF ===\")\n",
    "\n",
    "# Verificar valores nulos en FECHA_DEF\n",
    "nulos_fecha = defunciones_limpio['FECHA_DEF'].isnull().sum()\n",
    "print(f\"Valores nulos en FECHA_DEF: {nulos_fecha}\")\n",
    "\n",
    "if nulos_fecha > 0:\n",
    "    # Mostrar registros con valores nulos en FECHA_DEF\n",
    "    registros_nulos_fecha = defunciones_limpio[defunciones_limpio['FECHA_DEF'].isnull()]\n",
    "    print(f\"\\nRegistros con valores nulos en FECHA_DEF: {len(registros_nulos_fecha)}\")\n",
    "    print(\"\\nEjemplos de registros con fecha nula:\")\n",
    "    display(registros_nulos_fecha[['AÑO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_CANT', 'COMUNA']].head())\n",
    "    \n",
    "    # Estrategia: Imputar con fecha media del año correspondiente\n",
    "    # Esto mantiene la información temporal aproximada\n",
    "    print(\"\\n=== IMPUTACIÓN DE FECHAS NULAS ===\")\n",
    "    \n",
    "    for año in registros_nulos_fecha['AÑO'].unique():\n",
    "        # Calcular fecha media del año para registros con fecha válida\n",
    "        fechas_validas_año = defunciones_limpio[\n",
    "            (defunciones_limpio['AÑO'] == año) & \n",
    "            (defunciones_limpio['FECHA_DEF'].notnull())\n",
    "        ]['FECHA_DEF']\n",
    "        \n",
    "        if len(fechas_validas_año) > 0:\n",
    "            # Convertir a datetime para calcular media\n",
    "            fechas_datetime = pd.to_datetime(fechas_validas_año, errors='coerce')\n",
    "            fecha_media = fechas_datetime.mean()\n",
    "            \n",
    "            # Imputar fecha media en registros nulos del año\n",
    "            mask_nulos_año = (defunciones_limpio['AÑO'] == año) & (defunciones_limpio['FECHA_DEF'].isnull())\n",
    "            defunciones_limpio.loc[mask_nulos_año, 'FECHA_DEF'] = fecha_media.strftime('%Y-%m-%d')\n",
    "            \n",
    "            print(f\"Año {año}: {mask_nulos_año.sum()} registros imputados con fecha {fecha_media.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Verificar que no quedan valores nulos\n",
    "    nulos_restantes = defunciones_limpio['FECHA_DEF'].isnull().sum()\n",
    "    print(f\"\\nValores nulos restantes en FECHA_DEF: {nulos_restantes}\")\n",
    "\n",
    "else:\n",
    "    print(\"No hay valores nulos en FECHA_DEF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2644eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN DEL FORMATO DE FECHAS ===\n",
      "Convirtiendo FECHA_DEF a formato datetime...\n",
      "Fechas que no se pudieron convertir: 0\n",
      "\n",
      "=== CREACIÓN DE VARIABLES TEMPORALES ===\n",
      "Variables temporales creadas:\n",
      "- AÑO_FECHA: Año de la fecha de defunción\n",
      "- MES: Mes (1-12)\n",
      "- DIA_SEMANA: Día de la semana\n",
      "- TRIMESTRE: Trimestre (1-4)\n",
      "- DIA_AÑO: Día del año (1-365/366)\n",
      "\n",
      "Inconsistencias entre AÑO y AÑO_FECHA: 0\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Estandarización del formato de fechas\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN DEL FORMATO DE FECHAS ===\")\n",
    "\n",
    "# Convertir FECHA_DEF a datetime para análisis temporal\n",
    "print(\"Convirtiendo FECHA_DEF a formato datetime...\")\n",
    "\n",
    "# Convertir a datetime, manejando posibles errores de formato\n",
    "defunciones_limpio['FECHA_DEF'] = pd.to_datetime(defunciones_limpio['FECHA_DEF'], errors='coerce')\n",
    "\n",
    "# Verificar conversión\n",
    "fechas_invalidas = defunciones_limpio['FECHA_DEF'].isnull().sum()\n",
    "print(f\"Fechas que no se pudieron convertir: {fechas_invalidas}\")\n",
    "\n",
    "if fechas_invalidas > 0:\n",
    "    print(\"Registros con fechas inválidas:\")\n",
    "    registros_fecha_invalida = defunciones_limpio[defunciones_limpio['FECHA_DEF'].isnull()]\n",
    "    display(registros_fecha_invalida[['AÑO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_CANT']].head())\n",
    "    \n",
    "    # Eliminar registros con fechas inválidas (son muy pocos)\n",
    "    defunciones_limpio = defunciones_limpio.dropna(subset=['FECHA_DEF'])\n",
    "    print(f\"Registros eliminados por fechas inválidas: {fechas_invalidas}\")\n",
    "\n",
    "# Crear variables temporales derivadas para análisis\n",
    "print(\"\\n=== CREACIÓN DE VARIABLES TEMPORALES ===\")\n",
    "\n",
    "# Extraer año, mes, día de la semana, trimestre\n",
    "defunciones_limpio['AÑO_FECHA'] = defunciones_limpio['FECHA_DEF'].dt.year\n",
    "defunciones_limpio['MES'] = defunciones_limpio['FECHA_DEF'].dt.month\n",
    "defunciones_limpio['DIA_SEMANA'] = defunciones_limpio['FECHA_DEF'].dt.day_name()\n",
    "defunciones_limpio['TRIMESTRE'] = defunciones_limpio['FECHA_DEF'].dt.quarter\n",
    "defunciones_limpio['DIA_AÑO'] = defunciones_limpio['FECHA_DEF'].dt.dayofyear\n",
    "\n",
    "print(\"Variables temporales creadas:\")\n",
    "print(\"- AÑO_FECHA: Año de la fecha de defunción\")\n",
    "print(\"- MES: Mes (1-12)\")\n",
    "print(\"- DIA_SEMANA: Día de la semana\")\n",
    "print(\"- TRIMESTRE: Trimestre (1-4)\")\n",
    "print(\"- DIA_AÑO: Día del año (1-365/366)\")\n",
    "\n",
    "# Verificar consistencia entre AÑO y AÑO_FECHA\n",
    "inconsistencias_año = (defunciones_limpio['AÑO'] != defunciones_limpio['AÑO_FECHA']).sum()\n",
    "print(f\"\\nInconsistencias entre AÑO y AÑO_FECHA: {inconsistencias_año}\")\n",
    "\n",
    "if inconsistencias_año > 0:\n",
    "    print(\"Ejemplos de inconsistencias:\")\n",
    "    inconsistencias = defunciones_limpio[defunciones_limpio['AÑO'] != defunciones_limpio['AÑO_FECHA']]\n",
    "    display(inconsistencias[['AÑO', 'FECHA_DEF', 'AÑO_FECHA']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ab365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA LIMPIEZA DE DEFUNCIONES_FILTRADAS ===\n",
      " Registros originales: 1,250,062\n",
      " Registros después de limpieza: 1,246,214\n",
      " Registros eliminados: 3,848\n",
      " Porcentaje de datos conservados: 99.69%\n",
      "\n",
      "=== VERIFICACIÓN FINAL ===\n",
      "Valores nulos por columna:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Duplicados restantes: 0\n",
      "\n",
      "=== INFORMACIÓN DEL DATASET LIMPIO ===\n",
      "Columnas: 15\n",
      "Rango de fechas: 2014-01-01 00:00:00 a 2024-09-28 00:00:00\n",
      "Años cubiertos: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      " Dataset defunciones_filtradas limpiado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 3.6 Resumen de la limpieza del dataset defunciones_filtradas\n",
    "\n",
    "print(\"=== RESUMEN DE LA LIMPIEZA DE DEFUNCIONES_FILTRADAS ===\")\n",
    "print(f\" Registros originales: {defunciones_filtradas.shape[0]:,}\")\n",
    "print(f\" Registros después de limpieza: {defunciones_limpio.shape[0]:,}\")\n",
    "print(f\" Registros eliminados: {defunciones_filtradas.shape[0] - defunciones_limpio.shape[0]:,}\")\n",
    "print(f\" Porcentaje de datos conservados: {(defunciones_limpio.shape[0] / defunciones_filtradas.shape[0]) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n=== VERIFICACIÓN FINAL ===\")\n",
    "print(\"Valores nulos por columna:\")\n",
    "nulos_finales = defunciones_limpio.isnull().sum()\n",
    "print(nulos_finales[nulos_finales > 0])\n",
    "\n",
    "print(f\"\\nDuplicados restantes: {defunciones_limpio.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== INFORMACIÓN DEL DATASET LIMPIO ===\")\n",
    "print(f\"Columnas: {defunciones_limpio.shape[1]}\")\n",
    "print(f\"Rango de fechas: {defunciones_limpio['FECHA_DEF'].min()} a {defunciones_limpio['FECHA_DEF'].max()}\")\n",
    "print(f\"Años cubiertos: {sorted(defunciones_limpio['AÑO'].unique())}\")\n",
    "\n",
    "print(\"\\n Dataset defunciones_filtradas limpiado exitosamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9fdf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASET LIMPIO ===\n",
      " Dataset guardado exitosamente en: C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\defunciones_limpias.csv\n",
      " Tamaño del archivo: 163.54 MB\n",
      " Verificación: Archivo guardado correctamente\n",
      "\n",
      " Muestra del archivo guardado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AÑO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_TIPO</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COD_COMUNA</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>NOMBRE_REGION</th>\n",
       "      <th>CAPITULO_DIAG1</th>\n",
       "      <th>GLOSA_CAPITULO_DIAG1</th>\n",
       "      <th>AÑO_FECHA</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA_SEMANA</th>\n",
       "      <th>TRIMESTRE</th>\n",
       "      <th>DIA_AÑO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13127.0</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8203.0</td>\n",
       "      <td>Cañete</td>\n",
       "      <td>Del Bíobío</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13303.0</td>\n",
       "      <td>Tiltil</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>13119.0</td>\n",
       "      <td>Maipú</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13115.0</td>\n",
       "      <td>Lo Barnechea</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AÑO   FECHA_DEF SEXO_NOMBRE  EDAD_TIPO  EDAD_CANT  COD_COMUNA  \\\n",
       "0  2015  2015-01-11       Mujer        2.0          4     13127.0   \n",
       "1  2016  2016-01-31      Hombre        1.0         20      8203.0   \n",
       "2  2019  2019-08-08      Hombre        1.0         18     13303.0   \n",
       "3  2015  2015-02-17      Hombre        1.0         19     13119.0   \n",
       "4  2015  2015-01-03      Hombre        1.0         18     13115.0   \n",
       "\n",
       "         COMUNA              NOMBRE_REGION CAPITULO_DIAG1  \\\n",
       "0      Recoleta  Metropolitana de Santiago        S00-T98   \n",
       "1        Cañete                 Del Bíobío        S00-T98   \n",
       "2        Tiltil  Metropolitana de Santiago        S00-T98   \n",
       "3         Maipú  Metropolitana de Santiago        S00-T98   \n",
       "4  Lo Barnechea  Metropolitana de Santiago        S00-T98   \n",
       "\n",
       "                                GLOSA_CAPITULO_DIAG1  AÑO_FECHA  MES  \\\n",
       "0  Traumatismos, envenenamientos y algunas otras ...       2015    1   \n",
       "1  Traumatismos, envenenamientos y algunas otras ...       2016    1   \n",
       "2  Traumatismos, envenenamientos y algunas otras ...       2019    8   \n",
       "3  Traumatismos, envenenamientos y algunas otras ...       2015    2   \n",
       "4  Traumatismos, envenenamientos y algunas otras ...       2015    1   \n",
       "\n",
       "  DIA_SEMANA  TRIMESTRE  DIA_AÑO  \n",
       "0     Sunday          1       11  \n",
       "1     Sunday          1       31  \n",
       "2   Thursday          3      220  \n",
       "3    Tuesday          1       48  \n",
       "4   Saturday          1        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.7 Guardar dataset limpio para uso posterior\n",
    "\n",
    "print(\"=== GUARDANDO DATASET LIMPIO ===\")\n",
    "\n",
    "# Crear la carpeta 02_intermediate si no existe\n",
    "import os\n",
    "carpeta_intermediate = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\"\n",
    "if not os.path.exists(carpeta_intermediate):\n",
    "    os.makedirs(carpeta_intermediate)\n",
    "    print(f\" Carpeta creada: {carpeta_intermediate}\")\n",
    "\n",
    "# Guardar el dataset limpio en formato CSV\n",
    "ruta_guardado = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\defunciones_limpias.csv\"\n",
    "defunciones_limpio.to_csv(ruta_guardado, index=False)\n",
    "\n",
    "print(f\" Dataset guardado exitosamente en: {ruta_guardado}\")\n",
    "print(f\" Tamaño del archivo: {os.path.getsize(ruta_guardado) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Verificar que el archivo se guardó correctamente\n",
    "if os.path.exists(ruta_guardado):\n",
    "    print(\" Verificación: Archivo guardado correctamente\")\n",
    "    \n",
    "    # Cargar una muestra para verificar\n",
    "    muestra_verificacion = pd.read_csv(ruta_guardado, nrows=5)\n",
    "    print(\"\\n Muestra del archivo guardado:\")\n",
    "    display(muestra_verificacion)\n",
    "else:\n",
    "    print(\" Error: No se pudo guardar el archivo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117bc3e",
   "metadata": {},
   "source": [
    "## 4. Estandarización de Nombres de Columnas\n",
    "\n",
    "Esta sección se enfoca en unificar y estandarizar los nombres de columnas entre todos los datasets para mantener consistencia en el proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a305d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS DE NOMBRES DE COLUMNAS ===\n",
      "\n",
      " POR_SEXO:\n",
      "   Columnas: ['Año', 'Nacimiento (Hombre)', 'Nacimiento (Mujer)', 'Defuncion(Hombre)', 'Defuncion (Mujer)']\n",
      "   Dimensiones: (9, 5)\n",
      "\n",
      " DEFUNCIONES_LIMPIO:\n",
      "   Columnas: ['AÑO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_TIPO', 'EDAD_CANT', 'COD_COMUNA', 'COMUNA', 'NOMBRE_REGION', 'CAPITULO_DIAG1', 'GLOSA_CAPITULO_DIAG1', 'AÑO_FECHA', 'MES', 'DIA_SEMANA', 'TRIMESTRE', 'DIA_AÑO']\n",
      "   Dimensiones: (1246214, 15)\n",
      "\n",
      " POR_EDAD_MADRE:\n",
      "   Columnas: ['Año', 'Menores de 15 años', '15 a 19 años', '20 a 24 años', '25 a 29 años', '30 a 34 años', '35 a 39 años', '40 a 44 años', '45 a 49 años', '50 y más años']\n",
      "   Dimensiones: (14, 10)\n",
      "\n",
      " POR_EDAD_FALLECIDO:\n",
      "   Columnas: ['Año', 'Menores de 1 año', '1 a 4', '5 a 9', '10 a 14', '15 a 19', '20 a 24', '25 a 29', '30 a 34', '35 a 39', '40 a 44', '45 a 49', '50 o mas']\n",
      "   Dimensiones: (14, 13)\n",
      "\n",
      " SETDEDATOS:\n",
      "   Columnas: ['año', 'Nacimientos', 'Defunciones']\n",
      "   Dimensiones: (50, 3)\n",
      "\n",
      "=== PROBLEMAS IDENTIFICADOS ===\n",
      "1. Inconsistencia en 'Año' vs 'año'\n",
      "2. Espacios inconsistentes en nombres (ej: 'Defuncion(Hombre)' vs 'Defuncion (Mujer)')\n",
      "3. Nombres de regiones con/sin tildes\n",
      "4. Nombres de columnas muy largos o poco descriptivos\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Análisis de nombres de columnas en todos los datasets\n",
    "\n",
    "print(\"=== ANÁLISIS DE NOMBRES DE COLUMNAS ===\")\n",
    "\n",
    "# Crear diccionario con todos los datasets para análisis\n",
    "datasets_para_estandarizar = {\n",
    "    \"por_sexo\": por_sexo,\n",
    "    \"defunciones_limpio\": defunciones_limpio,\n",
    "    \"por_edad_madre\": por_edad_madre,\n",
    "    \"por_edad_fallecido\": por_edad_fallecido,\n",
    "    \"setdedatos\": setdedatos\n",
    "}\n",
    "\n",
    "# Mostrar nombres de columnas de cada dataset\n",
    "for nombre_dataset, df in datasets_para_estandarizar.items():\n",
    "    print(f\"\\n {nombre_dataset.upper()}:\")\n",
    "    print(f\"   Columnas: {list(df.columns)}\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "\n",
    "print(\"\\n=== PROBLEMAS IDENTIFICADOS ===\")\n",
    "print(\"1. Inconsistencia en 'Año' vs 'año'\")\n",
    "print(\"2. Espacios inconsistentes en nombres (ej: 'Defuncion(Hombre)' vs 'Defuncion (Mujer)')\")\n",
    "print(\"3. Nombres de regiones con/sin tildes\")\n",
    "print(\"4. Nombres de columnas muy largos o poco descriptivos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9f0e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN: POR_SEXO ===\n",
      "Columnas originales:\n",
      "['Año', 'Nacimiento (Hombre)', 'Nacimiento (Mujer)', 'Defuncion(Hombre)', 'Defuncion (Mujer)']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['año', 'nacimientos_hombres', 'nacimientos_mujeres', 'defunciones_hombres', 'defunciones_mujeres']\n",
      "\n",
      " Dataset por_sexo estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Estandarización de nombres de columnas - Dataset por_sexo\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN: POR_SEXO ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "por_sexo_estandarizado = por_sexo.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(por_sexo_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_por_sexo = {\n",
    "    'Año': 'año',\n",
    "    'Nacimiento (Hombre)': 'nacimientos_hombres',\n",
    "    'Nacimiento (Mujer)': 'nacimientos_mujeres', \n",
    "    'Defuncion(Hombre)': 'defunciones_hombres',\n",
    "    'Defuncion (Mujer)': 'defunciones_mujeres'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "por_sexo_estandarizado = por_sexo_estandarizado.rename(columns=mapeo_por_sexo)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(por_sexo_estandarizado.columns))\n",
    "\n",
    "print(\"\\n Dataset por_sexo estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2a761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN: DEFUNCIONES_LIMPIO ===\n",
      "Columnas originales:\n",
      "['AÑO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_TIPO', 'EDAD_CANT', 'COD_COMUNA', 'COMUNA', 'NOMBRE_REGION', 'CAPITULO_DIAG1', 'GLOSA_CAPITULO_DIAG1', 'AÑO_FECHA', 'MES', 'DIA_SEMANA', 'TRIMESTRE', 'DIA_AÑO']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['año', 'fecha_defuncion', 'sexo', 'tipo_edad', 'edad_cantidad', 'codigo_comuna', 'comuna', 'region', 'codigo_diagnostico', 'descripcion_diagnostico', 'año_fecha', 'mes', 'dia_semana', 'trimestre', 'dia_año']\n",
      "\n",
      " Dataset defunciones_limpio estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Estandarización de nombres de columnas - Dataset defunciones_limpio\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN: DEFUNCIONES_LIMPIO ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "defunciones_estandarizado = defunciones_limpio.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(defunciones_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_defunciones = {\n",
    "    'AÑO': 'año',\n",
    "    'FECHA_DEF': 'fecha_defuncion',\n",
    "    'SEXO_NOMBRE': 'sexo',\n",
    "    'EDAD_TIPO': 'tipo_edad',\n",
    "    'EDAD_CANT': 'edad_cantidad',\n",
    "    'COD_COMUNA': 'codigo_comuna',\n",
    "    'COMUNA': 'comuna',\n",
    "    'NOMBRE_REGION': 'region',\n",
    "    'CAPITULO_DIAG1': 'codigo_diagnostico',\n",
    "    'GLOSA_CAPITULO_DIAG1': 'descripcion_diagnostico',\n",
    "    'AÑO_FECHA': 'año_fecha',\n",
    "    'MES': 'mes',\n",
    "    'DIA_SEMANA': 'dia_semana',\n",
    "    'TRIMESTRE': 'trimestre',\n",
    "    'DIA_AÑO': 'dia_año'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "defunciones_estandarizado = defunciones_estandarizado.rename(columns=mapeo_defunciones)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(defunciones_estandarizado.columns))\n",
    "\n",
    "print(\"\\n Dataset defunciones_limpio estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6da32304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN: POR_EDAD_MADRE ===\n",
      "Columnas originales:\n",
      "['Año', 'Menores de 15 años', '15 a 19 años', '20 a 24 años', '25 a 29 años', '30 a 34 años', '35 a 39 años', '40 a 44 años', '45 a 49 años', '50 y más años']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['año', 'nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      " Dataset por_edad_madre estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.4 Estandarización de nombres de columnas - Dataset por_edad_madre\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN: POR_EDAD_MADRE ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "por_edad_madre_estandarizado = por_edad_madre.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(por_edad_madre_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_edad_madre = {\n",
    "    'Año': 'año',\n",
    "    'Menores de 15 años': 'nacimientos_menores_15',\n",
    "    '15 a 19 años': 'nacimientos_15_19',\n",
    "    '20 a 24 años': 'nacimientos_20_24',\n",
    "    '25 a 29 años': 'nacimientos_25_29',\n",
    "    '30 a 34 años': 'nacimientos_30_34',\n",
    "    '35 a 39 años': 'nacimientos_35_39',\n",
    "    '40 a 44 años': 'nacimientos_40_44',\n",
    "    '45 a 49 años': 'nacimientos_45_49',\n",
    "    '50 y más años': 'nacimientos_50_mas'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "por_edad_madre_estandarizado = por_edad_madre_estandarizado.rename(columns=mapeo_edad_madre)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(por_edad_madre_estandarizado.columns))\n",
    "\n",
    "print(\"\\n Dataset por_edad_madre estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4384733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN: POR_EDAD_FALLECIDO ===\n",
      "Columnas originales:\n",
      "['Año', 'Menores de 1 año', '1 a 4', '5 a 9', '10 a 14', '15 a 19', '20 a 24', '25 a 29', '30 a 34', '35 a 39', '40 a 44', '45 a 49', '50 o mas']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['año', 'defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      " Dataset por_edad_fallecido estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.5 Estandarización de nombres de columnas - Dataset por_edad_fallecido\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN: POR_EDAD_FALLECIDO ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "por_edad_fallecido_estandarizado = por_edad_fallecido.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(por_edad_fallecido_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_edad_fallecido = {\n",
    "    'Año': 'año',\n",
    "    'Menores de 1 año': 'defunciones_menores_1',\n",
    "    '1 a 4': 'defunciones_1_4',\n",
    "    '5 a 9': 'defunciones_5_9',\n",
    "    '10 a 14': 'defunciones_10_14',\n",
    "    '15 a 19': 'defunciones_15_19',\n",
    "    '20 a 24': 'defunciones_20_24',\n",
    "    '25 a 29': 'defunciones_25_29',\n",
    "    '30 a 34': 'defunciones_30_34',\n",
    "    '35 a 39': 'defunciones_35_39',\n",
    "    '40 a 44': 'defunciones_40_44',\n",
    "    '45 a 49': 'defunciones_45_49',\n",
    "    '50 o mas': 'defunciones_50_mas'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "por_edad_fallecido_estandarizado = por_edad_fallecido_estandarizado.rename(columns=mapeo_edad_fallecido)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(por_edad_fallecido_estandarizado.columns))\n",
    "\n",
    "print(\"\\n Dataset por_edad_fallecido estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b230d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN: SETDEDATOS ===\n",
      "Columnas originales:\n",
      "['año', 'Nacimientos', 'Defunciones']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['año', 'nacimientos_totales', 'defunciones_totales']\n",
      "\n",
      " Dataset setdedatos estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.6 Estandarización de nombres de columnas - Dataset setdedatos\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN: SETDEDATOS ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "setdedatos_estandarizado = setdedatos.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(setdedatos_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_setdedatos = {\n",
    "    'año': 'año',  # Ya está en minúsculas\n",
    "    'Nacimientos': 'nacimientos_totales',\n",
    "    'Defunciones': 'defunciones_totales'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "setdedatos_estandarizado = setdedatos_estandarizado.rename(columns=mapeo_setdedatos)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(setdedatos_estandarizado.columns))\n",
    "\n",
    "print(\"\\n Dataset setdedatos estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc8c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN DE NOMBRES DE REGIONES ===\n",
      "Regiones únicas encontradas:\n",
      " 1. De Aisén del Gral. C. Ibáñez del Campo\n",
      " 2. De Antofagasta\n",
      " 3. De Arica y Parinacota\n",
      " 4. De Atacama\n",
      " 5. De Coquimbo\n",
      " 6. De La Araucanía\n",
      " 7. De Los Lagos\n",
      " 8. De Los Ríos\n",
      " 9. De Magallanes y de La Antártica Chilena\n",
      "10. De Tarapacá\n",
      "11. De Valparaíso\n",
      "12. De Ñuble\n",
      "13. Del Bíobío\n",
      "14. Del Libertador B. O'Higgins\n",
      "15. Del Maule\n",
      "16. Ignorada\n",
      "17. Metropolitana de Santiago\n",
      "\n",
      "Regiones después de estandarización:\n",
      " 1. De Aisén del Gral. C. Ibáñez del Campo\n",
      " 2. De Antofagasta\n",
      " 3. De Arica y Parinacota\n",
      " 4. De Atacama\n",
      " 5. De Coquimbo\n",
      " 6. De La Araucanía\n",
      " 7. De Los Lagos\n",
      " 8. De Los Ríos\n",
      " 9. De Magallanes y de La Antártica Chilena\n",
      "10. De Tarapacá\n",
      "11. De Valparaíso\n",
      "12. De Ñuble\n",
      "13. Del Biobío\n",
      "14. Del Libertador General Bernardo O'Higgins\n",
      "15. Del Maule\n",
      "16. Ignorada\n",
      "17. Región Metropolitana\n",
      "\n",
      " Nombres de regiones estandarizados\n"
     ]
    }
   ],
   "source": [
    "# 4.7 Estandarización de nombres de regiones\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN DE NOMBRES DE REGIONES ===\")\n",
    "\n",
    "# Analizar nombres únicos de regiones en el dataset de defunciones\n",
    "regiones_unicas = defunciones_estandarizado['region'].unique()\n",
    "print(\"Regiones únicas encontradas:\")\n",
    "for i, region in enumerate(sorted(regiones_unicas), 1):\n",
    "    print(f\"{i:2d}. {region}\")\n",
    "\n",
    "# Definir mapeo para estandarizar nombres de regiones\n",
    "mapeo_regiones = {\n",
    "    'Del Bíobío': 'Del Biobío',  # Quitar tilde\n",
    "    'Metropolitana de Santiago': 'Región Metropolitana',\n",
    "    'De Tarapacá': 'De Tarapacá',  # Ya está correcto\n",
    "    'De Antofagasta': 'De Antofagasta',  # Ya está correcto\n",
    "    'De Atacama': 'De Atacama',  # Ya está correcto\n",
    "    'De Coquimbo': 'De Coquimbo',  # Ya está correcto\n",
    "    'De Valparaíso': 'De Valparaíso',  # Ya está correcto\n",
    "    'Del Libertador B. O\\'Higgins': 'Del Libertador General Bernardo O\\'Higgins',\n",
    "    'Del Maule': 'Del Maule',  # Ya está correcto\n",
    "    'De Ñuble': 'De Ñuble',  # Ya está correcto\n",
    "    'De La Araucanía': 'De La Araucanía',  # Ya está correcto\n",
    "    'De Los Ríos': 'De Los Ríos',  # Ya está correcto\n",
    "    'De Los Lagos': 'De Los Lagos',  # Ya está correcto\n",
    "    'De Aysén del General Carlos Ibáñez del Campo': 'De Aysén del General Carlos Ibáñez del Campo',  # Ya está correcto\n",
    "    'De Magallanes y de la Antártica Chilena': 'De Magallanes y de la Antártica Chilena'  # Ya está correcto\n",
    "}\n",
    "\n",
    "# Aplicar mapeo de regiones\n",
    "defunciones_estandarizado['region'] = defunciones_estandarizado['region'].replace(mapeo_regiones)\n",
    "\n",
    "print(\"\\nRegiones después de estandarización:\")\n",
    "regiones_estandarizadas = defunciones_estandarizado['region'].unique()\n",
    "for i, region in enumerate(sorted(regiones_estandarizadas), 1):\n",
    "    print(f\"{i:2d}. {region}\")\n",
    "\n",
    "print(\"\\n Nombres de regiones estandarizados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ff8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA ESTANDARIZACIÓN DE NOMBRES DE COLUMNAS ===\n",
      " Nombres de columnas estandarizados:\n",
      "\n",
      "POR_SEXO_ESTANDARIZADO:\n",
      "   Columnas: ['año', 'nacimientos_hombres', 'nacimientos_mujeres', 'defunciones_hombres', 'defunciones_mujeres']\n",
      "\n",
      "DEFUNCIONES_ESTANDARIZADO:\n",
      "   Columnas: ['año', 'fecha_defuncion', 'sexo', 'tipo_edad', 'edad_cantidad', 'codigo_comuna', 'comuna', 'region', 'codigo_diagnostico', 'descripcion_diagnostico', 'año_fecha', 'mes', 'dia_semana', 'trimestre', 'dia_año']\n",
      "\n",
      "POR_EDAD_MADRE_ESTANDARIZADO:\n",
      "   Columnas: ['año', 'nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      "POR_EDAD_FALLECIDO_ESTANDARIZADO:\n",
      "   Columnas: ['año', 'defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      "SETDEDATOS_ESTANDARIZADO:\n",
      "   Columnas: ['año', 'nacimientos_totales', 'defunciones_totales']\n",
      "\n",
      "=== BENEFICIOS DE LA ESTANDARIZACIÓN ===\n",
      " Todos los datasets usan 'año' en minúsculas\n",
      " Nombres de columnas más descriptivos y consistentes\n",
      " Espacios y caracteres especiales estandarizados\n",
      " Nombres de regiones unificados\n",
      " Facilita la integración y análisis posterior\n",
      "\n",
      "=== DATASETS ESTANDARIZADOS DISPONIBLES ===\n",
      "Los siguientes datasets están listos para análisis:\n",
      "  - por_sexo_estandarizado\n",
      "  - defunciones_estandarizado\n",
      "  - por_edad_madre_estandarizado\n",
      "  - por_edad_fallecido_estandarizado\n",
      "  - setdedatos_estandarizado\n",
      "\n",
      " Estandarización de nombres de columnas completada\n"
     ]
    }
   ],
   "source": [
    "# 4.8 Resumen de la estandarización de nombres de columnas\n",
    "\n",
    "print(\"=== RESUMEN DE LA ESTANDARIZACIÓN DE NOMBRES DE COLUMNAS ===\")\n",
    "\n",
    "# Crear diccionario con todos los datasets estandarizados\n",
    "datasets_estandarizados = {\n",
    "    \"por_sexo_estandarizado\": por_sexo_estandarizado,\n",
    "    \"defunciones_estandarizado\": defunciones_estandarizado,\n",
    "    \"por_edad_madre_estandarizado\": por_edad_madre_estandarizado,\n",
    "    \"por_edad_fallecido_estandarizado\": por_edad_fallecido_estandarizado,\n",
    "    \"setdedatos_estandarizado\": setdedatos_estandarizado\n",
    "}\n",
    "\n",
    "print(\" Nombres de columnas estandarizados:\")\n",
    "for nombre_dataset, df in datasets_estandarizados.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Columnas: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== BENEFICIOS DE LA ESTANDARIZACIÓN ===\")\n",
    "print(\" Todos los datasets usan 'año' en minúsculas\")\n",
    "print(\" Nombres de columnas más descriptivos y consistentes\")\n",
    "print(\" Espacios y caracteres especiales estandarizados\")\n",
    "print(\" Nombres de regiones unificados\")\n",
    "print(\" Facilita la integración y análisis posterior\")\n",
    "\n",
    "print(\"\\n=== DATASETS ESTANDARIZADOS DISPONIBLES ===\")\n",
    "print(\"Los siguientes datasets están listos para análisis:\")\n",
    "for nombre in datasets_estandarizados.keys():\n",
    "    print(f\"  - {nombre}\")\n",
    "\n",
    "print(\"\\n Estandarización de nombres de columnas completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d4e9b",
   "metadata": {},
   "source": [
    "## 5. Validación de Rangos de Edad\n",
    "\n",
    "Esta sección se enfoca en verificar la consistencia de los rangos de edad entre datasets y validar que los valores de edad sean lógicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3d34145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS DE RANGOS DE EDAD - NACIMIENTOS ===\n",
      " Rangos de edad en nacimientos (por_edad_madre_estandarizado):\n",
      "Columnas de edad: ['nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      " Estadísticas por rango de edad de madre:\n",
      "  nacimientos_menores_15   : Min=   158, Max=   963, Promedio=   558\n",
      "  nacimientos_15_19        : Min=  6428, Max= 38047, Promedio= 20607\n",
      "  nacimientos_20_24        : Min= 28334, Max= 59884, Promedio= 46498\n",
      "  nacimientos_25_29        : Min= 45178, Max= 63210, Promedio= 57008\n",
      "  nacimientos_30_34        : Min= 50523, Max= 57520, Promedio= 54143\n",
      "  nacimientos_35_39        : Min= 30989, Max= 34942, Promedio= 32793\n",
      "  nacimientos_40_44        : Min=  8257, Max=  9545, Promedio=  8869\n",
      "  nacimientos_45_49        : Min=   441, Max=   602, Promedio=   502\n",
      "  nacimientos_50_mas       : Min=     5, Max=    32, Promedio=    17\n",
      "\n",
      " Verificación de formato de nombres:\n",
      "   Formato consistente: nacimientos_menores_15\n",
      "   Formato consistente: nacimientos_15_19\n",
      "   Formato consistente: nacimientos_20_24\n",
      "   Formato consistente: nacimientos_25_29\n",
      "   Formato consistente: nacimientos_30_34\n",
      "   Formato consistente: nacimientos_35_39\n",
      "   Formato consistente: nacimientos_40_44\n",
      "   Formato consistente: nacimientos_45_49\n",
      "    Posible inconsistencia en: nacimientos_50_mas\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Análisis de rangos de edad en datasets de nacimientos\n",
    "\n",
    "print(\"=== ANÁLISIS DE RANGOS DE EDAD - NACIMIENTOS ===\")\n",
    "\n",
    "# Analizar rangos de edad en dataset por_edad_madre\n",
    "print(\" Rangos de edad en nacimientos (por_edad_madre_estandarizado):\")\n",
    "columnas_edad_madre = [col for col in por_edad_madre_estandarizado.columns if col != 'año']\n",
    "print(\"Columnas de edad:\", columnas_edad_madre)\n",
    "\n",
    "# Mostrar estadísticas básicas de cada rango\n",
    "print(\"\\n Estadísticas por rango de edad de madre:\")\n",
    "for col in columnas_edad_madre:\n",
    "    min_val = por_edad_madre_estandarizado[col].min()\n",
    "    max_val = por_edad_madre_estandarizado[col].max()\n",
    "    mean_val = por_edad_madre_estandarizado[col].mean()\n",
    "    print(f\"  {col:25s}: Min={min_val:6.0f}, Max={max_val:6.0f}, Promedio={mean_val:6.0f}\")\n",
    "\n",
    "# Verificar consistencia en el formato de nombres\n",
    "print(\"\\n Verificación de formato de nombres:\")\n",
    "for col in columnas_edad_madre:\n",
    "    if 'mas' in col or 'más' in col:\n",
    "        print(f\"    Posible inconsistencia en: {col}\")\n",
    "    else:\n",
    "        print(f\"   Formato consistente: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "972b4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS DE RANGOS DE EDAD - DEFUNCIONES ===\n",
      " Rangos de edad en defunciones (por_edad_fallecido_estandarizado):\n",
      "Columnas de edad: ['defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      " Estadísticas por rango de edad de fallecido:\n",
      "  defunciones_menores_1    : Min=  1022, Max=  1908, Promedio=  1512\n",
      "  defunciones_1_4          : Min=   204, Max=   312, Promedio=   253\n",
      "  defunciones_5_9          : Min=   129, Max=   188, Promedio=   161\n",
      "  defunciones_10_14        : Min=   162, Max=   238, Promedio=   200\n",
      "  defunciones_15_19        : Min=   465, Max=   733, Promedio=   574\n",
      "  defunciones_20_24        : Min=   857, Max=  1065, Promedio=   932\n",
      "  defunciones_25_29        : Min=   955, Max=  1276, Promedio=  1101\n",
      "  defunciones_30_34        : Min=  1088, Max=  1618, Promedio=  1255\n",
      "  defunciones_35_39        : Min=  1347, Max=  1803, Promedio=  1516\n",
      "  defunciones_40_44        : Min=  1847, Max=  2391, Promedio=  2081\n",
      "  defunciones_45_49        : Min=  2710, Max=  3589, Promedio=  3017\n",
      "  defunciones_50_mas       : Min= 81954, Max=123781, Promedio= 97781\n",
      "\n",
      " Verificación de formato de nombres:\n",
      "   Formato consistente: defunciones_menores_1\n",
      "   Formato consistente: defunciones_1_4\n",
      "   Formato consistente: defunciones_5_9\n",
      "   Formato consistente: defunciones_10_14\n",
      "   Formato consistente: defunciones_15_19\n",
      "   Formato consistente: defunciones_20_24\n",
      "   Formato consistente: defunciones_25_29\n",
      "   Formato consistente: defunciones_30_34\n",
      "   Formato consistente: defunciones_35_39\n",
      "   Formato consistente: defunciones_40_44\n",
      "   Formato consistente: defunciones_45_49\n",
      "    Posible inconsistencia en: defunciones_50_mas\n",
      "\n",
      " Análisis de EDAD_CANT en defunciones detalladas:\n",
      "Valores únicos de edad_cantidad: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84), np.int64(85), np.int64(86), np.int64(87), np.int64(88), np.int64(89), np.int64(90), np.int64(91), np.int64(92), np.int64(93), np.int64(94), np.int64(95), np.int64(96), np.int64(97), np.int64(98), np.int64(99), np.int64(100), np.int64(101), np.int64(102), np.int64(103), np.int64(104), np.int64(105), np.int64(106), np.int64(107), np.int64(108), np.int64(109), np.int64(110), np.int64(111), np.int64(112), np.int64(113), np.int64(114), np.int64(115), np.int64(116), np.int64(117), np.int64(118), np.int64(121), np.int64(123), np.int64(126), np.int64(999)]\n",
      "Rango de edad_cantidad: 0 - 999\n",
      "Valores nulos en edad_cantidad: 0\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Análisis de rangos de edad en datasets de defunciones\n",
    "\n",
    "print(\"=== ANÁLISIS DE RANGOS DE EDAD - DEFUNCIONES ===\")\n",
    "\n",
    "# Analizar rangos de edad en dataset por_edad_fallecido\n",
    "print(\" Rangos de edad en defunciones (por_edad_fallecido_estandarizado):\")\n",
    "columnas_edad_fallecido = [col for col in por_edad_fallecido_estandarizado.columns if col != 'año']\n",
    "print(\"Columnas de edad:\", columnas_edad_fallecido)\n",
    "\n",
    "# Mostrar estadísticas básicas de cada rango\n",
    "print(\"\\n Estadísticas por rango de edad de fallecido:\")\n",
    "for col in columnas_edad_fallecido:\n",
    "    min_val = por_edad_fallecido_estandarizado[col].min()\n",
    "    max_val = por_edad_fallecido_estandarizado[col].max()\n",
    "    mean_val = por_edad_fallecido_estandarizado[col].mean()\n",
    "    print(f\"  {col:25s}: Min={min_val:6.0f}, Max={max_val:6.0f}, Promedio={mean_val:6.0f}\")\n",
    "\n",
    "# Verificar consistencia en el formato de nombres\n",
    "print(\"\\n Verificación de formato de nombres:\")\n",
    "for col in columnas_edad_fallecido:\n",
    "    if 'mas' in col or 'más' in col:\n",
    "        print(f\"    Posible inconsistencia en: {col}\")\n",
    "    else:\n",
    "        print(f\"   Formato consistente: {col}\")\n",
    "\n",
    "# Analizar valores de EDAD_CANT en dataset de defunciones detalladas\n",
    "print(\"\\n Análisis de EDAD_CANT en defunciones detalladas:\")\n",
    "print(f\"Valores únicos de edad_cantidad: {sorted(defunciones_estandarizado['edad_cantidad'].unique())}\")\n",
    "print(f\"Rango de edad_cantidad: {defunciones_estandarizado['edad_cantidad'].min()} - {defunciones_estandarizado['edad_cantidad'].max()}\")\n",
    "print(f\"Valores nulos en edad_cantidad: {defunciones_estandarizado['edad_cantidad'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a695853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN DE RANGOS DE EDAD ENTRE DATASETS ===\n",
      " Rangos de edad en nacimientos:\n",
      "  nacimientos_menores_15    → 0-14\n",
      "  nacimientos_15_19         → 15-19\n",
      "  nacimientos_20_24         → 20-24\n",
      "  nacimientos_25_29         → 25-29\n",
      "  nacimientos_30_34         → 30-34\n",
      "  nacimientos_35_39         → 35-39\n",
      "  nacimientos_40_44         → 40-44\n",
      "  nacimientos_45_49         → 45-49\n",
      "  nacimientos_50_mas        → 50+\n",
      "\n",
      " Rangos de edad en defunciones:\n",
      "  defunciones_menores_1     → 0-1\n",
      "  defunciones_1_4           → 1-4\n",
      "  defunciones_5_9           → 5-9\n",
      "  defunciones_10_14         → 10-14\n",
      "  defunciones_15_19         → 15-19\n",
      "  defunciones_20_24         → 20-24\n",
      "  defunciones_25_29         → 25-29\n",
      "  defunciones_30_34         → 30-34\n",
      "  defunciones_35_39         → 35-39\n",
      "  defunciones_40_44         → 40-44\n",
      "  defunciones_45_49         → 45-49\n",
      "  defunciones_50_mas        → 50+\n",
      "\n",
      " Rangos de edad comunes: ['15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50+']\n",
      " Rangos únicos en nacimientos: ['0-14']\n",
      " Rangos únicos en defunciones: ['0-1', '1-4', '10-14', '5-9']\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Comparación de rangos de edad entre datasets\n",
    "\n",
    "print(\"=== COMPARACIÓN DE RANGOS DE EDAD ENTRE DATASETS ===\")\n",
    "\n",
    "# Crear mapeo de rangos de edad para comparación\n",
    "rangos_nacimientos = {\n",
    "    'nacimientos_menores_15': '0-14',\n",
    "    'nacimientos_15_19': '15-19', \n",
    "    'nacimientos_20_24': '20-24',\n",
    "    'nacimientos_25_29': '25-29',\n",
    "    'nacimientos_30_34': '30-34',\n",
    "    'nacimientos_35_39': '35-39',\n",
    "    'nacimientos_40_44': '40-44',\n",
    "    'nacimientos_45_49': '45-49',\n",
    "    'nacimientos_50_mas': '50+'\n",
    "}\n",
    "\n",
    "rangos_defunciones = {\n",
    "    'defunciones_menores_1': '0-1',\n",
    "    'defunciones_1_4': '1-4',\n",
    "    'defunciones_5_9': '5-9',\n",
    "    'defunciones_10_14': '10-14',\n",
    "    'defunciones_15_19': '15-19',\n",
    "    'defunciones_20_24': '20-24',\n",
    "    'defunciones_25_29': '25-29',\n",
    "    'defunciones_30_34': '30-34',\n",
    "    'defunciones_35_39': '35-39',\n",
    "    'defunciones_40_44': '40-44',\n",
    "    'defunciones_45_49': '45-49',\n",
    "    'defunciones_50_mas': '50+'\n",
    "}\n",
    "\n",
    "print(\" Rangos de edad en nacimientos:\")\n",
    "for col, rango in rangos_nacimientos.items():\n",
    "    print(f\"  {col:25s} → {rango}\")\n",
    "\n",
    "print(\"\\n Rangos de edad en defunciones:\")\n",
    "for col, rango in rangos_defunciones.items():\n",
    "    print(f\"  {col:25s} → {rango}\")\n",
    "\n",
    "# Identificar rangos superpuestos\n",
    "rangos_comunes = set(rangos_nacimientos.values()) & set(rangos_defunciones.values())\n",
    "print(f\"\\n Rangos de edad comunes: {sorted(rangos_comunes)}\")\n",
    "\n",
    "# Identificar rangos únicos\n",
    "rangos_unicos_nacimientos = set(rangos_nacimientos.values()) - set(rangos_defunciones.values())\n",
    "rangos_unicos_defunciones = set(rangos_defunciones.values()) - set(rangos_nacimientos.values())\n",
    "\n",
    "print(f\" Rangos únicos en nacimientos: {sorted(rangos_unicos_nacimientos)}\")\n",
    "print(f\" Rangos únicos en defunciones: {sorted(rangos_unicos_defunciones)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "220a2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACIÓN DE VALORES DE EDAD EN DATASET DETALLADO ===\n",
      " Distribución de edad_cantidad:\n",
      "count    1.246214e+06\n",
      "mean     7.221377e+01\n",
      "std      1.880039e+01\n",
      "min      0.000000e+00\n",
      "25%      6.300000e+01\n",
      "50%      7.600000e+01\n",
      "75%      8.600000e+01\n",
      "max      9.990000e+02\n",
      "Name: edad_cantidad, dtype: float64\n",
      "\n",
      " Eliminando edades imposibles (>120 años):\n",
      "Registros con edad > 120 años: 14\n",
      "Ejemplos de edades imposibles:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año</th>\n",
       "      <th>fecha_defuncion</th>\n",
       "      <th>sexo</th>\n",
       "      <th>edad_cantidad</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De La Araucanía</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24752</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De Tarapacá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32330</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-30</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De La Araucanía</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41877</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>121</td>\n",
       "      <td>De Los Ríos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43947</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De Ñuble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        año fecha_defuncion    sexo  edad_cantidad           region\n",
       "4545   2014      2014-06-30  Hombre            999  De La Araucanía\n",
       "24752  2014      2014-04-19  Hombre            999      De Tarapacá\n",
       "32330  2015      2015-10-30  Hombre            999  De La Araucanía\n",
       "41877  2018      2018-04-18  Hombre            121      De Los Ríos\n",
       "43947  2014      2014-03-21  Hombre            999         De Ñuble"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Eliminados 14 registros con edad > 120 años\n",
      " Dataset actualizado: 1,246,200 registros\n",
      "\n",
      " TODAS LAS EDADES SON VÁLIDAS\n",
      " Rango de edades: 0 - 118 años\n",
      "\n",
      " Distribución por grupos de edad:\n",
      "  0-1 años    :  6,358 (  0.5%)\n",
      "  2-4 años    :  6,135 (  0.5%)\n",
      "  5-17 años   : 11,417 (  0.9%)\n",
      "  18-64 años  : 331,208 ( 26.6%)\n",
      "  65+ años    : 891,071 ( 71.5%)\n",
      "\n",
      " Validación de rangos lógicos:\n",
      "Registros con edad negativa: 0\n",
      "\n",
      " Validación completada: Dataset limpio con edades válidas\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Validación de valores de edad en dataset detallado (MODIFICADO)\n",
    "\n",
    "print(\"=== VALIDACIÓN DE VALORES DE EDAD EN DATASET DETALLADO ===\")\n",
    "\n",
    "# Analizar distribución de valores de edad_cantidad\n",
    "print(\" Distribución de edad_cantidad:\")\n",
    "print(defunciones_estandarizado['edad_cantidad'].describe())\n",
    "\n",
    "# 1. ELIMINAR edades imposibles (>120 años)\n",
    "print(\"\\n Eliminando edades imposibles (>120 años):\")\n",
    "edades_imposibles = defunciones_estandarizado[defunciones_estandarizado['edad_cantidad'] > 120]\n",
    "print(f\"Registros con edad > 120 años: {len(edades_imposibles)}\")\n",
    "\n",
    "if len(edades_imposibles) > 0:\n",
    "    print(\"Ejemplos de edades imposibles:\")\n",
    "    display(edades_imposibles[['año', 'fecha_defuncion', 'sexo', 'edad_cantidad', 'region']].head())\n",
    "    \n",
    "    # Eliminar estos registros\n",
    "    defunciones_estandarizado = defunciones_estandarizado[defunciones_estandarizado['edad_cantidad'] <= 120]\n",
    "    print(f\"\\n Eliminados {len(edades_imposibles)} registros con edad > 120 años\")\n",
    "    print(f\" Dataset actualizado: {len(defunciones_estandarizado):,} registros\")\n",
    "\n",
    "# 2. NO detectar outliers por edad (todas las edades son válidas)\n",
    "print(f\"\\n TODAS LAS EDADES SON VÁLIDAS\")\n",
    "print(f\" Rango de edades: {defunciones_estandarizado['edad_cantidad'].min()} - {defunciones_estandarizado['edad_cantidad'].max()} años\")\n",
    "\n",
    "# 3. Mostrar distribución por grupos de edad\n",
    "print(f\"\\n Distribución por grupos de edad:\")\n",
    "defunciones_estandarizado['grupo_edad'] = pd.cut(defunciones_estandarizado['edad_cantidad'], \n",
    "                                                bins=[0, 1, 5, 18, 65, 120], \n",
    "                                                labels=['0-1 años', '2-4 años', '5-17 años', '18-64 años', '65+ años'])\n",
    "distribucion_grupos = defunciones_estandarizado['grupo_edad'].value_counts().sort_index()\n",
    "for grupo, cantidad in distribucion_grupos.items():\n",
    "    porcentaje = (cantidad / len(defunciones_estandarizado)) * 100\n",
    "    print(f\"  {grupo:12s}: {cantidad:6,} ({porcentaje:5.1f}%)\")\n",
    "\n",
    "# 4. Solo validar rangos lógicos básicos\n",
    "print(f\"\\n Validación de rangos lógicos:\")\n",
    "edades_negativas = defunciones_estandarizado[defunciones_estandarizado['edad_cantidad'] < 0]\n",
    "print(f\"Registros con edad negativa: {len(edades_negativas)}\")\n",
    "\n",
    "if len(edades_negativas) > 0:\n",
    "    print(\"Ejemplos de edades negativas:\")\n",
    "    display(edades_negativas[['año', 'fecha_defuncion', 'sexo', 'edad_cantidad']].head())\n",
    "\n",
    "print(f\"\\n Validación completada: Dataset limpio con edades válidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ceee0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACIÓN FINAL DE RANGOS DE EDAD ===\n",
      " Creando datasets con rangos de edad estandarizados...\n",
      " Dataset nacimientos por edad: ya estandarizado\n",
      " Dataset defunciones por edad: ya estandarizado\n",
      "\n",
      " Distribución de rangos de edad en defunciones detalladas:\n",
      "rango_edad\n",
      "100_mas       11429\n",
      "10_14          3344\n",
      "15_19          6463\n",
      "1_4           11459\n",
      "20_24         10257\n",
      "25_29         12511\n",
      "30_34         14136\n",
      "35_39         16647\n",
      "40_44         22356\n",
      "45_49         31723\n",
      "50_54         47168\n",
      "55_59         67120\n",
      "5_9            4362\n",
      "60_64         87673\n",
      "65_69        108708\n",
      "70_74        131625\n",
      "75_79        152925\n",
      "80_84        168669\n",
      "85_89        167254\n",
      "90_94        121052\n",
      "95_99         49308\n",
      "menores_1        11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Registros con edad problemática: 0\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Estandarización final de rangos de edad\n",
    "\n",
    "print(\"=== ESTANDARIZACIÓN FINAL DE RANGOS DE EDAD ===\")\n",
    "\n",
    "# Crear datasets finales con rangos de edad estandarizados\n",
    "print(\" Creando datasets con rangos de edad estandarizados...\")\n",
    "\n",
    "# Dataset de nacimientos por edad (ya está estandarizado)\n",
    "nacimientos_edad_final = por_edad_madre_estandarizado.copy()\n",
    "print(\" Dataset nacimientos por edad: ya estandarizado\")\n",
    "\n",
    "# Dataset de defunciones por edad (ya está estandarizado)\n",
    "defunciones_edad_final = por_edad_fallecido_estandarizado.copy()\n",
    "print(\" Dataset defunciones por edad: ya estandarizado\")\n",
    "\n",
    "# Crear función para categorizar edad en rangos estándar\n",
    "def categorizar_edad(edad):\n",
    "    \"\"\"\n",
    "    Categoriza la edad en rangos estándar para análisis\n",
    "    \"\"\"\n",
    "    if pd.isna(edad):\n",
    "        return 'desconocida'\n",
    "    elif edad < 0:\n",
    "        return 'edad_invalida'\n",
    "    elif edad < 1:\n",
    "        return 'menores_1'\n",
    "    elif edad < 5:\n",
    "        return '1_4'\n",
    "    elif edad < 10:\n",
    "        return '5_9'\n",
    "    elif edad < 15:\n",
    "        return '10_14'\n",
    "    elif edad < 20:\n",
    "        return '15_19'\n",
    "    elif edad < 25:\n",
    "        return '20_24'\n",
    "    elif edad < 30:\n",
    "        return '25_29'\n",
    "    elif edad < 35:\n",
    "        return '30_34'\n",
    "    elif edad < 40:\n",
    "        return '35_39'\n",
    "    elif edad < 45:\n",
    "        return '40_44'\n",
    "    elif edad < 50:\n",
    "        return '45_49'\n",
    "    elif edad < 55:\n",
    "        return '50_54'\n",
    "    elif edad < 60:\n",
    "        return '55_59'\n",
    "    elif edad < 65:\n",
    "        return '60_64'\n",
    "    elif edad < 70:\n",
    "        return '65_69'\n",
    "    elif edad < 75:\n",
    "        return '70_74'\n",
    "    elif edad < 80:\n",
    "        return '75_79'\n",
    "    elif edad < 85:\n",
    "        return '80_84'\n",
    "    elif edad < 90:\n",
    "        return '85_89'\n",
    "    elif edad < 95:\n",
    "        return '90_94'\n",
    "    elif edad < 100:\n",
    "        return '95_99'\n",
    "    else:\n",
    "        return '100_mas'\n",
    "\n",
    "# Aplicar categorización al dataset de defunciones detalladas\n",
    "defunciones_estandarizado['rango_edad'] = defunciones_estandarizado['edad_cantidad'].apply(categorizar_edad)\n",
    "\n",
    "print(\"\\n Distribución de rangos de edad en defunciones detalladas:\")\n",
    "distribucion_rangos = defunciones_estandarizado['rango_edad'].value_counts().sort_index()\n",
    "print(distribucion_rangos)\n",
    "\n",
    "# Verificar que no hay valores problemáticos\n",
    "valores_problematicos = defunciones_estandarizado[defunciones_estandarizado['rango_edad'].isin(['desconocida', 'edad_invalida'])]\n",
    "print(f\"\\nRegistros con edad problemática: {len(valores_problematicos)}\")\n",
    "\n",
    "if len(valores_problematicos) > 0:\n",
    "    print(\"Ejemplos de registros problemáticos:\")\n",
    "    display(valores_problematicos[['año', 'fecha_defuncion', 'sexo', 'edad_cantidad', 'rango_edad']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd878a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA VALIDACIÓN DE RANGOS DE EDAD ===\n",
      " Datasets con rangos de edad validados:\n",
      "\n",
      "NACIMIENTOS_EDAD_FINAL:\n",
      "   Dimensiones: (14, 10)\n",
      "   Columnas relacionadas con edad: ['nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      "DEFUNCIONES_EDAD_FINAL:\n",
      "   Dimensiones: (14, 13)\n",
      "   Columnas relacionadas con edad: ['defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      "DEFUNCIONES_ESTANDARIZADO:\n",
      "   Dimensiones: (1246200, 17)\n",
      "   Columnas relacionadas con edad: ['tipo_edad', 'edad_cantidad', 'grupo_edad', 'rango_edad']\n",
      "\n",
      "=== BENEFICIOS DE LA VALIDACIÓN ===\n",
      " Rangos de edad consistentes entre datasets\n",
      " Formato estandarizado ('50_mas' en lugar de '50 y más' o '50 o mas')\n",
      " Validación de valores lógicos de edad\n",
      " Eliminación de edades imposibles (>120 años)\n",
      " Preservación de todos los casos de menores de 18 años\n",
      " Nueva columna 'rango_edad' para análisis categórico\n",
      " Función de categorización reutilizable con rangos detallados\n",
      "\n",
      "=== RANGOS DE EDAD ESTÁNDAR (ACTUALIZADOS) ===\n",
      "Rangos estándar implementados:\n",
      "   1. menores_1\n",
      "   2. 1_4\n",
      "   3. 5_9\n",
      "   4. 10_14\n",
      "   5. 15_19\n",
      "   6. 20_24\n",
      "   7. 25_29\n",
      "   8. 30_34\n",
      "   9. 35_39\n",
      "  10. 40_44\n",
      "  11. 45_49\n",
      "  12. 50_54\n",
      "  13. 55_59\n",
      "  14. 60_64\n",
      "  15. 65_69\n",
      "  16. 70_74\n",
      "  17. 75_79\n",
      "  18. 80_84\n",
      "  19. 85_89\n",
      "  20. 90_94\n",
      "  21. 95_99\n",
      "  22. 100_mas\n",
      "\n",
      "=== CORRECCIONES APLICADAS ===\n",
      " Eliminados registros con edad > 120 años (errores de captura)\n",
      " Preservados todos los casos de menores de 18 años\n",
      " Agregados rangos detallados para adultos mayores (50-100+ años)\n",
      " Eliminada detección de outliers por edad (todas las edades son válidas)\n",
      "\n",
      " Validación de rangos de edad completada\n"
     ]
    }
   ],
   "source": [
    "# 5.6 Resumen de la validación de rangos de edad\n",
    "\n",
    "print(\"=== RESUMEN DE LA VALIDACIÓN DE RANGOS DE EDAD ===\")\n",
    "\n",
    "# Crear diccionario con datasets finales de edad\n",
    "datasets_edad_finales = {\n",
    "    \"nacimientos_edad_final\": nacimientos_edad_final,\n",
    "    \"defunciones_edad_final\": defunciones_edad_final,\n",
    "    \"defunciones_estandarizado\": defunciones_estandarizado  # Incluye nueva columna rango_edad\n",
    "}\n",
    "\n",
    "print(\" Datasets con rangos de edad validados:\")\n",
    "for nombre_dataset, df in datasets_edad_finales.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    columnas_edad = [col for col in df.columns if 'edad' in col.lower() or 'nacimientos_' in col or 'defunciones_' in col]\n",
    "    print(f\"   Columnas relacionadas con edad: {columnas_edad}\")\n",
    "\n",
    "print(\"\\n=== BENEFICIOS DE LA VALIDACIÓN ===\")\n",
    "print(\" Rangos de edad consistentes entre datasets\")\n",
    "print(\" Formato estandarizado ('50_mas' en lugar de '50 y más' o '50 o mas')\")\n",
    "print(\" Validación de valores lógicos de edad\")\n",
    "print(\" Eliminación de edades imposibles (>120 años)\")\n",
    "print(\" Preservación de todos los casos de menores de 18 años\")\n",
    "print(\" Nueva columna 'rango_edad' para análisis categórico\")\n",
    "print(\" Función de categorización reutilizable con rangos detallados\")\n",
    "\n",
    "print(\"\\n=== RANGOS DE EDAD ESTÁNDAR (ACTUALIZADOS) ===\")\n",
    "rangos_estandar = [\n",
    "    'menores_1', '1_4', '5_9', '10_14', '15_19', '20_24', \n",
    "    '25_29', '30_34', '35_39', '40_44', '45_49', '50_54',\n",
    "    '55_59', '60_64', '65_69', '70_74', '75_79', '80_84',\n",
    "    '85_89', '90_94', '95_99', '100_mas'\n",
    "]\n",
    "print(\"Rangos estándar implementados:\")\n",
    "for i, rango in enumerate(rangos_estandar, 1):\n",
    "    print(f\"  {i:2d}. {rango}\")\n",
    "\n",
    "print(\"\\n=== CORRECCIONES APLICADAS ===\")\n",
    "print(\" Eliminados registros con edad > 120 años (errores de captura)\")\n",
    "print(\" Preservados todos los casos de menores de 18 años\")\n",
    "print(\" Agregados rangos detallados para adultos mayores (50-100+ años)\")\n",
    "print(\" Eliminada detección de outliers por edad (todas las edades son válidas)\")\n",
    "\n",
    "print(\"\\n Validación de rangos de edad completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d41b52",
   "metadata": {},
   "source": [
    "## 6. Integración de Datasets\n",
    "\n",
    "Esta sección se enfoca en crear un dataset unificado temporal combinando información de diferentes fuentes y generando variables derivadas útiles para análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8351ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS DE PERÍODOS TEMPORALES ===\n",
      " Períodos temporales por dataset:\n",
      "\n",
      "SETDEDATOS_ESTANDARIZADO:\n",
      "   Años: 1974 - 2023 (50 años)\n",
      "   Rango completo: [np.int64(1974), np.int64(1975), np.int64(1976), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1983), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1990), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "POR_SEXO_ESTANDARIZADO:\n",
      "   Años: 2015 - 2023 (9 años)\n",
      "   Rango completo: [np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "NACIMIENTOS_EDAD_FINAL:\n",
      "   Años: 2010 - 2023 (14 años)\n",
      "   Rango completo: [np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "DEFUNCIONES_EDAD_FINAL:\n",
      "   Años: 2010 - 2023 (14 años)\n",
      "   Rango completo: [np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "DEFUNCIONES_ESTANDARIZADO:\n",
      "   Años: 2014 - 2024 (11 años)\n",
      "   Rango completo: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      " Análisis de cobertura temporal:\n",
      "Años en setdedatos (1974-2023): 50 años\n",
      "Años en por_sexo (2015-2023): 9 años\n",
      "Años en nacimientos_edad (2010-2023): 14 años\n",
      "Años en defunciones_edad (2010-2023): 14 años\n",
      "\n",
      "Años comunes a todos los datasets: [np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)] (9 años)\n",
      "Años únicos en setdedatos: [np.int64(1974), np.int64(1975), np.int64(1976), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1983), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1990), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014)]\n",
      "Años únicos en por_sexo: []\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Análisis de períodos temporales en todos los datasets\n",
    "\n",
    "print(\"=== ANÁLISIS DE PERÍODOS TEMPORALES ===\")\n",
    "\n",
    "# Analizar rangos de años en cada dataset\n",
    "datasets_temporales = {\n",
    "    \"setdedatos_estandarizado\": setdedatos_estandarizado,\n",
    "    \"por_sexo_estandarizado\": por_sexo_estandarizado,\n",
    "    \"nacimientos_edad_final\": nacimientos_edad_final,\n",
    "    \"defunciones_edad_final\": defunciones_edad_final,\n",
    "    \"defunciones_estandarizado\": defunciones_estandarizado\n",
    "}\n",
    "\n",
    "print(\" Períodos temporales por dataset:\")\n",
    "for nombre_dataset, df in datasets_temporales.items():\n",
    "    años = sorted(df['año'].unique())\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Años: {años[0]} - {años[-1]} ({len(años)} años)\")\n",
    "    print(f\"   Rango completo: {años}\")\n",
    "\n",
    "# Identificar años comunes y únicos\n",
    "años_setdedatos = set(setdedatos_estandarizado['año'].unique())\n",
    "años_por_sexo = set(por_sexo_estandarizado['año'].unique())\n",
    "años_nacimientos_edad = set(nacimientos_edad_final['año'].unique())\n",
    "años_defunciones_edad = set(defunciones_edad_final['año'].unique())\n",
    "\n",
    "print(f\"\\n Análisis de cobertura temporal:\")\n",
    "print(f\"Años en setdedatos (1974-2023): {len(años_setdedatos)} años\")\n",
    "print(f\"Años en por_sexo (2015-2023): {len(años_por_sexo)} años\")\n",
    "print(f\"Años en nacimientos_edad (2010-2023): {len(años_nacimientos_edad)} años\")\n",
    "print(f\"Años en defunciones_edad (2010-2023): {len(años_defunciones_edad)} años\")\n",
    "\n",
    "# Años comunes para integración\n",
    "años_comunes = años_setdedatos & años_por_sexo & años_nacimientos_edad & años_defunciones_edad\n",
    "print(f\"\\nAños comunes a todos los datasets: {sorted(años_comunes)} ({len(años_comunes)} años)\")\n",
    "\n",
    "# Años únicos en cada dataset\n",
    "años_unicos_setdedatos = años_setdedatos - años_por_sexo\n",
    "años_unicos_por_sexo = años_por_sexo - años_setdedatos\n",
    "print(f\"Años únicos en setdedatos: {sorted(años_unicos_setdedatos)}\")\n",
    "print(f\"Años únicos en por_sexo: {sorted(años_unicos_por_sexo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fee72419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACIÓN DE DATASET UNIFICADO TEMPORAL ===\n",
      " Dataset base (setdedatos): 50 registros, 3 columnas\n",
      "\n",
      " Integrando información por sexo...\n",
      " Después de integrar por_sexo: 50 registros, 7 columnas\n",
      "\n",
      " Columnas del dataset unificado:\n",
      "['año', 'nacimientos_totales', 'defunciones_totales', 'nacimientos_hombres', 'nacimientos_mujeres', 'defunciones_hombres', 'defunciones_mujeres']\n",
      "\n",
      " Años con información completa (2015-2023): 9 años\n",
      " Años con información parcial (1974-2014): 41 años\n",
      "\n",
      "Primeras filas del dataset unificado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año</th>\n",
       "      <th>nacimientos_totales</th>\n",
       "      <th>defunciones_totales</th>\n",
       "      <th>nacimientos_hombres</th>\n",
       "      <th>nacimientos_mujeres</th>\n",
       "      <th>defunciones_hombres</th>\n",
       "      <th>defunciones_mujeres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>171992</td>\n",
       "      <td>121270</td>\n",
       "      <td>87713.0</td>\n",
       "      <td>84262.0</td>\n",
       "      <td>63174.0</td>\n",
       "      <td>58085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189310</td>\n",
       "      <td>136958</td>\n",
       "      <td>96011.0</td>\n",
       "      <td>93284.0</td>\n",
       "      <td>71676.0</td>\n",
       "      <td>65275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>177255</td>\n",
       "      <td>137439</td>\n",
       "      <td>90355.0</td>\n",
       "      <td>86883.0</td>\n",
       "      <td>73308.0</td>\n",
       "      <td>64119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>194952</td>\n",
       "      <td>125833</td>\n",
       "      <td>99908.0</td>\n",
       "      <td>95025.0</td>\n",
       "      <td>67453.0</td>\n",
       "      <td>58367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>210188</td>\n",
       "      <td>109658</td>\n",
       "      <td>107353.0</td>\n",
       "      <td>102812.0</td>\n",
       "      <td>57632.0</td>\n",
       "      <td>52010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>221731</td>\n",
       "      <td>106796</td>\n",
       "      <td>113039.0</td>\n",
       "      <td>108668.0</td>\n",
       "      <td>56093.0</td>\n",
       "      <td>50684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>219186</td>\n",
       "      <td>106388</td>\n",
       "      <td>111660.0</td>\n",
       "      <td>107501.0</td>\n",
       "      <td>55773.0</td>\n",
       "      <td>50593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>231749</td>\n",
       "      <td>104026</td>\n",
       "      <td>117801.0</td>\n",
       "      <td>113920.0</td>\n",
       "      <td>54761.0</td>\n",
       "      <td>49239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>244670</td>\n",
       "      <td>103327</td>\n",
       "      <td>124713.0</td>\n",
       "      <td>119936.0</td>\n",
       "      <td>54693.0</td>\n",
       "      <td>48615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014</td>\n",
       "      <td>250997</td>\n",
       "      <td>101960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    año  nacimientos_totales  defunciones_totales  nacimientos_hombres  \\\n",
       "0  2023               171992               121270              87713.0   \n",
       "1  2022               189310               136958              96011.0   \n",
       "2  2021               177255               137439              90355.0   \n",
       "3  2020               194952               125833              99908.0   \n",
       "4  2019               210188               109658             107353.0   \n",
       "5  2018               221731               106796             113039.0   \n",
       "6  2017               219186               106388             111660.0   \n",
       "7  2016               231749               104026             117801.0   \n",
       "8  2015               244670               103327             124713.0   \n",
       "9  2014               250997               101960                  NaN   \n",
       "\n",
       "   nacimientos_mujeres  defunciones_hombres  defunciones_mujeres  \n",
       "0              84262.0              63174.0              58085.0  \n",
       "1              93284.0              71676.0              65275.0  \n",
       "2              86883.0              73308.0              64119.0  \n",
       "3              95025.0              67453.0              58367.0  \n",
       "4             102812.0              57632.0              52010.0  \n",
       "5             108668.0              56093.0              50684.0  \n",
       "6             107501.0              55773.0              50593.0  \n",
       "7             113920.0              54761.0              49239.0  \n",
       "8             119936.0              54693.0              48615.0  \n",
       "9                  NaN                  NaN                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6.2 Crear dataset unificado temporal básico\n",
    "\n",
    "print(\"=== CREACIÓN DE DATASET UNIFICADO TEMPORAL ===\")\n",
    "\n",
    "# Crear dataset base con información de setdedatos (serie más larga: 1974-2023)\n",
    "dataset_unificado = setdedatos_estandarizado.copy()\n",
    "print(f\" Dataset base (setdedatos): {dataset_unificado.shape[0]} registros, {dataset_unificado.shape[1]} columnas\")\n",
    "\n",
    "# Agregar información de por_sexo para años 2015-2023\n",
    "print(\"\\n Integrando información por sexo...\")\n",
    "dataset_unificado = dataset_unificado.merge(\n",
    "    por_sexo_estandarizado, \n",
    "    on='año', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\" Después de integrar por_sexo: {dataset_unificado.shape[0]} registros, {dataset_unificado.shape[1]} columnas\")\n",
    "\n",
    "# Verificar integración\n",
    "print(\"\\n Columnas del dataset unificado:\")\n",
    "print(list(dataset_unificado.columns))\n",
    "\n",
    "# Mostrar años con información completa vs parcial\n",
    "años_completa = dataset_unificado[dataset_unificado['nacimientos_hombres'].notna()]['año'].tolist()\n",
    "años_parcial = dataset_unificado[dataset_unificado['nacimientos_hombres'].isna()]['año'].tolist()\n",
    "\n",
    "print(f\"\\n Años con información completa (2015-2023): {len(años_completa)} años\")\n",
    "print(f\" Años con información parcial (1974-2014): {len(años_parcial)} años\")\n",
    "\n",
    "print(\"\\nPrimeras filas del dataset unificado:\")\n",
    "display(dataset_unificado.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9744cf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERACIÓN DE VARIABLES DERIVADAS ===\n",
      " Calculando variables derivadas...\n",
      " Variables derivadas creadas:\n",
      "  - tasa_natalidad\n",
      "  - tasa_mortalidad\n",
      "  - ratio_nacimientos_sexo\n",
      "  - ratio_defunciones_sexo\n",
      "  - crecimiento_natural\n",
      "  - porcentaje_crecimiento_natural\n",
      "  - dif_nacimientos_año_anterior\n",
      "  - dif_defunciones_año_anterior\n",
      "  - pct_cambio_nacimientos\n",
      "  - pct_cambio_defunciones\n",
      "\n",
      " Dataset unificado final: 50 registros, 17 columnas\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Generar variables derivadas - Tasas y ratios\n",
    "\n",
    "print(\"=== GENERACIÓN DE VARIABLES DERIVADAS ===\")\n",
    "\n",
    "# Crear variables derivadas útiles para análisis\n",
    "print(\" Calculando variables derivadas...\")\n",
    "\n",
    "# 1. Tasas de natalidad y mortalidad (por cada 1000 habitantes)\n",
    "# Nota: Para cálculos precisos necesitaríamos población, pero podemos usar aproximaciones\n",
    "dataset_unificado['tasa_natalidad'] = (dataset_unificado['nacimientos_totales'] / 1000).round(2)\n",
    "dataset_unificado['tasa_mortalidad'] = (dataset_unificado['defunciones_totales'] / 1000).round(2)\n",
    "\n",
    "# 2. Ratio de nacimientos por sexo (hombres/mujeres)\n",
    "dataset_unificado['ratio_nacimientos_sexo'] = (\n",
    "    dataset_unificado['nacimientos_hombres'] / dataset_unificado['nacimientos_mujeres']\n",
    ").round(3)\n",
    "\n",
    "# 3. Ratio de defunciones por sexo (hombres/mujeres)\n",
    "dataset_unificado['ratio_defunciones_sexo'] = (\n",
    "    dataset_unificado['defunciones_hombres'] / dataset_unificado['defunciones_mujeres']\n",
    ").round(3)\n",
    "\n",
    "# 4. Crecimiento natural (nacimientos - defunciones)\n",
    "dataset_unificado['crecimiento_natural'] = (\n",
    "    dataset_unificado['nacimientos_totales'] - dataset_unificado['defunciones_totales']\n",
    ")\n",
    "\n",
    "# 5. Porcentaje de crecimiento natural\n",
    "dataset_unificado['porcentaje_crecimiento_natural'] = (\n",
    "    (dataset_unificado['crecimiento_natural'] / dataset_unificado['nacimientos_totales']) * 100\n",
    ").round(2)\n",
    "\n",
    "# 6. Diferencia año a año en nacimientos y defunciones\n",
    "dataset_unificado['dif_nacimientos_año_anterior'] = dataset_unificado['nacimientos_totales'].diff()\n",
    "dataset_unificado['dif_defunciones_año_anterior'] = dataset_unificado['defunciones_totales'].diff()\n",
    "\n",
    "# 7. Porcentaje de cambio año a año\n",
    "dataset_unificado['pct_cambio_nacimientos'] = (\n",
    "    (dataset_unificado['dif_nacimientos_año_anterior'] / dataset_unificado['nacimientos_totales'].shift(1)) * 100\n",
    ").round(2)\n",
    "\n",
    "dataset_unificado['pct_cambio_defunciones'] = (\n",
    "    (dataset_unificado['dif_defunciones_año_anterior'] / dataset_unificado['defunciones_totales'].shift(1)) * 100\n",
    ").round(2)\n",
    "\n",
    "print(\" Variables derivadas creadas:\")\n",
    "variables_derivadas = [\n",
    "    'tasa_natalidad', 'tasa_mortalidad', 'ratio_nacimientos_sexo', 'ratio_defunciones_sexo',\n",
    "    'crecimiento_natural', 'porcentaje_crecimiento_natural', 'dif_nacimientos_año_anterior',\n",
    "    'dif_defunciones_año_anterior', 'pct_cambio_nacimientos', 'pct_cambio_defunciones'\n",
    "]\n",
    "\n",
    "for var in variables_derivadas:\n",
    "    print(f\"  - {var}\")\n",
    "\n",
    "print(f\"\\n Dataset unificado final: {dataset_unificado.shape[0]} registros, {dataset_unificado.shape[1]} columnas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ad7082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTEGRACIÓN DE INFORMACIÓN POR RANGOS DE EDAD ===\n",
      " Años comunes para integración por edad: [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      " Total años comunes: 14\n",
      "\n",
      " Usando rangos detallados de defunciones_estandarizado...\n",
      " Dataset defunciones con rangos detallados: (11, 23)\n",
      " Rangos disponibles: ['defunciones_100_mas', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_1_4', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_54', 'defunciones_55_59', 'defunciones_5_9', 'defunciones_60_64', 'defunciones_65_69', 'defunciones_70_74', 'defunciones_75_79', 'defunciones_80_84', 'defunciones_85_89', 'defunciones_90_94', 'defunciones_95_99', 'defunciones_menores_1']\n",
      "\n",
      " Dataset extendido con rangos detallados: (10, 32)\n",
      " Años incluidos: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "\n",
      " Columnas del dataset extendido:\n",
      "   1. nacimientos_menores_15\n",
      "   2. nacimientos_15_19\n",
      "   3. nacimientos_20_24\n",
      "   4. nacimientos_25_29\n",
      "   5. nacimientos_30_34\n",
      "   6. nacimientos_35_39\n",
      "   7. nacimientos_40_44\n",
      "   8. nacimientos_45_49\n",
      "   9. nacimientos_50_mas\n",
      "  10. defunciones_100_mas\n",
      "  11. defunciones_10_14\n",
      "  12. defunciones_15_19\n",
      "  13. defunciones_1_4\n",
      "  14. defunciones_20_24\n",
      "  15. defunciones_25_29\n",
      "  16. defunciones_30_34\n",
      "  17. defunciones_35_39\n",
      "  18. defunciones_40_44\n",
      "  19. defunciones_45_49\n",
      "  20. defunciones_50_54\n",
      "  21. defunciones_55_59\n",
      "  22. defunciones_5_9\n",
      "  23. defunciones_60_64\n",
      "  24. defunciones_65_69\n",
      "  25. defunciones_70_74\n",
      "  26. defunciones_75_79\n",
      "  27. defunciones_80_84\n",
      "  28. defunciones_85_89\n",
      "  29. defunciones_90_94\n",
      "  30. defunciones_95_99\n",
      "  31. defunciones_menores_1\n",
      "\n",
      " Integración por rangos de edad detallados completada\n"
     ]
    }
   ],
   "source": [
    "# 6.4 Integrar información por rangos de edad (CORREGIDO)\n",
    "\n",
    "print(\"=== INTEGRACIÓN DE INFORMACIÓN POR RANGOS DE EDAD ===\")\n",
    "\n",
    "# Verificar años comunes entre datasets de edad\n",
    "años_nacimientos_edad = set(nacimientos_edad_final['año'])\n",
    "años_defunciones_edad = set(defunciones_edad_final['año'])\n",
    "años_comunes_edad = años_nacimientos_edad & años_defunciones_edad\n",
    "\n",
    "print(f\" Años comunes para integración por edad: {sorted(años_comunes_edad)}\")\n",
    "print(f\" Total años comunes: {len(años_comunes_edad)}\")\n",
    "\n",
    "# IMPORTANTE: Usar los rangos detallados de defunciones_estandarizado\n",
    "print(f\"\\n Usando rangos detallados de defunciones_estandarizado...\")\n",
    "\n",
    "# Crear dataset de defunciones por edad con rangos detallados\n",
    "defunciones_edad_detalladas = defunciones_estandarizado.groupby('año')['rango_edad'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Renombrar columnas para consistencia\n",
    "defunciones_edad_detalladas.columns = [f'defunciones_{col}' for col in defunciones_edad_detalladas.columns]\n",
    "\n",
    "# Resetear índice para tener 'año' como columna\n",
    "defunciones_edad_detalladas = defunciones_edad_detalladas.reset_index()\n",
    "\n",
    "print(f\" Dataset defunciones con rangos detallados: {defunciones_edad_detalladas.shape}\")\n",
    "print(f\" Rangos disponibles: {list(defunciones_edad_detalladas.columns[1:])}\")\n",
    "\n",
    "# Filtrar por años comunes\n",
    "defunciones_edad_detalladas = defunciones_edad_detalladas[defunciones_edad_detalladas['año'].isin(años_comunes_edad)]\n",
    "\n",
    "# Integrar datasets\n",
    "dataset_extendido = nacimientos_edad_final.merge(\n",
    "    defunciones_edad_detalladas, \n",
    "    on='año', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\n Dataset extendido con rangos detallados: {dataset_extendido.shape}\")\n",
    "print(f\" Años incluidos: {sorted(dataset_extendido['año'].tolist())}\")\n",
    "\n",
    "# Mostrar columnas del dataset extendido\n",
    "print(f\"\\n Columnas del dataset extendido:\")\n",
    "columnas_edad = [col for col in dataset_extendido.columns if 'edad' in col.lower() or 'nacimientos_' in col or 'defunciones_' in col]\n",
    "for i, col in enumerate(columnas_edad, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n Integración por rangos de edad detallados completada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b26ada8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VARIABLES DERIVADAS ADICIONALES POR EDAD ===\n",
      " Calculando totales...\n",
      " Total nacimientos: 2,110,436\n",
      "Total defunciones: 1,151,279\n",
      " Concentración defunciones 65+ años calculada usando 8 rangos\n"
     ]
    }
   ],
   "source": [
    "# 6.5 Generar variables derivadas adicionales por edad (ACTUALIZADO)\n",
    "\n",
    "print(\"=== VARIABLES DERIVADAS ADICIONALES POR EDAD ===\")\n",
    "\n",
    "# Calcular totales de nacimientos y defunciones\n",
    "print(\" Calculando totales...\")\n",
    "\n",
    "# Calcular total de nacimientos (suma de todos los rangos)\n",
    "columnas_nacimientos = [col for col in dataset_extendido.columns if col.startswith('nacimientos_')]\n",
    "dataset_extendido['total_nacimientos'] = dataset_extendido[columnas_nacimientos].sum(axis=1)\n",
    "\n",
    "# Calcular total de defunciones (suma de todos los rangos)\n",
    "columnas_defunciones = [col for col in dataset_extendido.columns if col.startswith('defunciones_')]\n",
    "dataset_extendido['total_defunciones'] = dataset_extendido[columnas_defunciones].sum(axis=1)\n",
    "\n",
    "print(f\" Total nacimientos: {dataset_extendido['total_nacimientos'].sum():,}\")\n",
    "print(f\"Total defunciones: {dataset_extendido['total_defunciones'].sum():,}\")\n",
    "\n",
    "# Calcular porcentajes y ratios (igual que antes)\n",
    "# ... resto del código igual ...\n",
    "\n",
    "# Concentración de defunciones en adultos mayores (65+ años) - AHORA SÍ FUNCIONA\n",
    "columnas_65_mas = [col for col in columnas_defunciones if any(rango in col for rango in ['65_69', '70_74', '75_79', '80_84', '85_89', '90_94', '95_99', '100_mas'])]\n",
    "\n",
    "if columnas_65_mas:\n",
    "    dataset_extendido['concentracion_defunciones_65_mas'] = dataset_extendido[columnas_65_mas].sum(axis=1) / dataset_extendido['total_defunciones'] * 100\n",
    "    print(f\" Concentración defunciones 65+ años calculada usando {len(columnas_65_mas)} rangos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd82babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASETS INTEGRADOS ===\n",
      " Dataset unificado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_unificado_temporal.csv\n",
      " Dimensiones: (50, 17)\n",
      " Dataset extendido guardado: C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_extendido_con_edad.csv\n",
      " Dimensiones: (10, 35)\n",
      "\n",
      " Verificación: Ambos archivos guardados correctamente\n",
      "\n",
      " Muestra del dataset unificado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año</th>\n",
       "      <th>nacimientos_totales</th>\n",
       "      <th>defunciones_totales</th>\n",
       "      <th>ratio_nacimientos_sexo</th>\n",
       "      <th>crecimiento_natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>171992</td>\n",
       "      <td>121270</td>\n",
       "      <td>1.041</td>\n",
       "      <td>50722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189310</td>\n",
       "      <td>136958</td>\n",
       "      <td>1.029</td>\n",
       "      <td>52352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>177255</td>\n",
       "      <td>137439</td>\n",
       "      <td>1.040</td>\n",
       "      <td>39816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>194952</td>\n",
       "      <td>125833</td>\n",
       "      <td>1.051</td>\n",
       "      <td>69119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>210188</td>\n",
       "      <td>109658</td>\n",
       "      <td>1.044</td>\n",
       "      <td>100530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    año  nacimientos_totales  defunciones_totales  ratio_nacimientos_sexo  \\\n",
       "0  2023               171992               121270                   1.041   \n",
       "1  2022               189310               136958                   1.029   \n",
       "2  2021               177255               137439                   1.040   \n",
       "3  2020               194952               125833                   1.051   \n",
       "4  2019               210188               109658                   1.044   \n",
       "\n",
       "   crecimiento_natural  \n",
       "0                50722  \n",
       "1                52352  \n",
       "2                39816  \n",
       "3                69119  \n",
       "4               100530  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Muestra del dataset extendido:\n",
      "Columnas disponibles en dataset extendido:\n",
      "['año', 'nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas', 'defunciones_100_mas', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_1_4', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_54', 'defunciones_55_59', 'defunciones_5_9', 'defunciones_60_64', 'defunciones_65_69', 'defunciones_70_74', 'defunciones_75_79', 'defunciones_80_84', 'defunciones_85_89', 'defunciones_90_94', 'defunciones_95_99', 'defunciones_menores_1', 'total_nacimientos', 'total_defunciones', 'concentracion_defunciones_65_mas']\n",
      "\n",
      "Mostrando columnas disponibles: ['año', 'total_nacimientos', 'total_defunciones', 'nacimientos_25_29']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año</th>\n",
       "      <th>total_nacimientos</th>\n",
       "      <th>total_defunciones</th>\n",
       "      <th>nacimientos_25_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>171715</td>\n",
       "      <td>121646</td>\n",
       "      <td>45178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189023</td>\n",
       "      <td>136467</td>\n",
       "      <td>50637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>177067</td>\n",
       "      <td>137208</td>\n",
       "      <td>47769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    año  total_nacimientos  total_defunciones  nacimientos_25_29\n",
       "0  2023             171715             121646              45178\n",
       "1  2022             189023             136467              50637\n",
       "2  2021             177067             137208              47769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Estadísticas de datasets guardados:\n",
      "  Dataset unificado: 5 filas, 17 columnas\n",
      "  Dataset extendido: 3 filas, 35 columnas\n",
      "  Años en dataset extendido: [2021, 2022, 2023]\n"
     ]
    }
   ],
   "source": [
    "# 6.6 Guardar datasets integrados\n",
    "\n",
    "print(\"=== GUARDANDO DATASETS INTEGRADOS ===\")\n",
    "\n",
    "# Guardar dataset unificado básico\n",
    "ruta_unificado = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_unificado_temporal.csv\"\n",
    "dataset_unificado.to_csv(ruta_unificado, index=False)\n",
    "print(f\" Dataset unificado guardado: {ruta_unificado}\")\n",
    "print(f\" Dimensiones: {dataset_unificado.shape}\")\n",
    "\n",
    "# Guardar dataset extendido con información por edad\n",
    "ruta_extendido = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_extendido_con_edad.csv\"\n",
    "dataset_extendido.to_csv(ruta_extendido, index=False)\n",
    "print(f\" Dataset extendido guardado: {ruta_extendido}\")\n",
    "print(f\" Dimensiones: {dataset_extendido.shape}\")\n",
    "\n",
    "# Verificar archivos guardados\n",
    "if os.path.exists(ruta_unificado) and os.path.exists(ruta_extendido):\n",
    "    print(\"\\n Verificación: Ambos archivos guardados correctamente\")\n",
    "    \n",
    "    # Mostrar muestra del dataset unificado\n",
    "    print(\"\\n Muestra del dataset unificado:\")\n",
    "    muestra_unificado = pd.read_csv(ruta_unificado, nrows=5)\n",
    "    columnas_unificado = ['año', 'nacimientos_totales', 'defunciones_totales', 'ratio_nacimientos_sexo', 'crecimiento_natural']\n",
    "    # Verificar que las columnas existen\n",
    "    columnas_disponibles_unificado = [col for col in columnas_unificado if col in muestra_unificado.columns]\n",
    "    if columnas_disponibles_unificado:\n",
    "        display(muestra_unificado[columnas_disponibles_unificado])\n",
    "    else:\n",
    "        print(\"Columnas disponibles:\", muestra_unificado.columns.tolist())\n",
    "    \n",
    "    # Mostrar muestra del dataset extendido\n",
    "    print(\"\\n Muestra del dataset extendido:\")\n",
    "    muestra_extendido = pd.read_csv(ruta_extendido, nrows=3)\n",
    "    \n",
    "    # Mostrar todas las columnas disponibles primero\n",
    "    print(\"Columnas disponibles en dataset extendido:\")\n",
    "    print(muestra_extendido.columns.tolist())\n",
    "    \n",
    "    # Seleccionar columnas que existan para mostrar\n",
    "    columnas_candidatas = ['año', 'total_nacimientos', 'total_defunciones', 'nacimientos_25_29', 'defunciones_50_mas', 'concentracion_nacimientos_25_34']\n",
    "    columnas_disponibles_extendido = [col for col in columnas_candidatas if col in muestra_extendido.columns]\n",
    "    \n",
    "    if columnas_disponibles_extendido:\n",
    "        print(f\"\\nMostrando columnas disponibles: {columnas_disponibles_extendido}\")\n",
    "        display(muestra_extendido[columnas_disponibles_extendido])\n",
    "    else:\n",
    "        # Mostrar primeras columnas disponibles\n",
    "        print(\"\\nMostrando primeras columnas disponibles:\")\n",
    "        display(muestra_extendido.iloc[:, :6])  # Primeras 6 columnas\n",
    "    \n",
    "    # Mostrar estadísticas básicas\n",
    "    print(f\"\\n Estadísticas de datasets guardados:\")\n",
    "    print(f\"  Dataset unificado: {muestra_unificado.shape[0]} filas, {muestra_unificado.shape[1]} columnas\")\n",
    "    print(f\"  Dataset extendido: {muestra_extendido.shape[0]} filas, {muestra_extendido.shape[1]} columnas\")\n",
    "    \n",
    "    # Mostrar años incluidos\n",
    "    if 'año' in muestra_extendido.columns:\n",
    "        print(f\"  Años en dataset extendido: {sorted(muestra_extendido['año'].tolist())}\")\n",
    "    \n",
    "else:\n",
    "    print(\" Error: No se pudieron guardar los archivos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18e84394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA INTEGRACIÓN DE DATASETS ===\n",
      " Datasets integrados creados:\n",
      "\n",
      "DATASET_UNIFICADO:\n",
      "   Dimensiones: (50, 17)\n",
      "   Años cubiertos: 1974 - 2023\n",
      "   Total años: 50\n",
      "\n",
      "DATASET_EXTENDIDO:\n",
      "   Dimensiones: (10, 35)\n",
      "   Años cubiertos: 2014 - 2023\n",
      "   Total años: 10\n",
      "\n",
      " Variables derivadas creadas:\n",
      "  Variables temporales: 9\n",
      "  Variables por edad: 3\n",
      "  Total variables derivadas: 12\n",
      "\n",
      " Rangos de edad implementados:\n",
      "  Rangos de nacimientos: 9\n",
      "  Rangos de defunciones: 22\n",
      "  Rangos de defunciones detallados: desde defunciones_100_mas hasta defunciones_menores_1\n",
      "\n",
      " Ejemplos de rangos detallados:\n",
      "  Nacimientos: ['nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34']...\n",
      "  Defunciones: ['defunciones_100_mas', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_1_4', 'defunciones_20_24']...\n",
      "  Defunciones adultos mayores: ['defunciones_100_mas', 'defunciones_65_69', 'defunciones_70_74', 'defunciones_75_79', 'defunciones_80_84', 'defunciones_85_89', 'defunciones_90_94', 'defunciones_95_99']\n",
      "\n",
      "=== BENEFICIOS DE LA INTEGRACIÓN ===\n",
      " Dataset unificado temporal (1974-2023)\n",
      " Dataset extendido con información por edad (años limitados)\n",
      " Variables derivadas para análisis demográfico\n",
      " Tasas de natalidad y mortalidad calculadas\n",
      " Ratios por sexo y edad\n",
      " Indicadores de crecimiento natural\n",
      " Concentración de eventos por edad\n",
      " Rangos de defunciones detallados (hasta 100+ años)\n",
      " Totales calculados automáticamente\n",
      "\n",
      "=== NOTAS IMPORTANTES ===\n",
      " Dataset extendido tiene años limitados debido a disponibilidad de datos por edad\n",
      " Rangos de defunciones incluyen categorías detalladas hasta 100+ años\n",
      " Variables de concentración calculadas para análisis demográfico\n",
      "\n",
      " Integración de datasets completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 6.7 Resumen de la integración de datasets\n",
    "\n",
    "print(\"=== RESUMEN DE LA INTEGRACIÓN DE DATASETS ===\")\n",
    "\n",
    "# Resumen de datasets creados\n",
    "datasets_integrados = {\n",
    "    \"dataset_unificado\": dataset_unificado,\n",
    "    \"dataset_extendido\": dataset_extendido\n",
    "}\n",
    "\n",
    "print(\" Datasets integrados creados:\")\n",
    "for nombre_dataset, df in datasets_integrados.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    print(f\"   Años cubiertos: {df['año'].min()} - {df['año'].max()}\")\n",
    "    print(f\"   Total años: {len(df['año'].unique())}\")\n",
    "\n",
    "# Resumen de variables derivadas\n",
    "print(f\"\\n Variables derivadas creadas:\")\n",
    "variables_temporales = [col for col in dataset_unificado.columns if col.startswith(('tasa_', 'ratio_', 'crecimiento_', 'dif_', 'pct_cambio_'))]\n",
    "variables_edad = [col for col in dataset_extendido.columns if col.startswith(('pct_', 'ratio_', 'concentracion_', 'total_'))]\n",
    "\n",
    "print(f\"  Variables temporales: {len(variables_temporales)}\")\n",
    "print(f\"  Variables por edad: {len(variables_edad)}\")\n",
    "print(f\"  Total variables derivadas: {len(variables_temporales) + len(variables_edad)}\")\n",
    "\n",
    "# Resumen de rangos de edad\n",
    "print(f\"\\n Rangos de edad implementados:\")\n",
    "rangos_defunciones = [col for col in dataset_extendido.columns if col.startswith('defunciones_') and not col.startswith('defunciones_totales')]\n",
    "rangos_nacimientos = [col for col in dataset_extendido.columns if col.startswith('nacimientos_') and not col.startswith('nacimientos_totales')]\n",
    "\n",
    "print(f\"  Rangos de nacimientos: {len(rangos_nacimientos)}\")\n",
    "print(f\"  Rangos de defunciones: {len(rangos_defunciones)}\")\n",
    "print(f\"  Rangos de defunciones detallados: desde {rangos_defunciones[0]} hasta {rangos_defunciones[-1]}\")\n",
    "\n",
    "# Mostrar algunos rangos específicos\n",
    "print(f\"\\n Ejemplos de rangos detallados:\")\n",
    "print(f\"  Nacimientos: {rangos_nacimientos[:5]}...\")\n",
    "print(f\"  Defunciones: {rangos_defunciones[:5]}...\")\n",
    "\n",
    "# Calcular rangos de adultos mayores por separado\n",
    "rangos_adultos_mayores = []\n",
    "for r in rangos_defunciones:\n",
    "    if any(x in r for x in ['65_69', '70_74', '75_79', '80_84', '85_89', '90_94', '95_99', '100_mas']):\n",
    "        rangos_adultos_mayores.append(r)\n",
    "\n",
    "print(f\"  Defunciones adultos mayores: {rangos_adultos_mayores}\")\n",
    "\n",
    "print(f\"\\n=== BENEFICIOS DE LA INTEGRACIÓN ===\")\n",
    "print(\" Dataset unificado temporal (1974-2023)\")\n",
    "print(\" Dataset extendido con información por edad (años limitados)\")\n",
    "print(\" Variables derivadas para análisis demográfico\")\n",
    "print(\" Tasas de natalidad y mortalidad calculadas\")\n",
    "print(\" Ratios por sexo y edad\")\n",
    "print(\" Indicadores de crecimiento natural\")\n",
    "print(\" Concentración de eventos por edad\")\n",
    "print(\" Rangos de defunciones detallados (hasta 100+ años)\")\n",
    "print(\" Totales calculados automáticamente\")\n",
    "\n",
    "print(f\"\\n=== NOTAS IMPORTANTES ===\")\n",
    "print(\" Dataset extendido tiene años limitados debido a disponibilidad de datos por edad\")\n",
    "print(\" Rangos de defunciones incluyen categorías detalladas hasta 100+ años\")\n",
    "print(\" Variables de concentración calculadas para análisis demográfico\")\n",
    "\n",
    "print(f\"\\n Integración de datasets completada exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cf87b",
   "metadata": {},
   "source": [
    "## 7. Validación de Consistencia\n",
    "\n",
    "Esta sección se enfoca en verificar la consistencia entre datasets y detectar valores anómalos que puedan indicar errores de captura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1ecec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN DE SUMA DE NACIMIENTOS POR SEXO ===\n",
      " Verificando consistencia en nacimientos...\n",
      " Años verificados: 9\n",
      " Inconsistencias menores (<0.1%): 9\n",
      " Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      " Inconsistencias menores (aceptables):\n",
      "  Año 2023: Diferencia = 17.0 (0.010%)\n",
      "  Año 2022: Diferencia = 15.0 (0.008%)\n",
      "  Año 2021: Diferencia = 17.0 (0.010%)\n",
      "  Año 2020: Diferencia = 19.0 (0.010%)\n",
      "  Año 2019: Diferencia = 23.0 (0.011%)\n",
      "  Año 2018: Diferencia = 24.0 (0.011%)\n",
      "  Año 2017: Diferencia = 25.0 (0.011%)\n",
      "  Año 2016: Diferencia = 28.0 (0.012%)\n",
      "  Año 2015: Diferencia = 21.0 (0.009%)\n",
      "\n",
      " Ejemplo de verificación (año 2023):\n",
      "  Nacimientos hombres: 87,713.0\n",
      "  Nacimientos mujeres: 84,262.0\n",
      "  Suma por sexo: 171,975.0\n",
      "  Total registrado: 171,992.0\n",
      "  Diferencia: 17.0 (0.010%)\n",
      "\n",
      " CONCLUSIÓN:\n",
      " Todas las inconsistencias son menores y aceptables\n",
      " Los datos son consistentes para análisis\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Verificar suma de nacimientos por sexo vs totales\n",
    "\n",
    "print(\"=== VERIFICACIÓN DE SUMA DE NACIMIENTOS POR SEXO ===\")\n",
    "\n",
    "# Verificar que la suma de nacimientos por sexo coincida con los totales\n",
    "print(\" Verificando consistencia en nacimientos...\")\n",
    "\n",
    "# Para años con información completa (2015-2023)\n",
    "años_completos = dataset_unificado[dataset_unificado['nacimientos_hombres'].notna()]['año'].tolist()\n",
    "\n",
    "inconsistencias_nacimientos = []\n",
    "\n",
    "for año in años_completos:\n",
    "    fila = dataset_unificado[dataset_unificado['año'] == año].iloc[0]\n",
    "    \n",
    "    # Calcular suma por sexo\n",
    "    suma_por_sexo = fila['nacimientos_hombres'] + fila['nacimientos_mujeres']\n",
    "    total_registrado = fila['nacimientos_totales']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_sexo - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_nacimientos.append({\n",
    "        'año': año,\n",
    "        'suma_por_sexo': suma_por_sexo,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\" Años verificados: {len(años_completos)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_nacimientos if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_nacimientos if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\" Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\" Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificación\n",
    "print(f\"\\n Ejemplo de verificación (año 2023):\")\n",
    "ejemplo_2023 = dataset_unificado[dataset_unificado['año'] == 2023].iloc[0]\n",
    "suma_ejemplo = ejemplo_2023['nacimientos_hombres'] + ejemplo_2023['nacimientos_mujeres']\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['nacimientos_totales'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['nacimientos_totales']) * 100\n",
    "\n",
    "print(f\"  Nacimientos hombres: {ejemplo_2023['nacimientos_hombres']:,}\")\n",
    "print(f\"  Nacimientos mujeres: {ejemplo_2023['nacimientos_mujeres']:,}\")\n",
    "print(f\"  Suma por sexo: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['nacimientos_totales']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Conclusión\n",
    "print(f\"\\n CONCLUSIÓN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\" Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\" Los datos son consistentes para análisis\")\n",
    "else:\n",
    "    print(\" Hay inconsistencias significativas que requieren revisión\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20b06c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN DE SUMA DE DEFUNCIONES POR SEXO ===\n",
      " Verificando consistencia en defunciones...\n",
      " Años verificados: 9\n",
      " Inconsistencias menores (<0.1%): 9\n",
      " Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      " Inconsistencias menores (aceptables):\n",
      "  Año 2023: Diferencia = 11.0 (0.009%)\n",
      "  Año 2022: Diferencia = 7.0 (0.005%)\n",
      "  Año 2021: Diferencia = 12.0 (0.009%)\n",
      "  Año 2020: Diferencia = 13.0 (0.010%)\n",
      "  Año 2019: Diferencia = 16.0 (0.015%)\n",
      "  Año 2018: Diferencia = 19.0 (0.018%)\n",
      "  Año 2017: Diferencia = 22.0 (0.021%)\n",
      "  Año 2016: Diferencia = 26.0 (0.025%)\n",
      "  Año 2015: Diferencia = 19.0 (0.018%)\n",
      "\n",
      " Ejemplo de verificación (año 2023):\n",
      "  Defunciones hombres: 63,174.0\n",
      "  Defunciones mujeres: 58,085.0\n",
      "  Suma por sexo: 121,259.0\n",
      "  Total registrado: 121,270.0\n",
      "  Diferencia: 11.0 (0.009%)\n",
      "\n",
      " CONCLUSIÓN:\n",
      " Todas las inconsistencias son menores y aceptables\n",
      " Los datos de defunciones son consistentes para análisis\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Verificar suma de defunciones por sexo vs totales\n",
    "\n",
    "print(\"=== VERIFICACIÓN DE SUMA DE DEFUNCIONES POR SEXO ===\")\n",
    "\n",
    "# Verificar que la suma de defunciones por sexo coincida con los totales\n",
    "print(\" Verificando consistencia en defunciones...\")\n",
    "\n",
    "inconsistencias_defunciones = []\n",
    "\n",
    "for año in años_completos:\n",
    "    fila = dataset_unificado[dataset_unificado['año'] == año].iloc[0]\n",
    "    \n",
    "    # Calcular suma por sexo\n",
    "    suma_por_sexo = fila['defunciones_hombres'] + fila['defunciones_mujeres']\n",
    "    total_registrado = fila['defunciones_totales']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_sexo - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_defunciones.append({\n",
    "        'año': año,\n",
    "        'suma_por_sexo': suma_por_sexo,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\" Años verificados: {len(años_completos)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_defunciones if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_defunciones if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\" Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\" Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificación\n",
    "print(f\"\\n Ejemplo de verificación (año 2023):\")\n",
    "ejemplo_2023 = dataset_unificado[dataset_unificado['año'] == 2023].iloc[0]\n",
    "suma_ejemplo = ejemplo_2023['defunciones_hombres'] + ejemplo_2023['defunciones_mujeres']\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['defunciones_totales'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['defunciones_totales']) * 100\n",
    "\n",
    "print(f\"  Defunciones hombres: {ejemplo_2023['defunciones_hombres']:,}\")\n",
    "print(f\"  Defunciones mujeres: {ejemplo_2023['defunciones_mujeres']:,}\")\n",
    "print(f\"  Suma por sexo: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['defunciones_totales']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Conclusión\n",
    "print(f\"\\n CONCLUSIÓN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\" Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\" Los datos de defunciones son consistentes para análisis\")\n",
    "else:\n",
    "    print(\" Hay inconsistencias significativas que requieren revisión\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e730337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN DE SUMA DE NACIMIENTOS POR EDAD ===\n",
      " Verificando consistencia en nacimientos por edad...\n",
      " Años disponibles para verificación por edad: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      " Años verificados: 10\n",
      " Inconsistencias menores (<0.1%): 10\n",
      " Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      " Inconsistencias menores (aceptables):\n",
      "  Año 2014: Diferencia = 0.0 (0.000%)\n",
      "  Año 2015: Diferencia = 0.0 (0.000%)\n",
      "  Año 2016: Diferencia = 0.0 (0.000%)\n",
      "  Año 2017: Diferencia = 0.0 (0.000%)\n",
      "  Año 2018: Diferencia = 0.0 (0.000%)\n",
      "  Año 2019: Diferencia = 0.0 (0.000%)\n",
      "  Año 2020: Diferencia = 0.0 (0.000%)\n",
      "  Año 2021: Diferencia = 0.0 (0.000%)\n",
      "  Año 2022: Diferencia = 0.0 (0.000%)\n",
      "  Año 2023: Diferencia = 0.0 (0.000%)\n",
      "\n",
      " Ejemplo de verificación (año 2023):\n",
      "  Suma por rangos de edad: 171,715.0\n",
      "  Total registrado: 171,715.0\n",
      "  Diferencia: 0.0 (0.000%)\n",
      "\n",
      " Rangos de edad incluidos en verificación:\n",
      "   1. nacimientos_menores_15\n",
      "   2. nacimientos_15_19\n",
      "   3. nacimientos_20_24\n",
      "   4. nacimientos_25_29\n",
      "   5. nacimientos_30_34\n",
      "   6. nacimientos_35_39\n",
      "   7. nacimientos_40_44\n",
      "   8. nacimientos_45_49\n",
      "   9. nacimientos_50_mas\n",
      "\n",
      " CONCLUSIÓN:\n",
      " Todas las inconsistencias son menores y aceptables\n",
      " Los datos de nacimientos por edad son consistentes para análisis\n"
     ]
    }
   ],
   "source": [
    "# 7.3 Verificar suma de nacimientos por edad vs totales\n",
    "\n",
    "print(\"=== VERIFICACIÓN DE SUMA DE NACIMIENTOS POR EDAD ===\")\n",
    "\n",
    "# Verificar que la suma de nacimientos por edad coincida con los totales\n",
    "print(\" Verificando consistencia en nacimientos por edad...\")\n",
    "\n",
    "# Usar años disponibles en dataset_extendido\n",
    "años_edad = sorted(dataset_extendido['año'].tolist())\n",
    "print(f\" Años disponibles para verificación por edad: {años_edad}\")\n",
    "\n",
    "inconsistencias_nacimientos_edad = []\n",
    "\n",
    "for año in años_edad:\n",
    "    fila = dataset_extendido[dataset_extendido['año'] == año].iloc[0]\n",
    "    \n",
    "    # Calcular suma por rangos de edad\n",
    "    columnas_nacimientos_edad = [col for col in fila.index if col.startswith('nacimientos_') and col != 'total_nacimientos']\n",
    "    suma_por_edad = fila[columnas_nacimientos_edad].sum()\n",
    "    total_registrado = fila['total_nacimientos']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_edad - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_nacimientos_edad.append({\n",
    "        'año': año,\n",
    "        'suma_por_edad': suma_por_edad,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\" Años verificados: {len(años_edad)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_nacimientos_edad if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_nacimientos_edad if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\" Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\" Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificación\n",
    "print(f\"\\n Ejemplo de verificación (año 2023):\")\n",
    "ejemplo_2023 = dataset_extendido[dataset_extendido['año'] == 2023].iloc[0]\n",
    "columnas_nacimientos_edad = [col for col in ejemplo_2023.index if col.startswith('nacimientos_') and col != 'total_nacimientos']\n",
    "suma_ejemplo = ejemplo_2023[columnas_nacimientos_edad].sum()\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['total_nacimientos'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['total_nacimientos']) * 100\n",
    "\n",
    "print(f\"  Suma por rangos de edad: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['total_nacimientos']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Mostrar rangos de edad incluidos\n",
    "print(f\"\\n Rangos de edad incluidos en verificación:\")\n",
    "for i, col in enumerate(columnas_nacimientos_edad, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Conclusión\n",
    "print(f\"\\n CONCLUSIÓN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\" Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\" Los datos de nacimientos por edad son consistentes para análisis\")\n",
    "else:\n",
    "    print(\" Hay inconsistencias significativas que requieren revisión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74457ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN DE SUMA DE DEFUNCIONES POR EDAD ===\n",
      " Verificando consistencia en defunciones por edad...\n",
      " Años disponibles para verificación por edad: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      " Años verificados: 10\n",
      " Inconsistencias menores (<0.1%): 10\n",
      " Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      " Inconsistencias menores (aceptables):\n",
      "  Año 2014: Diferencia = 0.0 (0.000%)\n",
      "  Año 2015: Diferencia = 0.0 (0.000%)\n",
      "  Año 2016: Diferencia = 0.0 (0.000%)\n",
      "  Año 2017: Diferencia = 0.0 (0.000%)\n",
      "  Año 2018: Diferencia = 0.0 (0.000%)\n",
      "  Año 2019: Diferencia = 0.0 (0.000%)\n",
      "  Año 2020: Diferencia = 0.0 (0.000%)\n",
      "  Año 2021: Diferencia = 0.0 (0.000%)\n",
      "  Año 2022: Diferencia = 0.0 (0.000%)\n",
      "  Año 2023: Diferencia = 0.0 (0.000%)\n",
      "\n",
      " Ejemplo de verificación (año 2023):\n",
      "  Suma por rangos de edad: 121,646.0\n",
      "  Total registrado: 121,646.0\n",
      "  Diferencia: 0.0 (0.000%)\n",
      "\n",
      " Rangos de edad incluidos en verificación:\n",
      "   1. defunciones_100_mas\n",
      "   2. defunciones_10_14\n",
      "   3. defunciones_15_19\n",
      "   4. defunciones_1_4\n",
      "   5. defunciones_20_24\n",
      "   6. defunciones_25_29\n",
      "   7. defunciones_30_34\n",
      "   8. defunciones_35_39\n",
      "   9. defunciones_40_44\n",
      "  10. defunciones_45_49\n",
      "  11. defunciones_50_54\n",
      "  12. defunciones_55_59\n",
      "  13. defunciones_5_9\n",
      "  14. defunciones_60_64\n",
      "  15. defunciones_65_69\n",
      "  16. defunciones_70_74\n",
      "  17. defunciones_75_79\n",
      "  18. defunciones_80_84\n",
      "  19. defunciones_85_89\n",
      "  20. defunciones_90_94\n",
      "  21. defunciones_95_99\n",
      "  22. defunciones_menores_1\n",
      "\n",
      " Estadísticas de rangos de defunciones:\n",
      "  Total rangos verificados: 22\n",
      "  Rango más bajo: defunciones_100_mas\n",
      "  Rango más alto: defunciones_menores_1\n",
      "\n",
      " CONCLUSIÓN:\n",
      " Todas las inconsistencias son menores y aceptables\n",
      " Los datos de defunciones por edad son consistentes para análisis\n",
      " Los 22 rangos detallados funcionan correctamente\n"
     ]
    }
   ],
   "source": [
    "# 7.4 Verificar suma de defunciones por edad vs totales\n",
    "\n",
    "print(\"=== VERIFICACIÓN DE SUMA DE DEFUNCIONES POR EDAD ===\")\n",
    "\n",
    "# Verificar que la suma de defunciones por edad coincida con los totales\n",
    "print(\" Verificando consistencia en defunciones por edad...\")\n",
    "\n",
    "# Usar años disponibles en dataset_extendido\n",
    "años_edad = sorted(dataset_extendido['año'].tolist())\n",
    "print(f\" Años disponibles para verificación por edad: {años_edad}\")\n",
    "\n",
    "inconsistencias_defunciones_edad = []\n",
    "\n",
    "for año in años_edad:\n",
    "    fila = dataset_extendido[dataset_extendido['año'] == año].iloc[0]\n",
    "    \n",
    "    # Calcular suma por rangos de edad\n",
    "    columnas_defunciones_edad = [col for col in fila.index if col.startswith('defunciones_') and col != 'total_defunciones']\n",
    "    suma_por_edad = fila[columnas_defunciones_edad].sum()\n",
    "    total_registrado = fila['total_defunciones']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_edad - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_defunciones_edad.append({\n",
    "        'año': año,\n",
    "        'suma_por_edad': suma_por_edad,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\" Años verificados: {len(años_edad)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_defunciones_edad if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_defunciones_edad if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\" Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\" Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  Año {inc['año']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificación\n",
    "print(f\"\\n Ejemplo de verificación (año 2023):\")\n",
    "ejemplo_2023 = dataset_extendido[dataset_extendido['año'] == 2023].iloc[0]\n",
    "columnas_defunciones_edad = [col for col in ejemplo_2023.index if col.startswith('defunciones_') and col != 'total_defunciones']\n",
    "suma_ejemplo = ejemplo_2023[columnas_defunciones_edad].sum()\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['total_defunciones'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['total_defunciones']) * 100\n",
    "\n",
    "print(f\"  Suma por rangos de edad: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['total_defunciones']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Mostrar rangos de edad incluidos\n",
    "print(f\"\\n Rangos de edad incluidos en verificación:\")\n",
    "for i, col in enumerate(columnas_defunciones_edad, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Mostrar estadísticas de rangos\n",
    "print(f\"\\n Estadísticas de rangos de defunciones:\")\n",
    "print(f\"  Total rangos verificados: {len(columnas_defunciones_edad)}\")\n",
    "print(f\"  Rango más bajo: {min(columnas_defunciones_edad)}\")\n",
    "print(f\"  Rango más alto: {max(columnas_defunciones_edad)}\")\n",
    "\n",
    "# Conclusión\n",
    "print(f\"\\n CONCLUSIÓN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\" Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\" Los datos de defunciones por edad son consistentes para análisis\")\n",
    "    print(\" Los 22 rangos detallados funcionan correctamente\")\n",
    "else:\n",
    "    print(\" Hay inconsistencias significativas que requieren revisión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae11c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETECCIÓN DE OUTLIERS ===\n",
      " Analizando outliers en variables principales...\n",
      "\n",
      " Resumen de outliers detectados:\n",
      "\n",
      "NACIMIENTOS_TOTALES:\n",
      "  Outliers detectados: 3 (6.0%)\n",
      "  Límites: [191990.8, 295932.8]\n",
      "  Valores outliers: [171992, 177255, 189310]\n",
      "\n",
      "DEFUNCIONES_TOTALES:\n",
      "  Outliers detectados: 2 (4.0%)\n",
      "  Límites: [40617.5, 131139.5]\n",
      "  Valores outliers: [136958, 137439]\n",
      "\n",
      "NACIMIENTOS_HOMBRES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  Límites: [70469.0, 138581.0]\n",
      "\n",
      "NACIMIENTOS_MUJERES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  Límites: [70208.0, 131744.0]\n",
      "\n",
      "DEFUNCIONES_HOMBRES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  Límites: [38253.0, 84973.0]\n",
      "\n",
      "DEFUNCIONES_MUJERES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  Límites: [38932.0, 70028.0]\n",
      "\n",
      "CRECIMIENTO_NATURAL:\n",
      "  Outliers detectados: 4 (8.0%)\n",
      "  Límites: [89589.0, 236759.0]\n",
      "  Valores outliers: [39816, 50722, 52352, 69119]\n",
      "\n",
      "RATIO_NACIMIENTOS_SEXO:\n",
      "  Outliers detectados: 3 (33.3%)\n",
      "  Límites: [1.0, 1.0]\n",
      "  Valores outliers: [1.029, 1.034, 1.051]\n",
      "\n",
      "RATIO_DEFUNCIONES_SEXO:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  Límites: [1.1, 1.2]\n",
      "\n",
      "PCT_CAMBIO_NACIMIENTOS:\n",
      "  Outliers detectados: 2 (4.1%)\n",
      "  Límites: [-9.1, 9.8]\n",
      "  Valores outliers: [9.98, 10.07]\n",
      "\n",
      "PCT_CAMBIO_DEFUNCIONES:\n",
      "  Outliers detectados: 3 (6.1%)\n",
      "  Límites: [-8.8, 7.0]\n",
      "  Valores outliers: [-12.85, 9.65, 12.94]\n",
      "\n",
      " Años con valores atípicos:\n",
      "Años con outliers: [np.int64(1976), np.int64(2016), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      " Año 1976 - Valores atípicos:\n",
      "  pct_cambio_defunciones: 9.65 (OUTLIER)\n",
      "\n",
      " Año 2016 - Valores atípicos:\n",
      "  ratio_nacimientos_sexo: 1.034 (OUTLIER)\n",
      "\n",
      " Año 2019 - Valores atípicos:\n",
      "  pct_cambio_defunciones: -12.85 (OUTLIER)\n",
      "\n",
      " Año 2020 - Valores atípicos:\n",
      "  crecimiento_natural: 69,119.0 (OUTLIER)\n",
      "  ratio_nacimientos_sexo: 1.051 (OUTLIER)\n",
      "  pct_cambio_nacimientos: 9.98 (OUTLIER)\n",
      "\n",
      " Año 2021 - Valores atípicos:\n",
      "  nacimientos_totales: 177,255.0 (OUTLIER)\n",
      "  defunciones_totales: 137,439.0 (OUTLIER)\n",
      "  crecimiento_natural: 39,816.0 (OUTLIER)\n",
      "\n",
      " Año 2022 - Valores atípicos:\n",
      "  nacimientos_totales: 189,310.0 (OUTLIER)\n",
      "  defunciones_totales: 136,958.0 (OUTLIER)\n",
      "  crecimiento_natural: 52,352.0 (OUTLIER)\n",
      "  ratio_nacimientos_sexo: 1.029 (OUTLIER)\n",
      "  pct_cambio_nacimientos: 10.07 (OUTLIER)\n",
      "  pct_cambio_defunciones: 12.94 (OUTLIER)\n",
      "\n",
      " Año 2023 - Valores atípicos:\n",
      "  nacimientos_totales: 171,992.0 (OUTLIER)\n",
      "  crecimiento_natural: 50,722.0 (OUTLIER)\n",
      "\n",
      " Análisis de patrones temporales:\n",
      "\n",
      "NACIMIENTOS_TOTALES:\n",
      "  Años con outliers: [np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "   Concentración en pocos años - revisar datos de esos períodos\n",
      "\n",
      "DEFUNCIONES_TOTALES:\n",
      "  Años con outliers: [np.int64(2021), np.int64(2022)]\n",
      "   Concentración en pocos años - revisar datos de esos períodos\n",
      "\n",
      "CRECIMIENTO_NATURAL:\n",
      "  Años con outliers: [np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "   Outliers distribuidos en múltiples años\n",
      "\n",
      "RATIO_NACIMIENTOS_SEXO:\n",
      "  Años con outliers: [np.int64(2016), np.int64(2020), np.int64(2022)]\n",
      "   Concentración en pocos años - revisar datos de esos períodos\n",
      "\n",
      "PCT_CAMBIO_NACIMIENTOS:\n",
      "  Años con outliers: [np.int64(2020), np.int64(2022)]\n",
      "   Concentración en pocos años - revisar datos de esos períodos\n",
      "\n",
      "PCT_CAMBIO_DEFUNCIONES:\n",
      "  Años con outliers: [np.int64(1976), np.int64(2019), np.int64(2022)]\n",
      "   Concentración en pocos años - revisar datos de esos períodos\n"
     ]
    }
   ],
   "source": [
    "# 7.5 Detección de outliers en variables numéricas\n",
    "\n",
    "print(\"=== DETECCIÓN DE OUTLIERS ===\")\n",
    "\n",
    "# Función para detectar outliers usando el método IQR\n",
    "def detectar_outliers_iqr(serie, nombre_variable):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el método del rango intercuartílico (IQR)\n",
    "    \"\"\"\n",
    "    Q1 = serie.quantile(0.25)\n",
    "    Q3 = serie.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = serie[(serie < limite_inferior) | (serie > limite_superior)]\n",
    "    \n",
    "    return {\n",
    "        'variable': nombre_variable,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'limite_inferior': limite_inferior,\n",
    "        'limite_superior': limite_superior,\n",
    "        'outliers': outliers,\n",
    "        'cantidad_outliers': len(outliers),\n",
    "        'porcentaje_outliers': (len(outliers) / len(serie)) * 100\n",
    "    }\n",
    "\n",
    "# Variables numéricas principales para análisis de outliers\n",
    "variables_analisis = [\n",
    "    'nacimientos_totales', 'defunciones_totales', 'nacimientos_hombres', 'nacimientos_mujeres',\n",
    "    'defunciones_hombres', 'defunciones_mujeres', 'crecimiento_natural', 'ratio_nacimientos_sexo',\n",
    "    'ratio_defunciones_sexo', 'pct_cambio_nacimientos', 'pct_cambio_defunciones'\n",
    "]\n",
    "\n",
    "print(\" Analizando outliers en variables principales...\")\n",
    "\n",
    "resultados_outliers = []\n",
    "\n",
    "for var in variables_analisis:\n",
    "    if var in dataset_unificado.columns:\n",
    "        serie = dataset_unificado[var].dropna()\n",
    "        resultado = detectar_outliers_iqr(serie, var)\n",
    "        resultados_outliers.append(resultado)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n Resumen de outliers detectados:\")\n",
    "for resultado in resultados_outliers:\n",
    "    print(f\"\\n{resultado['variable'].upper()}:\")\n",
    "    print(f\"  Outliers detectados: {resultado['cantidad_outliers']} ({resultado['porcentaje_outliers']:.1f}%)\")\n",
    "    print(f\"  Límites: [{resultado['limite_inferior']:.1f}, {resultado['limite_superior']:.1f}]\")\n",
    "    \n",
    "    if resultado['cantidad_outliers'] > 0:\n",
    "        print(f\"  Valores outliers: {sorted(resultado['outliers'].tolist())}\")\n",
    "\n",
    "# Identificar años con múltiples outliers (CORREGIDO)\n",
    "print(f\"\\n Años con valores atípicos:\")\n",
    "años_outliers = set()\n",
    "\n",
    "for resultado in resultados_outliers:\n",
    "    if resultado['cantidad_outliers'] > 0:\n",
    "        # CORRECCIÓN: Usar el índice correcto\n",
    "        for idx in resultado['outliers'].index:\n",
    "            año_outlier = dataset_unificado.loc[idx, 'año']\n",
    "            años_outliers.add(año_outlier)\n",
    "\n",
    "if años_outliers:\n",
    "    print(f\"Años con outliers: {sorted(años_outliers)}\")\n",
    "    \n",
    "    # Mostrar detalles de años problemáticos (CORREGIDO)\n",
    "    for año in sorted(años_outliers):\n",
    "        print(f\"\\n Año {año} - Valores atípicos:\")\n",
    "        fila = dataset_unificado[dataset_unificado['año'] == año].iloc[0]\n",
    "        \n",
    "        for resultado in resultados_outliers:\n",
    "            if resultado['cantidad_outliers'] > 0:\n",
    "                # Verificar si este año tiene outliers en esta variable\n",
    "                año_idx = dataset_unificado[dataset_unificado['año'] == año].index[0]\n",
    "                if año_idx in resultado['outliers'].index:\n",
    "                    valor = fila[resultado['variable']]\n",
    "                    print(f\"  {resultado['variable']}: {valor:,} (OUTLIER)\")\n",
    "else:\n",
    "    print(\"No se detectaron años con múltiples outliers\")\n",
    "\n",
    "# Análisis adicional: identificar patrones temporales\n",
    "print(f\"\\n Análisis de patrones temporales:\")\n",
    "for resultado in resultados_outliers:\n",
    "    if resultado['cantidad_outliers'] > 0:\n",
    "        print(f\"\\n{resultado['variable'].upper()}:\")\n",
    "        # Obtener años de outliers\n",
    "        años_outliers_var = [dataset_unificado.loc[idx, 'año'] for idx in resultado['outliers'].index]\n",
    "        print(f\"  Años con outliers: {sorted(años_outliers_var)}\")\n",
    "        \n",
    "        # Analizar si hay patrones (ej: concentración en ciertos años)\n",
    "        if len(set(años_outliers_var)) <= 3:\n",
    "            print(f\"   Concentración en pocos años - revisar datos de esos períodos\")\n",
    "        else:\n",
    "            print(f\"   Outliers distribuidos en múltiples años\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcbcf6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACIÓN DE VALORES LÓGICOS Y RANGOS ===\n",
      " Validando valores lógicos...\n",
      " Registros con nacimientos negativos: 0\n",
      " Registros con defunciones negativas: 0\n",
      " Registros con ratio nacimientos extremo (<0.8 o >1.2): 0\n",
      " Registros con ratio defunciones extremo (<0.8 o >1.2): 0\n",
      " Registros con cambio nacimientos >50%: 0\n",
      " Registros con cambio defunciones >50%: 0\n",
      "\n",
      " Verificando consistencia temporal...\n",
      " Años con cambios grandes en nacimientos (>50,000): 0\n",
      " Años con cambios grandes en defunciones (>50,000): 0\n",
      "\n",
      " Verificando rangos de valores esperados...\n",
      " Años con inconsistencias en nacimientos (>100 diferencia): 0\n",
      " Años con inconsistencias en defunciones (>100 diferencia): 0\n",
      "\n",
      " RESUMEN DE VALIDACIÓN:\n",
      " Nacimientos negativos: 0\n",
      " Defunciones negativas: 0\n",
      " Ratios extremos nacimientos: 0\n",
      " Ratios extremos defunciones: 0\n",
      "Cambios extremos nacimientos: 0\n",
      " Cambios extremos defunciones: 0\n",
      " Cambios grandes temporales: 0\n",
      " Inconsistencias internas: 0\n",
      "\n",
      " ¡TODOS LOS VALORES SON LÓGICOS Y CONSISTENTES!\n"
     ]
    }
   ],
   "source": [
    "# 7.6 Validación de valores lógicos y rangos\n",
    "\n",
    "print(\"=== VALIDACIÓN DE VALORES LÓGICOS Y RANGOS ===\")\n",
    "\n",
    "# Validar valores lógicos en variables clave\n",
    "print(\" Validando valores lógicos...\")\n",
    "\n",
    "# 1. Verificar que nacimientos y defunciones sean positivos\n",
    "nacimientos_negativos = dataset_unificado[dataset_unificado['nacimientos_totales'] < 0]\n",
    "defunciones_negativas = dataset_unificado[dataset_unificado['defunciones_totales'] < 0]\n",
    "\n",
    "print(f\" Registros con nacimientos negativos: {len(nacimientos_negativos)}\")\n",
    "print(f\" Registros con defunciones negativas: {len(defunciones_negativas)}\")\n",
    "\n",
    "# 2. Verificar ratios de sexo (deben estar entre 0.8 y 1.2 aproximadamente)\n",
    "ratios_nacimientos_extremos = dataset_unificado[\n",
    "    (dataset_unificado['ratio_nacimientos_sexo'] < 0.8) | \n",
    "    (dataset_unificado['ratio_nacimientos_sexo'] > 1.2)\n",
    "]\n",
    "\n",
    "ratios_defunciones_extremos = dataset_unificado[\n",
    "    (dataset_unificado['ratio_defunciones_sexo'] < 0.8) | \n",
    "    (dataset_unificado['ratio_defunciones_sexo'] > 1.2)\n",
    "]\n",
    "\n",
    "print(f\" Registros con ratio nacimientos extremo (<0.8 o >1.2): {len(ratios_nacimientos_extremos)}\")\n",
    "print(f\" Registros con ratio defunciones extremo (<0.8 o >1.2): {len(ratios_defunciones_extremos)}\")\n",
    "\n",
    "# 3. Verificar cambios porcentuales extremos (>50% cambio año a año)\n",
    "# CORRECCIÓN: Usar abs() correctamente\n",
    "cambios_nacimientos_extremos = dataset_unificado[\n",
    "    (dataset_unificado['pct_cambio_nacimientos'].abs() > 50)\n",
    "]\n",
    "\n",
    "cambios_defunciones_extremos = dataset_unificado[\n",
    "    (dataset_unificado['pct_cambio_defunciones'].abs() > 50)\n",
    "]\n",
    "\n",
    "print(f\" Registros con cambio nacimientos >50%: {len(cambios_nacimientos_extremos)}\")\n",
    "print(f\" Registros con cambio defunciones >50%: {len(cambios_defunciones_extremos)}\")\n",
    "\n",
    "# Mostrar ejemplos de valores problemáticos\n",
    "if len(ratios_nacimientos_extremos) > 0:\n",
    "    print(f\"\\n Ejemplos de ratios de nacimientos extremos:\")\n",
    "    display(ratios_nacimientos_extremos[['año', 'nacimientos_hombres', 'nacimientos_mujeres', 'ratio_nacimientos_sexo']].head())\n",
    "\n",
    "if len(cambios_nacimientos_extremos) > 0:\n",
    "    print(f\"\\n Ejemplos de cambios extremos en nacimientos:\")\n",
    "    display(cambios_nacimientos_extremos[['año', 'nacimientos_totales', 'dif_nacimientos_año_anterior', 'pct_cambio_nacimientos']].head())\n",
    "\n",
    "# 4. Verificar consistencia temporal (no debe haber saltos imposibles)\n",
    "print(f\"\\n Verificando consistencia temporal...\")\n",
    "\n",
    "# CORRECCIÓN: Calcular diferencias año a año correctamente\n",
    "dataset_unificado['dif_nacimientos_abs'] = dataset_unificado['nacimientos_totales'].diff().abs()\n",
    "dataset_unificado['dif_defunciones_abs'] = dataset_unificado['defunciones_totales'].diff().abs()\n",
    "\n",
    "# Identificar cambios muy grandes (más de 50,000 en un año)\n",
    "cambios_grandes_nacimientos = dataset_unificado[dataset_unificado['dif_nacimientos_abs'] > 50000]\n",
    "cambios_grandes_defunciones = dataset_unificado[dataset_unificado['dif_defunciones_abs'] > 50000]\n",
    "\n",
    "print(f\" Años con cambios grandes en nacimientos (>50,000): {len(cambios_grandes_nacimientos)}\")\n",
    "print(f\" Años con cambios grandes en defunciones (>50,000): {len(cambios_grandes_defunciones)}\")\n",
    "\n",
    "if len(cambios_grandes_nacimientos) > 0:\n",
    "    print(f\"\\n Años con cambios grandes en nacimientos:\")\n",
    "    display(cambios_grandes_nacimientos[['año', 'nacimientos_totales', 'dif_nacimientos_año_anterior', 'dif_nacimientos_abs']])\n",
    "\n",
    "if len(cambios_grandes_defunciones) > 0:\n",
    "    print(f\"\\n Años con cambios grandes en defunciones:\")\n",
    "    display(cambios_grandes_defunciones[['año', 'defunciones_totales', 'dif_defunciones_año_anterior', 'dif_defunciones_abs']])\n",
    "\n",
    "# 5. Verificación adicional: rangos de valores esperados\n",
    "print(f\"\\n Verificando rangos de valores esperados...\")\n",
    "\n",
    "# Verificar que los totales sean consistentes con la suma por sexo\n",
    "dataset_unificado['suma_nacimientos_sexo'] = dataset_unificado['nacimientos_hombres'] + dataset_unificado['nacimientos_mujeres']\n",
    "dataset_unificado['suma_defunciones_sexo'] = dataset_unificado['defunciones_hombres'] + dataset_unificado['defunciones_mujeres']\n",
    "\n",
    "# Calcular diferencias\n",
    "dataset_unificado['diff_nacimientos'] = abs(dataset_unificado['nacimientos_totales'] - dataset_unificado['suma_nacimientos_sexo'])\n",
    "dataset_unificado['diff_defunciones'] = abs(dataset_unificado['defunciones_totales'] - dataset_unificado['suma_defunciones_sexo'])\n",
    "\n",
    "# Identificar inconsistencias significativas\n",
    "inconsistencias_nacimientos = dataset_unificado[dataset_unificado['diff_nacimientos'] > 100]\n",
    "inconsistencias_defunciones = dataset_unificado[dataset_unificado['diff_defunciones'] > 100]\n",
    "\n",
    "print(f\" Años con inconsistencias en nacimientos (>100 diferencia): {len(inconsistencias_nacimientos)}\")\n",
    "print(f\" Años con inconsistencias en defunciones (>100 diferencia): {len(inconsistencias_defunciones)}\")\n",
    "\n",
    "if len(inconsistencias_nacimientos) > 0:\n",
    "    print(f\"\\n Años con inconsistencias en nacimientos:\")\n",
    "    display(inconsistencias_nacimientos[['año', 'nacimientos_totales', 'suma_nacimientos_sexo', 'diff_nacimientos']])\n",
    "\n",
    "if len(inconsistencias_defunciones) > 0:\n",
    "    print(f\"\\n Años con inconsistencias en defunciones:\")\n",
    "    display(inconsistencias_defunciones[['año', 'defunciones_totales', 'suma_defunciones_sexo', 'diff_defunciones']])\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\n RESUMEN DE VALIDACIÓN:\")\n",
    "print(f\" Nacimientos negativos: {len(nacimientos_negativos)}\")\n",
    "print(f\" Defunciones negativas: {len(defunciones_negativas)}\")\n",
    "print(f\" Ratios extremos nacimientos: {len(ratios_nacimientos_extremos)}\")\n",
    "print(f\" Ratios extremos defunciones: {len(ratios_defunciones_extremos)}\")\n",
    "print(f\"Cambios extremos nacimientos: {len(cambios_nacimientos_extremos)}\")\n",
    "print(f\" Cambios extremos defunciones: {len(cambios_defunciones_extremos)}\")\n",
    "print(f\" Cambios grandes temporales: {len(cambios_grandes_nacimientos) + len(cambios_grandes_defunciones)}\")\n",
    "print(f\" Inconsistencias internas: {len(inconsistencias_nacimientos) + len(inconsistencias_defunciones)}\")\n",
    "\n",
    "if (len(nacimientos_negativos) == 0 and len(defunciones_negativas) == 0 and \n",
    "    len(ratios_nacimientos_extremos) == 0 and len(ratios_defunciones_extremos) == 0 and\n",
    "    len(cambios_nacimientos_extremos) == 0 and len(cambios_defunciones_extremos) == 0 and\n",
    "    len(cambios_grandes_nacimientos) == 0 and len(cambios_grandes_defunciones) == 0 and\n",
    "    len(inconsistencias_nacimientos) == 0 and len(inconsistencias_defunciones) == 0):\n",
    "    print(f\"\\n ¡TODOS LOS VALORES SON LÓGICOS Y CONSISTENTES!\")\n",
    "else:\n",
    "    print(f\"\\n Se encontraron algunos valores que requieren revisión\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "114b1dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA VALIDACIÓN DE CONSISTENCIA ===\n",
      " Resumen de validaciones:\n",
      "\n",
      "VERIFICACIONES REALIZADAS:\n",
      "   Suma de nacimientos por sexo vs totales\n",
      "   Suma de defunciones por sexo vs totales\n",
      "   Suma de nacimientos por edad vs totales\n",
      "   Suma de defunciones por edad vs totales\n",
      "   Detección de outliers en variables numéricas\n",
      "   Validación de valores lógicos y rangos\n",
      "   Verificación de consistencia temporal\n",
      "\n",
      "INCONSISTENCIAS ENCONTRADAS:\n",
      "  nacimientos_por_sexo: 0\n",
      "  defunciones_por_sexo: 0\n",
      "  nacimientos_por_edad: 10\n",
      "  defunciones_por_edad: 10\n",
      "\n",
      "OUTLIERS DETECTADOS:\n",
      "  total_variables_analizadas: 11\n",
      "  variables_con_outliers: 6\n",
      "  años_con_outliers: 7\n",
      "\n",
      "VALORES PROBLEMÁTICOS:\n",
      "  nacimientos_negativos: 0\n",
      "  defunciones_negativas: 0\n",
      "  ratios_extremos_nacimientos: 0\n",
      "  ratios_extremos_defunciones: 0\n",
      "  cambios_extremos_nacimientos: 0\n",
      "  cambios_extremos_defunciones: 0\n",
      "\n",
      " PUNTUACIÓN DE CALIDAD DE DATOS:\n",
      "Verificaciones realizadas: 788\n",
      "Problemas encontrados: 20\n",
      "Puntuación de calidad: 97.5%\n",
      " CALIDAD EXCELENTE: Los datos están muy bien estructurados\n",
      "\n",
      "=== RESUMEN FINAL DE LA SECCIÓN 7 ===\n",
      " Validación de consistencia completada exitosamente\n",
      " Todos los datasets están listos para modelado\n",
      " Calidad de datos verificada en múltiples dimensiones\n",
      " Base sólida para análisis y machine learning\n",
      "\n",
      " Validación de consistencia completada\n"
     ]
    }
   ],
   "source": [
    "# 7.7 Resumen de la validación de consistencia\n",
    "\n",
    "print(\"=== RESUMEN DE LA VALIDACIÓN DE CONSISTENCIA ===\")\n",
    "\n",
    "# Verificar que las variables necesarias estén definidas\n",
    "try:\n",
    "    años_con_edad = sorted(dataset_extendido['año'].tolist())\n",
    "except:\n",
    "    años_con_edad = []\n",
    "\n",
    "# Crear resumen de todas las validaciones realizadas\n",
    "resumen_validaciones = {\n",
    "    \"Verificaciones realizadas\": [\n",
    "        \"Suma de nacimientos por sexo vs totales\",\n",
    "        \"Suma de defunciones por sexo vs totales\", \n",
    "        \"Suma de nacimientos por edad vs totales\",\n",
    "        \"Suma de defunciones por edad vs totales\",\n",
    "        \"Detección de outliers en variables numéricas\",\n",
    "        \"Validación de valores lógicos y rangos\",\n",
    "        \"Verificación de consistencia temporal\"\n",
    "    ],\n",
    "    \"Inconsistencias encontradas\": {\n",
    "        \"nacimientos_por_sexo\": len(inconsistencias_nacimientos),\n",
    "        \"defunciones_por_sexo\": len(inconsistencias_defunciones),\n",
    "        \"nacimientos_por_edad\": len(inconsistencias_nacimientos_edad),\n",
    "        \"defunciones_por_edad\": len(inconsistencias_defunciones_edad)\n",
    "    },\n",
    "    \"Outliers detectados\": {\n",
    "        \"total_variables_analizadas\": len(resultados_outliers),\n",
    "        \"variables_con_outliers\": len([r for r in resultados_outliers if r['cantidad_outliers'] > 0]),\n",
    "        \"años_con_outliers\": len(años_outliers)\n",
    "    },\n",
    "    \"Valores problemáticos\": {\n",
    "        \"nacimientos_negativos\": len(nacimientos_negativos),\n",
    "        \"defunciones_negativas\": len(defunciones_negativas),\n",
    "        \"ratios_extremos_nacimientos\": len(ratios_nacimientos_extremos),\n",
    "        \"ratios_extremos_defunciones\": len(ratios_defunciones_extremos),\n",
    "        \"cambios_extremos_nacimientos\": len(cambios_nacimientos_extremos),\n",
    "        \"cambios_extremos_defunciones\": len(cambios_defunciones_extremos)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\" Resumen de validaciones:\")\n",
    "for categoria, items in resumen_validaciones.items():\n",
    "    print(f\"\\n{categoria.upper()}:\")\n",
    "    if isinstance(items, list):\n",
    "        for item in items:\n",
    "            print(f\"   {item}\")\n",
    "    else:\n",
    "        for clave, valor in items.items():\n",
    "            print(f\"  {clave}: {valor}\")\n",
    "\n",
    "# Calcular puntuación de calidad de datos (CORREGIDO)\n",
    "total_verificaciones = 0\n",
    "total_problemas = 0\n",
    "\n",
    "# Contar problemas encontrados\n",
    "total_problemas += len(inconsistencias_nacimientos)\n",
    "total_problemas += len(inconsistencias_defunciones)\n",
    "total_problemas += len(inconsistencias_nacimientos_edad)\n",
    "total_problemas += len(inconsistencias_defunciones_edad)\n",
    "total_problemas += len(nacimientos_negativos)\n",
    "total_problemas += len(defunciones_negativas)\n",
    "total_problemas += len(ratios_nacimientos_extremos)\n",
    "total_problemas += len(ratios_defunciones_extremos)\n",
    "\n",
    "# CORRECCIÓN: Contar verificaciones realizadas correctamente\n",
    "total_verificaciones += len(años_completos) * 2  # nacimientos y defunciones por sexo\n",
    "total_verificaciones += len(años_con_edad) * 2  # nacimientos y defunciones por edad\n",
    "total_verificaciones += len(dataset_unificado) * 4  # valores negativos y ratios extremos\n",
    "\n",
    "# Agregar verificaciones de outliers\n",
    "total_verificaciones += len(resultados_outliers) * len(dataset_unificado)\n",
    "\n",
    "puntuacion_calidad = ((total_verificaciones - total_problemas) / total_verificaciones) * 100\n",
    "\n",
    "print(f\"\\n PUNTUACIÓN DE CALIDAD DE DATOS:\")\n",
    "print(f\"Verificaciones realizadas: {total_verificaciones:,}\")\n",
    "print(f\"Problemas encontrados: {total_problemas:,}\")\n",
    "print(f\"Puntuación de calidad: {puntuacion_calidad:.1f}%\")\n",
    "\n",
    "if puntuacion_calidad >= 95:\n",
    "    print(\" CALIDAD EXCELENTE: Los datos están muy bien estructurados\")\n",
    "elif puntuacion_calidad >= 90:\n",
    "    print(\" CALIDAD BUENA: Los datos tienen calidad aceptable\")\n",
    "elif puntuacion_calidad >= 80:\n",
    "    print(\" CALIDAD REGULAR: Se recomienda revisar algunos valores\")\n",
    "else:\n",
    "    print(\" CALIDAD BAJA: Se requiere limpieza adicional\")\n",
    "\n",
    "# Resumen final de la sección 7\n",
    "print(f\"\\n=== RESUMEN FINAL DE LA SECCIÓN 7 ===\")\n",
    "print(f\" Validación de consistencia completada exitosamente\")\n",
    "print(f\" Todos los datasets están listos para modelado\")\n",
    "print(f\" Calidad de datos verificada en múltiples dimensiones\")\n",
    "print(f\" Base sólida para análisis y machine learning\")\n",
    "\n",
    "print(f\"\\n Validación de consistencia completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc46836",
   "metadata": {},
   "source": [
    "## 8. Preparación para Modelado\n",
    "\n",
    "Esta sección se enfoca en crear variables y features necesarios para modelos de Machine Learning, incluyendo codificaciones categóricas, features temporales y variables de tendencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88625159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACIÓN DE VARIABLES CATEGÓRICAS ===\n",
      " Dataset base para modelado: (1246200, 17)\n",
      "\n",
      " Columnas disponibles en dataset_modelado:\n",
      "['año', 'fecha_defuncion', 'sexo', 'tipo_edad', 'edad_cantidad', 'codigo_comuna', 'comuna', 'region', 'codigo_diagnostico', 'descripcion_diagnostico', 'año_fecha', 'mes', 'dia_semana', 'trimestre', 'dia_año', 'grupo_edad', 'rango_edad']\n",
      "\n",
      " Codificando regiones...\n",
      "Regiones codificadas: 17\n",
      "  0: De Aisén del Gral. C. Ibáñez del Campo\n",
      "  1: De Antofagasta\n",
      "  2: De Arica y Parinacota\n",
      "  3: De Atacama\n",
      "  4: De Coquimbo\n",
      "  5: De La Araucanía\n",
      "  6: De Los Lagos\n",
      "  7: De Los Ríos\n",
      "  8: De Magallanes y de La Antártica Chilena\n",
      "  9: De Tarapacá\n",
      "  10: De Valparaíso\n",
      "  11: De Ñuble\n",
      "  12: Del Biobío\n",
      "  13: Del Libertador General Bernardo O'Higgins\n",
      "  14: Del Maule\n",
      "  15: Ignorada\n",
      "  16: Región Metropolitana\n",
      "\n",
      " Codificando sexo...\n",
      "Sexo codificado: {'Hombre': 1, 'Mujer': 0}\n",
      "\n",
      " Codificando rangos de edad...\n",
      "Rangos de edad codificados: 22\n",
      "  0: 100_mas\n",
      "  1: 10_14\n",
      "  2: 15_19\n",
      "  3: 1_4\n",
      "  4: 20_24\n",
      "  5: 25_29\n",
      "  6: 30_34\n",
      "  7: 35_39\n",
      "  8: 40_44\n",
      "  9: 45_49\n",
      "  10: 50_54\n",
      "  11: 55_59\n",
      "  12: 5_9\n",
      "  13: 60_64\n",
      "  14: 65_69\n",
      "  15: 70_74\n",
      "  16: 75_79\n",
      "  17: 80_84\n",
      "  18: 85_89\n",
      "  19: 90_94\n",
      "  20: 95_99\n",
      "  21: menores_1\n",
      "\n",
      " Codificando códigos de diagnóstico...\n",
      "Columnas relacionadas con diagnóstico: ['codigo_diagnostico', 'descripcion_diagnostico']\n",
      "Usando columna: codigo_diagnostico\n",
      "Categorías de diagnóstico codificadas: 18\n",
      "  0: afecciones_perinatales\n",
      "  1: causas_externas\n",
      "  2: complicaciones_embarazo\n",
      "  3: enfermedades_cardiovasculares\n",
      "  4: enfermedades_digestivas\n",
      "  5: enfermedades_endocrinas\n",
      "  6: enfermedades_genitourinarias\n",
      "  7: enfermedades_infecciosas\n",
      "  8: enfermedades_mentales\n",
      "  9: enfermedades_musculoesqueleticas\n",
      "  10: enfermedades_nerviosas\n",
      "  11: enfermedades_ojos_oidos\n",
      "  12: enfermedades_piel\n",
      "  13: enfermedades_respiratorias\n",
      "  14: malformaciones_congenitas\n",
      "  15: neoplasias\n",
      "  16: sintomas_signos_anormales\n",
      "  17: traumatismos_envenenamientos\n",
      "\n",
      " Dataset con variables categóricas: (1246200, 22)\n",
      " Nuevas columnas creadas:\n",
      "   sexo_codificado\n",
      "   rango_edad_codificado\n",
      "   categoria_diagnostico\n",
      "   categoria_diagnostico_codificada\n",
      "\n",
      " Verificación de valores nulos:\n",
      "   sexo_codificado: 163 valores nulos\n",
      "   rango_edad_codificado: Sin valores nulos\n",
      "   categoria_diagnostico: Sin valores nulos\n",
      "   categoria_diagnostico_codificada: Sin valores nulos\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Crear variables categóricas para el dataset de defunciones detalladas\n",
    "\n",
    "print(\"=== CREACIÓN DE VARIABLES CATEGÓRICAS ===\")\n",
    "\n",
    "# Crear dataset preparado para modelado basado en defunciones detalladas\n",
    "dataset_modelado = defunciones_estandarizado.copy()\n",
    "print(f\" Dataset base para modelado: {dataset_modelado.shape}\")\n",
    "\n",
    "# Verificar columnas disponibles\n",
    "print(f\"\\n Columnas disponibles en dataset_modelado:\")\n",
    "print(dataset_modelado.columns.tolist())\n",
    "\n",
    "# 1. Codificación de regiones (Label Encoding)\n",
    "print(\"\\n Codificando regiones...\")\n",
    "if 'region' in dataset_modelado.columns:\n",
    "    regiones_unicas = sorted(dataset_modelado['region'].unique())\n",
    "    mapeo_regiones = {region: i for i, region in enumerate(regiones_unicas)}\n",
    "    dataset_modelado['region_codificada'] = dataset_modelado['region'].map(mapeo_regiones)\n",
    "    \n",
    "    print(f\"Regiones codificadas: {len(regiones_unicas)}\")\n",
    "    for region, codigo in mapeo_regiones.items():\n",
    "        print(f\"  {codigo}: {region}\")\n",
    "else:\n",
    "    print(\" Columna 'region' no encontrada\")\n",
    "\n",
    "# 2. Codificación de sexo (Binary Encoding)\n",
    "print(\"\\n Codificando sexo...\")\n",
    "if 'sexo' in dataset_modelado.columns:\n",
    "    mapeo_sexo = {'Hombre': 1, 'Mujer': 0}\n",
    "    dataset_modelado['sexo_codificado'] = dataset_modelado['sexo'].map(mapeo_sexo)\n",
    "    print(f\"Sexo codificado: {mapeo_sexo}\")\n",
    "else:\n",
    "    print(\" Columna 'sexo' no encontrada\")\n",
    "\n",
    "# 3. Codificación de rangos de edad (ya tenemos la columna 'rango_edad')\n",
    "print(\"\\n Codificando rangos de edad...\")\n",
    "if 'rango_edad' in dataset_modelado.columns:\n",
    "    rangos_edad_unicos = sorted(dataset_modelado['rango_edad'].unique())\n",
    "    mapeo_rangos_edad = {rango: i for i, rango in enumerate(rangos_edad_unicos)}\n",
    "    dataset_modelado['rango_edad_codificado'] = dataset_modelado['rango_edad'].map(mapeo_rangos_edad)\n",
    "    \n",
    "    print(f\"Rangos de edad codificados: {len(rangos_edad_unicos)}\")\n",
    "    for rango, codigo in mapeo_rangos_edad.items():\n",
    "        print(f\"  {codigo}: {rango}\")\n",
    "else:\n",
    "    print(\" Columna 'rango_edad' no encontrada\")\n",
    "\n",
    "# 4. Codificación de códigos de diagnóstico (agrupar por categorías principales)\n",
    "print(\"\\n Codificando códigos de diagnóstico...\")\n",
    "\n",
    "# Verificar si existe columna de diagnóstico\n",
    "columnas_diagnostico = [col for col in dataset_modelado.columns if 'diagnostico' in col.lower() or 'cie' in col.lower()]\n",
    "print(f\"Columnas relacionadas con diagnóstico: {columnas_diagnostico}\")\n",
    "\n",
    "if columnas_diagnostico:\n",
    "    columna_diagnostico = columnas_diagnostico[0]  # Usar la primera encontrada\n",
    "    print(f\"Usando columna: {columna_diagnostico}\")\n",
    "    \n",
    "    # Crear función para categorizar códigos CIE-10\n",
    "    def categorizar_diagnostico(codigo):\n",
    "        \"\"\"\n",
    "        Categoriza códigos CIE-10 en grupos principales\n",
    "        \"\"\"\n",
    "        if pd.isna(codigo):\n",
    "            return 'desconocido'\n",
    "        \n",
    "        codigo_str = str(codigo)\n",
    "        \n",
    "        # Categorías principales basadas en códigos CIE-10\n",
    "        if codigo_str.startswith('A') or codigo_str.startswith('B'):\n",
    "            return 'enfermedades_infecciosas'\n",
    "        elif codigo_str.startswith('C') or codigo_str.startswith('D'):\n",
    "            return 'neoplasias'\n",
    "        elif codigo_str.startswith('E'):\n",
    "            return 'enfermedades_endocrinas'\n",
    "        elif codigo_str.startswith('F'):\n",
    "            return 'enfermedades_mentales'\n",
    "        elif codigo_str.startswith('G'):\n",
    "            return 'enfermedades_nerviosas'\n",
    "        elif codigo_str.startswith('H'):\n",
    "            return 'enfermedades_ojos_oidos'\n",
    "        elif codigo_str.startswith('I'):\n",
    "            return 'enfermedades_cardiovasculares'\n",
    "        elif codigo_str.startswith('J'):\n",
    "            return 'enfermedades_respiratorias'\n",
    "        elif codigo_str.startswith('K'):\n",
    "            return 'enfermedades_digestivas'\n",
    "        elif codigo_str.startswith('L'):\n",
    "            return 'enfermedades_piel'\n",
    "        elif codigo_str.startswith('M'):\n",
    "            return 'enfermedades_musculoesqueleticas'\n",
    "        elif codigo_str.startswith('N'):\n",
    "            return 'enfermedades_genitourinarias'\n",
    "        elif codigo_str.startswith('O'):\n",
    "            return 'complicaciones_embarazo'\n",
    "        elif codigo_str.startswith('P'):\n",
    "            return 'afecciones_perinatales'\n",
    "        elif codigo_str.startswith('Q'):\n",
    "            return 'malformaciones_congenitas'\n",
    "        elif codigo_str.startswith('R'):\n",
    "            return 'sintomas_signos_anormales'\n",
    "        elif codigo_str.startswith('S') or codigo_str.startswith('T'):\n",
    "            return 'traumatismos_envenenamientos'\n",
    "        elif codigo_str.startswith('U'):\n",
    "            return 'causas_externas'\n",
    "        elif codigo_str.startswith('V') or codigo_str.startswith('W') or codigo_str.startswith('X') or codigo_str.startswith('Y'):\n",
    "            return 'causas_externas_accidentes'\n",
    "        elif codigo_str.startswith('Z'):\n",
    "            return 'factores_influencia_salud'\n",
    "        else:\n",
    "            return 'otros'\n",
    "\n",
    "    # Aplicar categorización\n",
    "    dataset_modelado['categoria_diagnostico'] = dataset_modelado[columna_diagnostico].apply(categorizar_diagnostico)\n",
    "    \n",
    "    # Codificar categorías de diagnóstico\n",
    "    categorias_diagnostico = sorted(dataset_modelado['categoria_diagnostico'].unique())\n",
    "    mapeo_categorias_diagnostico = {cat: i for i, cat in enumerate(categorias_diagnostico)}\n",
    "    dataset_modelado['categoria_diagnostico_codificada'] = dataset_modelado['categoria_diagnostico'].map(mapeo_categorias_diagnostico)\n",
    "    \n",
    "    print(f\"Categorías de diagnóstico codificadas: {len(categorias_diagnostico)}\")\n",
    "    for categoria, codigo in mapeo_categorias_diagnostico.items():\n",
    "        print(f\"  {codigo}: {categoria}\")\n",
    "else:\n",
    "    print(\" No se encontraron columnas de diagnóstico\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(f\"\\n Dataset con variables categóricas: {dataset_modelado.shape}\")\n",
    "print(f\" Nuevas columnas creadas:\")\n",
    "nuevas_columnas = [col for col in dataset_modelado.columns if col.endswith('_codificado') or col.startswith('categoria_')]\n",
    "for col in nuevas_columnas:\n",
    "    print(f\"   {col}\")\n",
    "\n",
    "# Verificar que no hay valores nulos en las nuevas columnas\n",
    "print(f\"\\n Verificación de valores nulos:\")\n",
    "for col in nuevas_columnas:\n",
    "    nulos = dataset_modelado[col].isnull().sum()\n",
    "    if nulos > 0:\n",
    "        print(f\"   {col}: {nulos} valores nulos\")\n",
    "    else:\n",
    "        print(f\"   {col}: Sin valores nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93c933d7-7cee-4cfd-9592-e7dfb61cb5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset después de limpieza: (1246037, 22)\n"
     ]
    }
   ],
   "source": [
    "# Limpiar valores nulos en sexo_codificado\n",
    "dataset_modelado = dataset_modelado.dropna(subset=['sexo_codificado'])\n",
    "print(f\" Dataset después de limpieza: {dataset_modelado.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2789bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERACIÓN DE FEATURES TEMPORALES ===\n",
      " Creando features temporales adicionales...\n",
      "\n",
      " Columnas temporales disponibles:\n",
      "  ['mes', 'dia_semana', 'trimestre', 'dia_año']\n",
      "\n",
      " Creando features cíclicos...\n",
      " Features cíclicos de mes creados\n",
      " Features cíclicos de día del año creados\n",
      " Features cíclicos de trimestre creados\n",
      "\n",
      " Codificando día de la semana...\n",
      "Valores únicos en dia_semana: ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']\n",
      " Día de la semana codificado: {'Friday': 0, 'Monday': 1, 'Saturday': 2, 'Sunday': 3, 'Thursday': 4, 'Tuesday': 5, 'Wednesday': 6}\n",
      "\n",
      " Creando features de días especiales...\n",
      " Feature 'es_fin_semana' creado\n",
      " Features 'es_invierno' y 'es_verano' creados\n",
      " Feature 'trimestre_fiscal' creado\n",
      "\n",
      " Creando features de época del año...\n",
      " Época del año codificada\n",
      "\n",
      " Dataset con features temporales: (1246037, 37)\n",
      " Nuevas columnas temporales creadas: 12\n",
      "   sexo_codificado\n",
      "   rango_edad_codificado\n",
      "   mes_sin\n",
      "   mes_cos\n",
      "   dia_año_sin\n",
      "   dia_año_cos\n",
      "   trimestre_sin\n",
      "   trimestre_cos\n",
      "   dia_semana_codificado\n",
      "   dia_semana_sin\n",
      "   dia_semana_cos\n",
      "   trimestre_fiscal\n",
      "\n",
      " Features temporales completados\n"
     ]
    }
   ],
   "source": [
    "# 8.2 Generar features temporales para análisis estacional\n",
    "\n",
    "print(\"=== GENERACIÓN DE FEATURES TEMPORALES ===\")\n",
    "\n",
    "# Ya tenemos algunas variables temporales básicas, vamos a crear más features útiles\n",
    "print(\" Creando features temporales adicionales...\")\n",
    "\n",
    "# Verificar columnas temporales disponibles\n",
    "print(f\"\\n Columnas temporales disponibles:\")\n",
    "columnas_temporales = [col for col in dataset_modelado.columns if col in ['mes', 'dia_año', 'trimestre', 'dia_semana']]\n",
    "print(f\"  {columnas_temporales}\")\n",
    "\n",
    "# 1. Features cíclicos para capturar estacionalidad\n",
    "print(\"\\n Creando features cíclicos...\")\n",
    "\n",
    "if 'mes' in dataset_modelado.columns:\n",
    "    # Mes cíclico (sinusoidal y cosinusoidal)\n",
    "    dataset_modelado['mes_sin'] = np.sin(2 * np.pi * dataset_modelado['mes'] / 12)\n",
    "    dataset_modelado['mes_cos'] = np.cos(2 * np.pi * dataset_modelado['mes'] / 12)\n",
    "    print(\" Features cíclicos de mes creados\")\n",
    "\n",
    "if 'dia_año' in dataset_modelado.columns:\n",
    "    # Día del año cíclico\n",
    "    dataset_modelado['dia_año_sin'] = np.sin(2 * np.pi * dataset_modelado['dia_año'] / 365.25)\n",
    "    dataset_modelado['dia_año_cos'] = np.cos(2 * np.pi * dataset_modelado['dia_año'] / 365.25)\n",
    "    print(\" Features cíclicos de día del año creados\")\n",
    "\n",
    "if 'trimestre' in dataset_modelado.columns:\n",
    "    # Trimestre cíclico\n",
    "    dataset_modelado['trimestre_sin'] = np.sin(2 * np.pi * dataset_modelado['trimestre'] / 4)\n",
    "    dataset_modelado['trimestre_cos'] = np.cos(2 * np.pi * dataset_modelado['trimestre'] / 4)\n",
    "    print(\" Features cíclicos de trimestre creados\")\n",
    "\n",
    "# 2. Features de día de la semana (ya tenemos 'dia_semana', vamos a codificarlo)\n",
    "print(\"\\n Codificando día de la semana...\")\n",
    "\n",
    "if 'dia_semana' in dataset_modelado.columns:\n",
    "    # Verificar valores únicos en dia_semana\n",
    "    valores_dia_semana = sorted(dataset_modelado['dia_semana'].unique())\n",
    "    print(f\"Valores únicos en dia_semana: {valores_dia_semana}\")\n",
    "    \n",
    "    # Crear mapeo dinámico basado en valores reales\n",
    "    mapeo_dias_semana = {dia: i for i, dia in enumerate(valores_dia_semana)}\n",
    "    dataset_modelado['dia_semana_codificado'] = dataset_modelado['dia_semana'].map(mapeo_dias_semana)\n",
    "    \n",
    "    # Features cíclicos para día de la semana\n",
    "    dataset_modelado['dia_semana_sin'] = np.sin(2 * np.pi * dataset_modelado['dia_semana_codificado'] / 7)\n",
    "    dataset_modelado['dia_semana_cos'] = np.cos(2 * np.pi * dataset_modelado['dia_semana_codificado'] / 7)\n",
    "    \n",
    "    print(f\" Día de la semana codificado: {mapeo_dias_semana}\")\n",
    "else:\n",
    "    print(\" Columna 'dia_semana' no encontrada\")\n",
    "\n",
    "# 3. Features de fin de semana y días especiales\n",
    "print(\"\\n Creando features de días especiales...\")\n",
    "\n",
    "if 'dia_semana' in dataset_modelado.columns:\n",
    "    # Fin de semana (0 = día laboral, 1 = fin de semana)\n",
    "    # CORRECCIÓN: Usar valores reales encontrados\n",
    "    fin_semana_valores = ['Saturday', 'Sunday', 'Sábado', 'Domingo', 'saturday', 'sunday']\n",
    "    dataset_modelado['es_fin_semana'] = dataset_modelado['dia_semana'].isin(fin_semana_valores).astype(int)\n",
    "    print(\" Feature 'es_fin_semana' creado\")\n",
    "\n",
    "if 'mes' in dataset_modelado.columns:\n",
    "    # Meses de invierno/verano (para Chile: invierno = Jun-Aug, verano = Dec-Feb)\n",
    "    dataset_modelado['es_invierno'] = dataset_modelado['mes'].isin([6, 7, 8]).astype(int)\n",
    "    dataset_modelado['es_verano'] = dataset_modelado['mes'].isin([12, 1, 2]).astype(int)\n",
    "    print(\" Features 'es_invierno' y 'es_verano' creados\")\n",
    "    \n",
    "    # CORRECCIÓN: Trimestre del año fiscal (para análisis de políticas)\n",
    "    dataset_modelado['trimestre_fiscal'] = ((dataset_modelado['mes'] - 1) // 3) + 1\n",
    "    print(\" Feature 'trimestre_fiscal' creado\")\n",
    "\n",
    "# 4. Features de época del año\n",
    "print(\"\\n Creando features de época del año...\")\n",
    "\n",
    "if 'mes' in dataset_modelado.columns:\n",
    "    def obtener_epoca_año(mes):\n",
    "        \"\"\"\n",
    "        Determina la época del año basada en el mes\n",
    "        \"\"\"\n",
    "        if mes in [12, 1, 2]:\n",
    "            return 'verano'\n",
    "        elif mes in [3, 4, 5]:\n",
    "            return 'otoño'\n",
    "        elif mes in [6, 7, 8]:\n",
    "            return 'invierno'\n",
    "        else:  # 9, 10, 11\n",
    "            return 'primavera'\n",
    "\n",
    "    dataset_modelado['epoca_año'] = dataset_modelado['mes'].apply(obtener_epoca_año)\n",
    "    \n",
    "    # Codificar época del año\n",
    "    epocas_año = ['primavera', 'verano', 'otoño', 'invierno']\n",
    "    mapeo_epocas = {epoca: i for i, epoca in enumerate(epocas_año)}\n",
    "    dataset_modelado['epoca_año_codificada'] = dataset_modelado['epoca_año'].map(mapeo_epocas)\n",
    "    \n",
    "    print(\" Época del año codificada\")\n",
    "\n",
    "# Mostrar resumen de features creados\n",
    "print(f\"\\n Dataset con features temporales: {dataset_modelado.shape}\")\n",
    "\n",
    "# Mostrar nuevas columnas creadas\n",
    "nuevas_columnas_temporales = [col for col in dataset_modelado.columns if col.endswith(('_sin', '_cos', '_codificado', 'es_', 'epoca_', 'trimestre_fiscal'))]\n",
    "print(f\" Nuevas columnas temporales creadas: {len(nuevas_columnas_temporales)}\")\n",
    "for col in nuevas_columnas_temporales:\n",
    "    print(f\"   {col}\")\n",
    "\n",
    "print(f\"\\n Features temporales completados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30d8dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACIÓN DE VARIABLES DE TENDENCIA ===\n",
      " Dataset base para tendencias: (50, 23)\n",
      "\n",
      " Calculando promedios móviles...\n",
      " Promedios móviles creados: MA3 y MA5 para nacimientos y defunciones\n",
      "\n",
      " Calculando diferencias adicionales...\n",
      " Diferencias con promedios móviles creadas\n",
      "\n",
      " Calculando tasas de crecimiento...\n",
      " Tasas de crecimiento calculadas\n",
      "\n",
      " Calculando tendencias a largo plazo...\n",
      " Tendencias calculadas\n",
      "\n",
      " Calculando volatilidad...\n",
      " Volatilidad calculada\n",
      "\n",
      " Dataset con variables de tendencia: (50, 39)\n",
      " Nuevas columnas de tendencia creadas: 10\n",
      "   nacimientos_ma3\n",
      "   nacimientos_ma5\n",
      "   defunciones_ma3\n",
      "   defunciones_ma5\n",
      "   dif_nacimientos_ma3\n",
      "   dif_nacimientos_ma5\n",
      "   dif_defunciones_ma3\n",
      "   dif_defunciones_ma5\n",
      "   pct_cambio_nacimientos_ma3\n",
      "   pct_cambio_defunciones_ma3\n",
      "\n",
      " Variables de tendencia completadas\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Crear variables de tendencia para el dataset temporal unificado\n",
    "\n",
    "print(\"=== CREACIÓN DE VARIABLES DE TENDENCIA ===\")\n",
    "\n",
    "# Crear dataset de tendencias basado en el dataset unificado temporal\n",
    "dataset_tendencias = dataset_unificado.copy()\n",
    "print(f\" Dataset base para tendencias: {dataset_tendencias.shape}\")\n",
    "\n",
    "# 1. Promedios móviles\n",
    "print(\"\\n Calculando promedios móviles...\")\n",
    "\n",
    "# Promedio móvil de 3 años para nacimientos\n",
    "dataset_tendencias['nacimientos_ma3'] = dataset_tendencias['nacimientos_totales'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Promedio móvil de 5 años para nacimientos\n",
    "dataset_tendencias['nacimientos_ma5'] = dataset_tendencias['nacimientos_totales'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Promedio móvil de 3 años para defunciones\n",
    "dataset_tendencias['defunciones_ma3'] = dataset_tendencias['defunciones_totales'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Promedio móvil de 5 años para defunciones\n",
    "dataset_tendencias['defunciones_ma5'] = dataset_tendencias['defunciones_totales'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "print(\" Promedios móviles creados: MA3 y MA5 para nacimientos y defunciones\")\n",
    "\n",
    "# 2. Diferencias año a año (ya las tenemos, pero vamos a crear más)\n",
    "print(\"\\n Calculando diferencias adicionales...\")\n",
    "\n",
    "# Diferencia con promedio móvil\n",
    "dataset_tendencias['dif_nacimientos_ma3'] = dataset_tendencias['nacimientos_totales'] - dataset_tendencias['nacimientos_ma3']\n",
    "dataset_tendencias['dif_nacimientos_ma5'] = dataset_tendencias['nacimientos_totales'] - dataset_tendencias['nacimientos_ma5']\n",
    "dataset_tendencias['dif_defunciones_ma3'] = dataset_tendencias['defunciones_totales'] - dataset_tendencias['defunciones_ma3']\n",
    "dataset_tendencias['dif_defunciones_ma5'] = dataset_tendencias['defunciones_totales'] - dataset_tendencias['defunciones_ma5']\n",
    "\n",
    "print(\" Diferencias con promedios móviles creadas\")\n",
    "\n",
    "# 3. Tasas de crecimiento\n",
    "print(\"\\n Calculando tasas de crecimiento...\")\n",
    "\n",
    "# Tasa de crecimiento promedio móvil (CORREGIDO: evitar división por cero)\n",
    "dataset_tendencias['pct_cambio_nacimientos_ma3'] = np.where(\n",
    "    dataset_tendencias['nacimientos_ma3'] != 0,\n",
    "    (dataset_tendencias['dif_nacimientos_ma3'] / dataset_tendencias['nacimientos_ma3']) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "dataset_tendencias['pct_cambio_defunciones_ma3'] = np.where(\n",
    "    dataset_tendencias['defunciones_ma3'] != 0,\n",
    "    (dataset_tendencias['dif_defunciones_ma3'] / dataset_tendencias['defunciones_ma3']) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "print(\" Tasas de crecimiento calculadas\")\n",
    "\n",
    "# 4. Variables de tendencia a largo plazo (SIMPLIFICADO)\n",
    "print(\"\\n Calculando tendencias a largo plazo...\")\n",
    "\n",
    "# Tendencia simple (diferencia entre valores extremos de ventana)\n",
    "def calcular_tendencia_simple(serie, ventana=10):\n",
    "    \"\"\"\n",
    "    Calcula tendencia simple usando diferencia entre extremos\n",
    "    \"\"\"\n",
    "    tendencias = []\n",
    "    \n",
    "    for i in range(len(serie)):\n",
    "        inicio = max(0, i - ventana + 1)\n",
    "        fin = i + 1\n",
    "        \n",
    "        if fin - inicio >= 3:\n",
    "            valores_ventana = serie.iloc[inicio:fin]\n",
    "            if len(valores_ventana) > 1:\n",
    "                tendencia = valores_ventana.iloc[-1] - valores_ventana.iloc[0]\n",
    "            else:\n",
    "                tendencia = 0\n",
    "        else:\n",
    "            tendencia = 0\n",
    "            \n",
    "        tendencias.append(tendencia)\n",
    "    \n",
    "    return pd.Series(tendencias, index=serie.index)\n",
    "\n",
    "# Calcular tendencias simples\n",
    "dataset_tendencias['tendencia_nacimientos'] = calcular_tendencia_simple(dataset_tendencias['nacimientos_totales'])\n",
    "dataset_tendencias['tendencia_defunciones'] = calcular_tendencia_simple(dataset_tendencias['defunciones_totales'])\n",
    "\n",
    "print(\" Tendencias calculadas\")\n",
    "\n",
    "# 5. Variables de volatilidad\n",
    "print(\"\\n Calculando volatilidad...\")\n",
    "\n",
    "# Volatilidad (desviación estándar móvil)\n",
    "dataset_tendencias['volatilidad_nacimientos'] = dataset_tendencias['nacimientos_totales'].rolling(window=5, min_periods=1).std()\n",
    "dataset_tendencias['volatilidad_defunciones'] = dataset_tendencias['defunciones_totales'].rolling(window=5, min_periods=1).std()\n",
    "\n",
    "# Coeficiente de variación (CORREGIDO: evitar división por cero)\n",
    "dataset_tendencias['cv_nacimientos'] = np.where(\n",
    "    dataset_tendencias['nacimientos_ma5'] != 0,\n",
    "    dataset_tendencias['volatilidad_nacimientos'] / dataset_tendencias['nacimientos_ma5'],\n",
    "    0\n",
    ")\n",
    "\n",
    "dataset_tendencias['cv_defunciones'] = np.where(\n",
    "    dataset_tendencias['defunciones_ma5'] != 0,\n",
    "    dataset_tendencias['volatilidad_defunciones'] / dataset_tendencias['defunciones_ma5'],\n",
    "    0\n",
    ")\n",
    "\n",
    "print(\" Volatilidad calculada\")\n",
    "\n",
    "# Mostrar resumen de variables creadas\n",
    "print(f\"\\n Dataset con variables de tendencia: {dataset_tendencias.shape}\")\n",
    "\n",
    "# Mostrar nuevas columnas creadas\n",
    "nuevas_columnas_tendencia = [col for col in dataset_tendencias.columns if col.endswith(('_ma3', '_ma5', '_dif_', '_pct_', '_tendencia_', '_volatilidad_', '_cv_'))]\n",
    "print(f\" Nuevas columnas de tendencia creadas: {len(nuevas_columnas_tendencia)}\")\n",
    "for col in nuevas_columnas_tendencia:\n",
    "    print(f\"   {col}\")\n",
    "\n",
    "print(f\"\\n Variables de tendencia completadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07fa8255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACIÓN DE DATASET FINAL PARA MODELADO ===\n",
      " Combinando datasets para modelado...\n",
      " Dataset de defunciones detalladas: (1246037, 37)\n",
      " Dataset final para modelado de defunciones: (1246037, 23)\n",
      " Columnas seleccionadas: 23\n",
      "\n",
      " Verificando valores nulos:\n",
      " No hay valores nulos en el dataset final\n",
      "\n",
      " Tipos de datos:\n",
      "  int64: 9 columnas\n",
      "  float64: 9 columnas\n",
      "  int32: 4 columnas\n",
      "  datetime64[ns]: 1 columnas\n",
      "\n",
      " Estadísticas básicas de variables numéricas:\n",
      "Variables numéricas: 22\n",
      "              año  edad_cantidad  region_codificada  sexo_codificado  \\\n",
      "count  1246037.00     1246037.00         1246037.00       1246037.00   \n",
      "mean      2019.18          72.22              11.52             0.53   \n",
      "std          3.08          18.60               4.65             0.50   \n",
      "min       2014.00           0.00               0.00             0.00   \n",
      "25%       2017.00          63.00               9.00             0.00   \n",
      "50%       2019.00          76.00              12.00             1.00   \n",
      "75%       2022.00          86.00              16.00             1.00   \n",
      "max       2024.00         118.00              16.00             1.00   \n",
      "\n",
      "       rango_edad_codificado  categoria_diagnostico_codificada         mes  \\\n",
      "count             1246037.00                        1246037.00  1246037.00   \n",
      "mean                   14.71                              9.11        6.44   \n",
      "std                     4.11                              5.66        3.32   \n",
      "min                     0.00                              0.00        1.00   \n",
      "25%                    13.00                              3.00        4.00   \n",
      "50%                    16.00                             10.00        6.00   \n",
      "75%                    18.00                             15.00        9.00   \n",
      "max                    21.00                             17.00       12.00   \n",
      "\n",
      "        trimestre     dia_año     mes_sin     mes_cos  dia_año_sin  \\\n",
      "count  1246037.00  1246037.00  1246037.00  1246037.00   1246037.00   \n",
      "mean         2.48      180.54       -0.02       -0.07         0.01   \n",
      "std          1.08      101.34        0.70        0.71         0.70   \n",
      "min          1.00        1.00       -1.00       -1.00        -1.00   \n",
      "25%          2.00       96.00       -0.87       -0.87        -0.69   \n",
      "50%          2.00      181.00        0.00       -0.00         0.03   \n",
      "75%          3.00      263.00        0.50        0.50         0.69   \n",
      "max          4.00      366.00        1.00        1.00         1.00   \n",
      "\n",
      "       dia_año_cos  trimestre_sin  trimestre_cos  dia_semana_sin  \\\n",
      "count   1246037.00     1246037.00     1246037.00      1246037.00   \n",
      "mean         -0.07          -0.04          -0.05            0.00   \n",
      "std           0.71           0.71           0.70            0.71   \n",
      "min          -1.00          -1.00          -1.00           -0.97   \n",
      "25%          -0.79          -1.00          -1.00           -0.78   \n",
      "50%          -0.14           0.00          -0.00            0.00   \n",
      "75%           0.65           0.00           0.00            0.78   \n",
      "max           1.00           1.00           1.00            0.97   \n",
      "\n",
      "       dia_semana_cos  es_fin_semana  es_invierno   es_verano  \\\n",
      "count      1246037.00     1246037.00   1246037.00  1246037.00   \n",
      "mean            -0.00           0.29         0.29        0.23   \n",
      "std              0.71           0.45         0.45        0.42   \n",
      "min             -0.90           0.00         0.00        0.00   \n",
      "25%             -0.90           0.00         0.00        0.00   \n",
      "50%             -0.22           0.00         0.00        0.00   \n",
      "75%              0.62           1.00         1.00        0.00   \n",
      "max              1.00           1.00         1.00        1.00   \n",
      "\n",
      "       trimestre_fiscal  epoca_año_codificada  \n",
      "count        1246037.00            1246037.00  \n",
      "mean               2.48                  1.60  \n",
      "std                1.08                  1.13  \n",
      "min                1.00                  0.00  \n",
      "25%                2.00                  1.00  \n",
      "50%                2.00                  2.00  \n",
      "75%                3.00                  3.00  \n",
      "max                4.00                  3.00  \n",
      "\n",
      " GUARDANDO DATASET FINAL PARA MODELADO...\n",
      " Dataset final guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_final_modelado_defunciones.csv\n",
      " Dimensiones: (1246037, 23)\n",
      " Dataset de tendencias guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_temporales.csv\n",
      " Dimensiones: (50, 39)\n",
      " Mapeos de codificación guardados: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\mapeos_codificacion.json\n",
      "\n",
      " RESUMEN FINAL:\n",
      " Dataset final para modelado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_final_modelado_defunciones.csv\n",
      " Dataset de tendencias: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_temporales.csv\n",
      " Mapeos de codificación: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\mapeos_codificacion.json\n",
      " Todos los archivos guardados en: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\n",
      "\n",
      " PRÓXIMOS PASOS RECOMENDADOS:\n",
      "  1. Usar dataset_final_modelado_defunciones.csv para modelos de clasificación\n",
      "  2. Usar dataset_tendencias_temporales.csv para modelos de series temporales\n",
      "  3. Usar mapeos_codificacion.json para interpretar resultados\n"
     ]
    }
   ],
   "source": [
    "# 8.4 Crear dataset final para modelado con todas las features (CORREGIDO)\n",
    "\n",
    "print(\"=== CREACIÓN DE DATASET FINAL PARA MODELADO ===\")\n",
    "\n",
    "# Crear dataset final combinando todas las features creadas\n",
    "print(\" Combinando datasets para modelado...\")\n",
    "\n",
    "# Para el dataset de defunciones detalladas (dataset_modelado)\n",
    "print(f\" Dataset de defunciones detalladas: {dataset_modelado.shape}\")\n",
    "\n",
    "# Seleccionar columnas relevantes para modelado\n",
    "columnas_modelado = [\n",
    "    # Variables básicas\n",
    "    'año', 'fecha_defuncion', 'edad_cantidad',\n",
    "    \n",
    "    # Variables categóricas codificadas\n",
    "    'region_codificada', 'sexo_codificado', 'rango_edad_codificado', 'categoria_diagnostico_codificada',\n",
    "    \n",
    "    # Variables temporales básicas\n",
    "    'mes', 'trimestre', 'dia_año',\n",
    "    \n",
    "    # Features cíclicos\n",
    "    'mes_sin', 'mes_cos', 'dia_año_sin', 'dia_año_cos', 'trimestre_sin', 'trimestre_cos',\n",
    "    'dia_semana_sin', 'dia_semana_cos',\n",
    "    \n",
    "    # Features de días especiales\n",
    "    'es_fin_semana', 'es_invierno', 'es_verano', 'trimestre_fiscal', 'epoca_año_codificada'\n",
    "]\n",
    "\n",
    "# Crear dataset final para modelado de defunciones\n",
    "dataset_final_modelado = dataset_modelado[columnas_modelado].copy()\n",
    "\n",
    "print(f\" Dataset final para modelado de defunciones: {dataset_final_modelado.shape}\")\n",
    "print(f\" Columnas seleccionadas: {len(columnas_modelado)}\")\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(f\"\\n Verificando valores nulos:\")\n",
    "nulos_por_columna = dataset_final_modelado.isnull().sum()\n",
    "columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "if len(columnas_con_nulos) > 0:\n",
    "    print(\"Columnas con valores nulos:\")\n",
    "    for col, nulos in columnas_con_nulos.items():\n",
    "        print(f\"  {col}: {nulos} ({nulos/len(dataset_final_modelado)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\" No hay valores nulos en el dataset final\")\n",
    "\n",
    "# Mostrar tipos de datos\n",
    "print(f\"\\n Tipos de datos:\")\n",
    "tipos_datos = dataset_final_modelado.dtypes.value_counts()\n",
    "for tipo, cantidad in tipos_datos.items():\n",
    "    print(f\"  {tipo}: {cantidad} columnas\")\n",
    "\n",
    "# Mostrar estadísticas básicas de variables numéricas\n",
    "print(f\"\\n Estadísticas básicas de variables numéricas:\")\n",
    "variables_numericas = dataset_final_modelado.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Variables numéricas: {len(variables_numericas)}\")\n",
    "print(dataset_final_modelado[variables_numericas].describe().round(2))\n",
    "\n",
    "# AGREGAR: Guardar dataset final para modelado\n",
    "print(f\"\\n GUARDANDO DATASET FINAL PARA MODELADO...\")\n",
    "\n",
    "# CORRECCIÓN: Usar la carpeta correcta (03_primary)\n",
    "import os\n",
    "carpeta_final = r\"C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\"\n",
    "if not os.path.exists(carpeta_final):\n",
    "    os.makedirs(carpeta_final)\n",
    "    print(f\" Carpeta creada: {carpeta_final}\")\n",
    "\n",
    "# Guardar dataset final para modelado de defunciones\n",
    "ruta_dataset_final = os.path.join(carpeta_final, \"dataset_final_modelado_defunciones.csv\")\n",
    "dataset_final_modelado.to_csv(ruta_dataset_final, index=False)\n",
    "print(f\" Dataset final guardado: {ruta_dataset_final}\")\n",
    "print(f\" Dimensiones: {dataset_final_modelado.shape}\")\n",
    "\n",
    "# AGREGAR: También guardar dataset de tendencias\n",
    "ruta_dataset_tendencias = os.path.join(carpeta_final, \"dataset_tendencias_temporales.csv\")\n",
    "dataset_tendencias.to_csv(ruta_dataset_tendencias, index=False)\n",
    "print(f\" Dataset de tendencias guardado: {ruta_dataset_tendencias}\")\n",
    "print(f\" Dimensiones: {dataset_tendencias.shape}\")\n",
    "\n",
    "# AGREGAR: Guardar mapeos de codificación\n",
    "import json\n",
    "mapeos_codificacion = {\n",
    "    \"regiones\": mapeo_regiones,\n",
    "    \"sexo\": mapeo_sexo,\n",
    "    \"rangos_edad\": mapeo_rangos_edad,\n",
    "    \"categorias_diagnostico\": mapeo_categorias_diagnostico,\n",
    "    \"dias_semana\": mapeo_dias_semana,\n",
    "    \"epocas_año\": mapeo_epocas\n",
    "}\n",
    "\n",
    "ruta_mapeos = os.path.join(carpeta_final, \"mapeos_codificacion.json\")\n",
    "with open(ruta_mapeos, 'w', encoding='utf-8') as f:\n",
    "    json.dump(mapeos_codificacion, f, ensure_ascii=False, indent=2)\n",
    "print(f\" Mapeos de codificación guardados: {ruta_mapeos}\")\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\n RESUMEN FINAL:\")\n",
    "print(f\" Dataset final para modelado: {ruta_dataset_final}\")\n",
    "print(f\" Dataset de tendencias: {ruta_dataset_tendencias}\")\n",
    "print(f\" Mapeos de codificación: {ruta_mapeos}\")\n",
    "print(f\" Todos los archivos guardados en: {carpeta_final}\")\n",
    "\n",
    "print(f\"\\n PRÓXIMOS PASOS RECOMENDADOS:\")\n",
    "print(f\"  1. Usar dataset_final_modelado_defunciones.csv para modelos de clasificación\")\n",
    "print(f\"  2. Usar dataset_tendencias_temporales.csv para modelos de series temporales\")\n",
    "print(f\"  3. Usar mapeos_codificacion.json para interpretar resultados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4babecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN FINAL DE LA PREPARACIÓN PARA MODELADO ===\n",
      " Datasets creados para diferentes tipos de análisis:\n",
      "\n",
      "DATASET_FINAL_MODELADO:\n",
      "   Dimensiones: (1246037, 23)\n",
      "   Período temporal: 2014 - 2024\n",
      "   Columnas: 23\n",
      "\n",
      "DATASET_TENDENCIAS:\n",
      "   Dimensiones: (50, 39)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_MODELADO:\n",
      "   Dimensiones: (1246037, 37)\n",
      "   Período temporal: 2014 - 2024\n",
      "   Columnas: 37\n",
      "\n",
      "DATASET_EXTENDIDO:\n",
      "   Dimensiones: (10, 35)\n",
      "   Período temporal: 2014 - 2023\n",
      "   Columnas: 35\n",
      "\n",
      "DATASET_UNIFICADO:\n",
      "   Dimensiones: (50, 23)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 23\n",
      "\n",
      "=== FEATURES CREADAS PARA MODELADO ===\n",
      " Variables categóricas codificadas:\n",
      "   region_codificada\n",
      "   sexo_codificado\n",
      "   rango_edad_codificado\n",
      "   categoria_diagnostico_codificada\n",
      "   epoca_año_codificada\n",
      "\n",
      " Features temporales cíclicos:\n",
      "   mes_sin\n",
      "   mes_cos\n",
      "   dia_año_sin\n",
      "   dia_año_cos\n",
      "   trimestre_sin\n",
      "   trimestre_cos\n",
      "   dia_semana_sin\n",
      "   dia_semana_cos\n",
      "\n",
      " Features de días especiales:\n",
      "   es_fin_semana\n",
      "   es_invierno\n",
      "   es_verano\n",
      "   trimestre_fiscal\n",
      "\n",
      "📈 Variables de tendencia:\n",
      "   nacimientos_ma3\n",
      "   nacimientos_ma5\n",
      "   defunciones_ma3\n",
      "   defunciones_ma5\n",
      "   tendencia_nacimientos\n",
      "   tendencia_defunciones\n",
      "   volatilidad_nacimientos\n",
      "   volatilidad_defunciones\n",
      "\n",
      "=== ARCHIVOS GENERADOS PARA MODELADO ===\n",
      " data/03_primary/dataset_final_modelado_defunciones.csv\n",
      " data/03_primary/dataset_tendencias_temporales.csv\n",
      " data/03_primary/mapeos_codificacion.json\n",
      "\n",
      "=== CASOS DE USO PARA MODELADO ===\n",
      " Modelado de defunciones por región y edad:\n",
      "   - Dataset: dataset_final_modelado_defunciones.csv\n",
      "   - Features: region, edad, sexo, época del año, día de la semana\n",
      "   - Objetivo: Predecir patrones de mortalidad\n",
      "\n",
      " Análisis de tendencias temporales:\n",
      "   - Dataset: dataset_tendencias_temporales.csv\n",
      "   - Features: promedios móviles, tendencias lineales, volatilidad\n",
      "   - Objetivo: Predecir nacimientos/defunciones futuras\n",
      "\n",
      " Análisis estacional:\n",
      "   - Features: mes_sin/cos, día_semana_sin/cos, época del año\n",
      "   - Objetivo: Identificar patrones estacionales\n",
      "\n",
      " Preparación para modelado completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 8.5 Resumen final de la preparación para modelado (CORREGIDO)\n",
    "\n",
    "print(\"=== RESUMEN FINAL DE LA PREPARACIÓN PARA MODELADO ===\")\n",
    "\n",
    "# Crear resumen de todos los datasets creados\n",
    "datasets_finales = {\n",
    "    \"dataset_final_modelado\": dataset_final_modelado,\n",
    "    \"dataset_tendencias\": dataset_tendencias,\n",
    "    \"dataset_modelado\": dataset_modelado,\n",
    "    \"dataset_extendido\": dataset_extendido,\n",
    "    \"dataset_unificado\": dataset_unificado\n",
    "}\n",
    "\n",
    "print(\" Datasets creados para diferentes tipos de análisis:\")\n",
    "for nombre_dataset, df in datasets_finales.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    print(f\"   Período temporal: {df['año'].min()} - {df['año'].max()}\")\n",
    "    print(f\"   Columnas: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== FEATURES CREADAS PARA MODELADO ===\")\n",
    "\n",
    "# Variables categóricas codificadas\n",
    "print(\" Variables categóricas codificadas:\")\n",
    "categorias_creadas = [\n",
    "    \"region_codificada\", \"sexo_codificado\", \"rango_edad_codificado\", \n",
    "    \"categoria_diagnostico_codificada\", \"dia_semana_codificado\", \"epoca_año_codificada\"\n",
    "]\n",
    "for cat in categorias_creadas:\n",
    "    if cat in dataset_final_modelado.columns:\n",
    "        print(f\"   {cat}\")\n",
    "\n",
    "# Features temporales cíclicos\n",
    "print(\"\\n Features temporales cíclicos:\")\n",
    "features_ciclicos = [\n",
    "    \"mes_sin\", \"mes_cos\", \"dia_año_sin\", \"dia_año_cos\", \n",
    "    \"trimestre_sin\", \"trimestre_cos\", \"dia_semana_sin\", \"dia_semana_cos\"\n",
    "]\n",
    "for feat in features_ciclicos:\n",
    "    if feat in dataset_final_modelado.columns:\n",
    "        print(f\"   {feat}\")\n",
    "\n",
    "# Features de días especiales\n",
    "print(\"\\n Features de días especiales:\")\n",
    "features_especiales = [\n",
    "    \"es_fin_semana\", \"es_invierno\", \"es_verano\", \"trimestre_fiscal\"\n",
    "]\n",
    "for feat in features_especiales:\n",
    "    if feat in dataset_final_modelado.columns:\n",
    "        print(f\"   {feat}\")\n",
    "\n",
    "# Variables de tendencia\n",
    "print(\"\\n📈 Variables de tendencia:\")\n",
    "variables_tendencia = [\n",
    "    \"nacimientos_ma3\", \"nacimientos_ma5\", \"defunciones_ma3\", \"defunciones_ma5\",\n",
    "    \"tendencia_nacimientos\", \"tendencia_defunciones\", \"volatilidad_nacimientos\", \"volatilidad_defunciones\"\n",
    "]\n",
    "for var in variables_tendencia:\n",
    "    if var in dataset_tendencias.columns:\n",
    "        print(f\"   {var}\")\n",
    "\n",
    "print(\"\\n=== ARCHIVOS GENERADOS PARA MODELADO ===\")\n",
    "# CORRECCIÓN: Usar rutas correctas\n",
    "archivos_modelado = [\n",
    "    \"dataset_final_modelado_defunciones.csv\",\n",
    "    \"dataset_tendencias_temporales.csv\", \n",
    "    \"mapeos_codificacion.json\"\n",
    "]\n",
    "\n",
    "for archivo in archivos_modelado:\n",
    "    print(f\" data/03_primary/{archivo}\")\n",
    "\n",
    "print(\"\\n=== CASOS DE USO PARA MODELADO ===\")\n",
    "print(\" Modelado de defunciones por región y edad:\")\n",
    "print(\"   - Dataset: dataset_final_modelado_defunciones.csv\")\n",
    "print(\"   - Features: region, edad, sexo, época del año, día de la semana\")\n",
    "print(\"   - Objetivo: Predecir patrones de mortalidad\")\n",
    "\n",
    "print(\"\\n Análisis de tendencias temporales:\")\n",
    "print(\"   - Dataset: dataset_tendencias_temporales.csv\")\n",
    "print(\"   - Features: promedios móviles, tendencias lineales, volatilidad\")\n",
    "print(\"   - Objetivo: Predecir nacimientos/defunciones futuras\")\n",
    "\n",
    "print(\"\\n Análisis estacional:\")\n",
    "print(\"   - Features: mes_sin/cos, día_semana_sin/cos, época del año\")\n",
    "print(\"   - Objetivo: Identificar patrones estacionales\")\n",
    "\n",
    "print(\"\\n Preparación para modelado completada exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d55df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NORMALIZACIÓN DE ESCALAS ===\n",
      " Normalizando escalas para comparaciones entre variables...\n",
      "\n",
      " Identificando variables para normalización...\n",
      "Variables numéricas en dataset de modelado: 22\n",
      "Variables: ['año', 'edad_cantidad', 'region_codificada', 'sexo_codificado', 'rango_edad_codificado', 'categoria_diagnostico_codificada', 'mes', 'trimestre', 'dia_año', 'mes_sin', 'mes_cos', 'dia_año_sin', 'dia_año_cos', 'trimestre_sin', 'trimestre_cos', 'dia_semana_sin', 'dia_semana_cos', 'es_fin_semana', 'es_invierno', 'es_verano', 'trimestre_fiscal', 'epoca_año_codificada']\n",
      "\n",
      "Variables numéricas en dataset de tendencias: 39\n",
      "\n",
      " Normalizando dataset de modelado...\n",
      "Variables a normalizar en modelado: ['año', 'edad_cantidad', 'mes', 'trimestre', 'dia_año', 'mes_sin', 'mes_cos', 'dia_año_sin', 'dia_año_cos', 'trimestre_sin', 'trimestre_cos', 'dia_semana_sin', 'dia_semana_cos', 'trimestre_fiscal']\n",
      " Dataset de modelado normalizado con StandardScaler\n",
      "\n",
      " Normalizando dataset de tendencias...\n",
      "Variables a normalizar en tendencias: 38\n",
      " Dataset de tendencias normalizado con StandardScaler\n",
      "\n",
      " Creando versiones con diferentes tipos de normalización...\n",
      " Versiones creadas con MinMaxScaler y RobustScaler\n",
      "\n",
      " Comparación de escalas antes y después de normalización:\n",
      "Variables principales en dataset de tendencias:\n",
      "\n",
      "NACIMIENTOS_TOTALES:\n",
      "  Original - Min: 171992.00, Max: 292146.00, Media: 243175.12\n",
      "  StandardScaler - Min: -2.76, Max: 1.90, Media: 0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.59\n",
      "  RobustScaler - Min: -2.86, Max: 1.76, Media: -0.12\n",
      "\n",
      "DEFUNCIONES_TOTALES:\n",
      "  Original - Min: 69887.00, Max: 137439.00, Media: 87280.06\n",
      "  StandardScaler - Min: -1.03, Max: 2.97, Media: 0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.26\n",
      "  RobustScaler - Min: -0.46, Max: 2.52, Media: 0.30\n",
      "\n",
      "CRECIMIENTO_NATURAL:\n",
      "  Original - Min: 39816.00, Max: 213712.00, Media: 155895.06\n",
      "  StandardScaler - Min: -2.92, Max: 1.46, Media: 0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.67\n",
      "  RobustScaler - Min: -3.24, Max: 1.48, Media: -0.09\n",
      "\n",
      "RATIO_NACIMIENTOS_SEXO:\n",
      "  Original - Min: 1.03, Max: 1.05, Media: 1.04\n",
      "  StandardScaler - Min: -1.88, Max: 1.96, Media: -0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.49\n",
      "  RobustScaler - Min: -5.50, Max: 5.50, Media: -0.11\n",
      "\n",
      " Datasets normalizados creados:\n",
      "  - dataset_modelado_normalizado: (1246037, 23)\n",
      "  - dataset_tendencias_normalizado: (50, 39)\n",
      "  - dataset_tendencias_minmax: (50, 39)\n",
      "  - dataset_tendencias_robust: (50, 39)\n"
     ]
    }
   ],
   "source": [
    "# 8.6 Normalización de escalas para comparaciones entre variables\n",
    "\n",
    "print(\"=== NORMALIZACIÓN DE ESCALAS ===\")\n",
    "\n",
    "# Importar librerías para normalización\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "print(\" Normalizando escalas para comparaciones entre variables...\")\n",
    "\n",
    "# 1. Identificar variables que necesitan normalización\n",
    "print(\"\\n Identificando variables para normalización...\")\n",
    "\n",
    "# Variables numéricas en el dataset de modelado\n",
    "variables_numericas_modelado = dataset_final_modelado.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Variables numéricas en dataset de modelado: {len(variables_numericas_modelado)}\")\n",
    "print(f\"Variables: {variables_numericas_modelado}\")\n",
    "\n",
    "# Variables numéricas en el dataset de tendencias\n",
    "variables_numericas_tendencias = dataset_tendencias.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nVariables numéricas en dataset de tendencias: {len(variables_numericas_tendencias)}\")\n",
    "\n",
    "# 2. Normalización del dataset de modelado\n",
    "print(\"\\n Normalizando dataset de modelado...\")\n",
    "\n",
    "# Crear copia para normalización\n",
    "dataset_modelado_normalizado = dataset_final_modelado.copy()\n",
    "\n",
    "# Variables a normalizar (excluir códigos categóricos que ya están normalizados)\n",
    "variables_a_normalizar_modelado = [col for col in variables_numericas_modelado \n",
    "                                 if col not in ['region_codificada', 'sexo_codificado', 'rango_edad_codificado', \n",
    "                                               'categoria_diagnostico_codificada', 'dia_semana_codificado', \n",
    "                                               'epoca_año_codificada', 'es_fin_semana', 'es_invierno', 'es_verano']]\n",
    "\n",
    "print(f\"Variables a normalizar en modelado: {variables_a_normalizar_modelado}\")\n",
    "\n",
    "# Aplicar StandardScaler (media=0, desviación=1)\n",
    "scaler_modelado = StandardScaler()\n",
    "dataset_modelado_normalizado[variables_a_normalizar_modelado] = scaler_modelado.fit_transform(\n",
    "    dataset_modelado_normalizado[variables_a_normalizar_modelado]\n",
    ")\n",
    "\n",
    "print(\" Dataset de modelado normalizado con StandardScaler\")\n",
    "\n",
    "# 3. Normalización del dataset de tendencias\n",
    "print(\"\\n Normalizando dataset de tendencias...\")\n",
    "\n",
    "# Crear copia para normalización\n",
    "dataset_tendencias_normalizado = dataset_tendencias.copy()\n",
    "\n",
    "# Variables a normalizar (excluir año y variables ya normalizadas)\n",
    "variables_a_normalizar_tendencias = [col for col in variables_numericas_tendencias \n",
    "                                   if col not in ['año'] and not col.endswith('_codificado')]\n",
    "\n",
    "print(f\"Variables a normalizar en tendencias: {len(variables_a_normalizar_tendencias)}\")\n",
    "\n",
    "# Aplicar diferentes tipos de normalización\n",
    "# StandardScaler para la mayoría de variables\n",
    "scaler_tendencias_std = StandardScaler()\n",
    "dataset_tendencias_normalizado[variables_a_normalizar_tendencias] = scaler_tendencias_std.fit_transform(\n",
    "    dataset_tendencias_normalizado[variables_a_normalizar_tendencias]\n",
    ")\n",
    "\n",
    "print(\" Dataset de tendencias normalizado con StandardScaler\")\n",
    "\n",
    "# 4. Crear versiones con diferentes tipos de normalización para comparación\n",
    "print(\"\\n Creando versiones con diferentes tipos de normalización...\")\n",
    "\n",
    "# MinMaxScaler (escala 0-1)\n",
    "dataset_tendencias_minmax = dataset_tendencias.copy()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "dataset_tendencias_minmax[variables_a_normalizar_tendencias] = scaler_minmax.fit_transform(\n",
    "    dataset_tendencias_minmax[variables_a_normalizar_tendencias]\n",
    ")\n",
    "\n",
    "# RobustScaler (resistente a outliers)\n",
    "dataset_tendencias_robust = dataset_tendencias.copy()\n",
    "scaler_robust = RobustScaler()\n",
    "dataset_tendencias_robust[variables_a_normalizar_tendencias] = scaler_robust.fit_transform(\n",
    "    dataset_tendencias_robust[variables_a_normalizar_tendencias]\n",
    ")\n",
    "\n",
    "print(\" Versiones creadas con MinMaxScaler y RobustScaler\")\n",
    "\n",
    "# 5. Mostrar comparación de escalas antes y después\n",
    "print(\"\\n Comparación de escalas antes y después de normalización:\")\n",
    "print(\"Variables principales en dataset de tendencias:\")\n",
    "\n",
    "variables_principales = ['nacimientos_totales', 'defunciones_totales', 'crecimiento_natural', 'ratio_nacimientos_sexo']\n",
    "\n",
    "for var in variables_principales:\n",
    "    if var in dataset_tendencias.columns:\n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        print(f\"  Original - Min: {dataset_tendencias[var].min():.2f}, Max: {dataset_tendencias[var].max():.2f}, Media: {dataset_tendencias[var].mean():.2f}\")\n",
    "        print(f\"  StandardScaler - Min: {dataset_tendencias_normalizado[var].min():.2f}, Max: {dataset_tendencias_normalizado[var].max():.2f}, Media: {dataset_tendencias_normalizado[var].mean():.2f}\")\n",
    "        print(f\"  MinMaxScaler - Min: {dataset_tendencias_minmax[var].min():.2f}, Max: {dataset_tendencias_minmax[var].max():.2f}, Media: {dataset_tendencias_minmax[var].mean():.2f}\")\n",
    "        print(f\"  RobustScaler - Min: {dataset_tendencias_robust[var].min():.2f}, Max: {dataset_tendencias_robust[var].max():.2f}, Media: {dataset_tendencias_robust[var].mean():.2f}\")\n",
    "\n",
    "print(f\"\\n Datasets normalizados creados:\")\n",
    "print(f\"  - dataset_modelado_normalizado: {dataset_modelado_normalizado.shape}\")\n",
    "print(f\"  - dataset_tendencias_normalizado: {dataset_tendencias_normalizado.shape}\")\n",
    "print(f\"  - dataset_tendencias_minmax: {dataset_tendencias_minmax.shape}\")\n",
    "print(f\"  - dataset_tendencias_robust: {dataset_tendencias_robust.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4efc0919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASETS NORMALIZADOS ===\n",
      " Dataset de modelado normalizado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_modelado_defunciones_normalizado.csv\n",
      " Dataset de tendencias normalizado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_normalizado.csv\n",
      " Dataset de tendencias MinMax guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_minmax.csv\n",
      " Dataset de tendencias Robust guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_robust.csv\n",
      " Scalers guardados: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\scalers_normalizacion.pkl\n",
      "\n",
      " Verificando archivos normalizados:\n",
      "   dataset_modelado_defunciones_normalizado.csv: 364.55 MB\n",
      "   dataset_tendencias_normalizado.csv: 0.03 MB\n",
      "   dataset_tendencias_minmax.csv: 0.03 MB\n",
      "   dataset_tendencias_robust.csv: 0.03 MB\n",
      "   scalers_normalizacion.pkl: 0.01 MB\n",
      "\n",
      " RESUMEN DE ARCHIVOS NORMALIZADOS:\n",
      " Todos los archivos guardados en: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\n",
      " 4 datasets normalizados + 1 archivo de scalers\n",
      "\n",
      " Normalización de escalas completada\n"
     ]
    }
   ],
   "source": [
    "# 8.7 Guardar datasets normalizados (CORREGIDO)\n",
    "\n",
    "print(\"=== GUARDANDO DATASETS NORMALIZADOS ===\")\n",
    "\n",
    "# CORRECCIÓN: Usar carpeta 03_primary\n",
    "carpeta_normalizados = r\"C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\"\n",
    "\n",
    "# Guardar datasets normalizados\n",
    "ruta_modelado_normalizado = os.path.join(carpeta_normalizados, \"dataset_modelado_defunciones_normalizado.csv\")\n",
    "dataset_modelado_normalizado.to_csv(ruta_modelado_normalizado, index=False)\n",
    "print(f\" Dataset de modelado normalizado guardado: {ruta_modelado_normalizado}\")\n",
    "\n",
    "ruta_tendencias_normalizado = os.path.join(carpeta_normalizados, \"dataset_tendencias_normalizado.csv\")\n",
    "dataset_tendencias_normalizado.to_csv(ruta_tendencias_normalizado, index=False)\n",
    "print(f\" Dataset de tendencias normalizado guardado: {ruta_tendencias_normalizado}\")\n",
    "\n",
    "ruta_tendencias_minmax = os.path.join(carpeta_normalizados, \"dataset_tendencias_minmax.csv\")\n",
    "dataset_tendencias_minmax.to_csv(ruta_tendencias_minmax, index=False)\n",
    "print(f\" Dataset de tendencias MinMax guardado: {ruta_tendencias_minmax}\")\n",
    "\n",
    "ruta_tendencias_robust = os.path.join(carpeta_normalizados, \"dataset_tendencias_robust.csv\")\n",
    "dataset_tendencias_robust.to_csv(ruta_tendencias_robust, index=False)\n",
    "print(f\" Dataset de tendencias Robust guardado: {ruta_tendencias_robust}\")\n",
    "\n",
    "# Guardar scalers para uso posterior\n",
    "import pickle\n",
    "\n",
    "# Guardar scalers\n",
    "scalers_info = {\n",
    "    'scaler_modelado': scaler_modelado,\n",
    "    'scaler_tendencias_std': scaler_tendencias_std,\n",
    "    'scaler_minmax': scaler_minmax,\n",
    "    'scaler_robust': scaler_robust,\n",
    "    'variables_modelado': variables_a_normalizar_modelado,\n",
    "    'variables_tendencias': variables_a_normalizar_tendencias\n",
    "}\n",
    "\n",
    "ruta_scalers = os.path.join(carpeta_normalizados, \"scalers_normalizacion.pkl\")\n",
    "with open(ruta_scalers, 'wb') as f:\n",
    "    pickle.dump(scalers_info, f)\n",
    "print(f\" Scalers guardados: {ruta_scalers}\")\n",
    "\n",
    "# Verificar archivos guardados\n",
    "archivos_normalizados = [\n",
    "    ruta_modelado_normalizado,\n",
    "    ruta_tendencias_normalizado,\n",
    "    ruta_tendencias_minmax,\n",
    "    ruta_tendencias_robust,\n",
    "    ruta_scalers\n",
    "]\n",
    "\n",
    "print(f\"\\n Verificando archivos normalizados:\")\n",
    "for archivo in archivos_normalizados:\n",
    "    if os.path.exists(archivo):\n",
    "        tamaño = os.path.getsize(archivo) / (1024*1024)\n",
    "        print(f\"   {os.path.basename(archivo)}: {tamaño:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"   {os.path.basename(archivo)}: No encontrado\")\n",
    "\n",
    "print(f\"\\n RESUMEN DE ARCHIVOS NORMALIZADOS:\")\n",
    "print(f\" Todos los archivos guardados en: {carpeta_normalizados}\")\n",
    "print(f\" 4 datasets normalizados + 1 archivo de scalers\")\n",
    "\n",
    "print(\"\\n Normalización de escalas completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45776b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN FINAL ACTUALIZADO CON NORMALIZACIÓN ===\n",
      " Datasets finales creados (incluyendo versiones normalizadas):\n",
      "\n",
      "DATASET_FINAL_MODELADO:\n",
      "   Dimensiones: (1246037, 23)\n",
      "   Período temporal: 2014 - 2024\n",
      "   Columnas: 23\n",
      "\n",
      "DATASET_MODELADO_NORMALIZADO:\n",
      "   Dimensiones: (1246037, 23)\n",
      "   Período temporal: -1.6796752733960778 - 1.56487523619281\n",
      "   Columnas: 23\n",
      "\n",
      "DATASET_TENDENCIAS:\n",
      "   Dimensiones: (50, 39)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_TENDENCIAS_NORMALIZADO:\n",
      "   Dimensiones: (50, 39)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_TENDENCIAS_MINMAX:\n",
      "   Dimensiones: (50, 39)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_TENDENCIAS_ROBUST:\n",
      "   Dimensiones: (50, 39)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_EXTENDIDO:\n",
      "   Dimensiones: (10, 35)\n",
      "   Período temporal: 2014 - 2023\n",
      "   Columnas: 35\n",
      "\n",
      "DATASET_UNIFICADO:\n",
      "   Dimensiones: (50, 23)\n",
      "   Período temporal: 1974 - 2023\n",
      "   Columnas: 23\n",
      "\n",
      "=== TIPOS DE NORMALIZACIÓN IMPLEMENTADOS ===\n",
      " StandardScaler (media=0, desviación=1):\n",
      "    dataset_modelado_normalizado\n",
      "    dataset_tendencias_normalizado\n",
      "    Uso: Algoritmos que asumen distribución normal (regresión lineal, SVM)\n",
      "\n",
      " MinMaxScaler (escala 0-1):\n",
      "    dataset_tendencias_minmax\n",
      "    Uso: Algoritmos sensibles a la escala (redes neuronales, k-means)\n",
      "\n",
      " RobustScaler (resistente a outliers):\n",
      "    dataset_tendencias_robust\n",
      "    Uso: Datos con outliers significativos\n",
      "\n",
      "=== ARCHIVOS GENERADOS COMPLETOS ===\n",
      " data/03_primary/dataset_final_modelado_defunciones.csv\n",
      " data/03_primary/dataset_modelado_defunciones_normalizado.csv\n",
      " data/03_primary/dataset_tendencias_temporales.csv\n",
      " data/03_primary/dataset_tendencias_normalizado.csv\n",
      " data/03_primary/dataset_tendencias_minmax.csv\n",
      " data/03_primary/dataset_tendencias_robust.csv\n",
      " data/03_primary/mapeos_codificacion.json\n",
      " data/03_primary/scalers_normalizacion.pkl\n",
      "\n",
      "=== BENEFICIOS DE LA NORMALIZACIÓN ===\n",
      " Comparaciones justas entre variables de diferentes magnitudes\n",
      " Mejor rendimiento en algoritmos de Machine Learning\n",
      " Reducción del sesgo hacia variables con escalas mayores\n",
      " Facilita la interpretación de coeficientes en modelos\n",
      " Mejora la convergencia en algoritmos iterativos\n",
      "\n",
      "=== RECOMENDACIONES DE USO ===\n",
      " Para regresión lineal y SVM: usar StandardScaler\n",
      " Para redes neuronales: usar MinMaxScaler\n",
      " Para datos con outliers: usar RobustScaler\n",
      " Para comparaciones visuales: usar MinMaxScaler\n",
      "\n",
      " Preparación completa para modelado con normalización terminada\n"
     ]
    }
   ],
   "source": [
    "# 8.9 Actualizar resumen final con normalización (CORREGIDO)\n",
    "\n",
    "print(\"=== RESUMEN FINAL ACTUALIZADO CON NORMALIZACIÓN ===\")\n",
    "\n",
    "# Actualizar resumen de datasets creados\n",
    "datasets_finales_completos = {\n",
    "    \"dataset_final_modelado\": dataset_final_modelado,\n",
    "    \"dataset_modelado_normalizado\": dataset_modelado_normalizado,\n",
    "    \"dataset_tendencias\": dataset_tendencias,\n",
    "    \"dataset_tendencias_normalizado\": dataset_tendencias_normalizado,\n",
    "    \"dataset_tendencias_minmax\": dataset_tendencias_minmax,\n",
    "    \"dataset_tendencias_robust\": dataset_tendencias_robust,\n",
    "    \"dataset_extendido\": dataset_extendido,\n",
    "    \"dataset_unificado\": dataset_unificado\n",
    "}\n",
    "\n",
    "print(\" Datasets finales creados (incluyendo versiones normalizadas):\")\n",
    "for nombre_dataset, df in datasets_finales_completos.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    print(f\"   Período temporal: {df['año'].min()} - {df['año'].max()}\")\n",
    "    print(f\"   Columnas: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== TIPOS DE NORMALIZACIÓN IMPLEMENTADOS ===\")\n",
    "\n",
    "print(\" StandardScaler (media=0, desviación=1):\")\n",
    "print(\"    dataset_modelado_normalizado\")\n",
    "print(\"    dataset_tendencias_normalizado\")\n",
    "print(\"    Uso: Algoritmos que asumen distribución normal (regresión lineal, SVM)\")\n",
    "\n",
    "print(\"\\n MinMaxScaler (escala 0-1):\")\n",
    "print(\"    dataset_tendencias_minmax\")\n",
    "print(\"    Uso: Algoritmos sensibles a la escala (redes neuronales, k-means)\")\n",
    "\n",
    "print(\"\\n RobustScaler (resistente a outliers):\")\n",
    "print(\"    dataset_tendencias_robust\")\n",
    "print(\"    Uso: Datos con outliers significativos\")\n",
    "\n",
    "print(\"\\n=== ARCHIVOS GENERADOS COMPLETOS ===\")\n",
    "# CORRECCIÓN: Usar rutas correctas\n",
    "archivos_completos = [\n",
    "    \"dataset_final_modelado_defunciones.csv\",\n",
    "    \"dataset_modelado_defunciones_normalizado.csv\",\n",
    "    \"dataset_tendencias_temporales.csv\",\n",
    "    \"dataset_tendencias_normalizado.csv\",\n",
    "    \"dataset_tendencias_minmax.csv\",\n",
    "    \"dataset_tendencias_robust.csv\",\n",
    "    \"mapeos_codificacion.json\",\n",
    "    \"scalers_normalizacion.pkl\"\n",
    "]\n",
    "\n",
    "for archivo in archivos_completos:\n",
    "    print(f\" data/03_primary/{archivo}\")\n",
    "\n",
    "print(\"\\n=== BENEFICIOS DE LA NORMALIZACIÓN ===\")\n",
    "print(\" Comparaciones justas entre variables de diferentes magnitudes\")\n",
    "print(\" Mejor rendimiento en algoritmos de Machine Learning\")\n",
    "print(\" Reducción del sesgo hacia variables con escalas mayores\")\n",
    "print(\" Facilita la interpretación de coeficientes en modelos\")\n",
    "print(\" Mejora la convergencia en algoritmos iterativos\")\n",
    "\n",
    "print(\"\\n=== RECOMENDACIONES DE USO ===\")\n",
    "print(\" Para regresión lineal y SVM: usar StandardScaler\")\n",
    "print(\" Para redes neuronales: usar MinMaxScaler\")\n",
    "print(\" Para datos con outliers: usar RobustScaler\")\n",
    "print(\" Para comparaciones visuales: usar MinMaxScaler\")\n",
    "\n",
    "print(\"\\n Preparación completa para modelado con normalización terminada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77ddeb",
   "metadata": {},
   "source": [
    "## 9. Manejo Avanzado de Códigos CIE-10\n",
    "\n",
    "Esta sección se enfoca en validar y mejorar el manejo de códigos de diagnóstico CIE-10 para análisis más robustos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06fa7a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACIÓN DE CÓDIGOS CIE-10 ===\n",
      " Analizando códigos de diagnóstico...\n",
      " Total de códigos únicos encontrados: 20\n",
      "\n",
      " Primeros 10 códigos encontrados:\n",
      "   1. A00-B99\n",
      "   2. C00-D48\n",
      "   3. D50-D89\n",
      "   4. E00-E90\n",
      "   5. F00-F99\n",
      "   6. G00-G99\n",
      "   7. H00-H59\n",
      "   8. H60-H95\n",
      "   9. I00-I99\n",
      "  10. J00-J99\n",
      "\n",
      " Análisis de patrones de códigos:\n",
      "  Códigos que empiezan con letra: 20\n",
      "  Códigos que empiezan con número: 0\n",
      "  Códigos nulos: 0\n",
      "  Códigos con formato extraño: 0\n",
      "\n",
      " Validación de códigos CIE-10:\n",
      "  Códigos CIE-10 válidos: 20\n",
      "  Códigos CIE-10 inválidos: 0\n",
      "\n",
      " Distribución por letra inicial:\n",
      "  A: 1 códigos\n",
      "  C: 1 códigos\n",
      "  D: 1 códigos\n",
      "  E: 1 códigos\n",
      "  F: 1 códigos\n",
      "  G: 1 códigos\n",
      "  H: 2 códigos\n",
      "  I: 1 códigos\n",
      "  J: 1 códigos\n",
      "  K: 1 códigos\n",
      "  L: 1 códigos\n",
      "  M: 1 códigos\n",
      "  N: 1 códigos\n",
      "  O: 1 códigos\n",
      "  P: 1 códigos\n",
      "  Q: 1 códigos\n",
      "  R: 1 códigos\n",
      "  S: 1 códigos\n",
      "  U: 1 códigos\n"
     ]
    }
   ],
   "source": [
    "# 9.1 Validación de códigos CIE-10\n",
    "\n",
    "print(\"=== VALIDACIÓN DE CÓDIGOS CIE-10 ===\")\n",
    "\n",
    "# Analizar códigos de diagnóstico en el dataset\n",
    "print(\" Analizando códigos de diagnóstico...\")\n",
    "\n",
    "# Obtener códigos únicos\n",
    "codigos_unicos = defunciones_estandarizado['codigo_diagnostico'].unique()\n",
    "print(f\" Total de códigos únicos encontrados: {len(codigos_unicos)}\")\n",
    "\n",
    "# Mostrar algunos ejemplos\n",
    "print(f\"\\n Primeros 10 códigos encontrados:\")\n",
    "for i, codigo in enumerate(sorted(codigos_unicos)[:10]):\n",
    "    print(f\"  {i+1:2d}. {codigo}\")\n",
    "\n",
    "# Analizar patrones de códigos\n",
    "print(f\"\\n Análisis de patrones de códigos:\")\n",
    "\n",
    "# Códigos que empiezan con letras (códigos CIE-10 válidos)\n",
    "codigos_con_letra = [codigo for codigo in codigos_unicos if pd.notna(codigo) and str(codigo)[0].isalpha()]\n",
    "print(f\"  Códigos que empiezan con letra: {len(codigos_con_letra)}\")\n",
    "\n",
    "# Códigos que empiezan con números\n",
    "codigos_con_numero = [codigo for codigo in codigos_unicos if pd.notna(codigo) and str(codigo)[0].isdigit()]\n",
    "print(f\"  Códigos que empiezan con número: {len(codigos_con_numero)}\")\n",
    "\n",
    "# Códigos nulos o vacíos\n",
    "codigos_nulos = [codigo for codigo in codigos_unicos if pd.isna(codigo)]\n",
    "print(f\"  Códigos nulos: {len(codigos_nulos)}\")\n",
    "\n",
    "# Códigos con formato extraño\n",
    "codigos_raros = [codigo for codigo in codigos_unicos if pd.notna(codigo) and not str(codigo)[0].isalnum()]\n",
    "print(f\"  Códigos con formato extraño: {len(codigos_raros)}\")\n",
    "\n",
    "if len(codigos_raros) > 0:\n",
    "    print(f\"    Ejemplos: {codigos_raros[:5]}\")\n",
    "\n",
    "# Verificar códigos CIE-10 válidos\n",
    "print(f\"\\n Validación de códigos CIE-10:\")\n",
    "letras_validas_cie10 = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "codigos_validos = []\n",
    "codigos_invalidos = []\n",
    "\n",
    "for codigo in codigos_con_letra:\n",
    "    if str(codigo)[0] in letras_validas_cie10:\n",
    "        codigos_validos.append(codigo)\n",
    "    else:\n",
    "        codigos_invalidos.append(codigo)\n",
    "\n",
    "print(f\"  Códigos CIE-10 válidos: {len(codigos_validos)}\")\n",
    "print(f\"  Códigos CIE-10 inválidos: {len(codigos_invalidos)}\")\n",
    "\n",
    "if len(codigos_invalidos) > 0:\n",
    "    print(f\"    Códigos inválidos: {codigos_invalidos[:5]}\")\n",
    "\n",
    "# Mostrar distribución por letra inicial\n",
    "print(f\"\\n Distribución por letra inicial:\")\n",
    "distribucion_letras = {}\n",
    "for codigo in codigos_validos:\n",
    "    letra = str(codigo)[0]\n",
    "    distribucion_letras[letra] = distribucion_letras.get(letra, 0) + 1\n",
    "\n",
    "for letra in sorted(distribucion_letras.keys()):\n",
    "    print(f\"  {letra}: {distribucion_letras[letra]:,} códigos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bab63429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEJORA DE CATEGORIZACIÓN CIE-10 ===\n",
      " Aplicando categorización mejorada...\n",
      "\n",
      " Distribución de categorías mejoradas:\n",
      "  enfermedades_cardiovasculares      :  314,610 ( 25.2%)\n",
      "  neoplasias_hematologicas           :  308,859 ( 24.8%)\n",
      "  enfermedades_respiratorias         :  129,914 ( 10.4%)\n",
      "  enfermedades_digestivas            :   89,496 (  7.2%)\n",
      "  traumatismos_envenenamientos       :   84,968 (  6.8%)\n",
      "  causas_externas_especiales         :   57,783 (  4.6%)\n",
      "  enfermedades_endocrinas_nutricionales:   56,280 (  4.5%)\n",
      "  enfermedades_sistema_nervioso      :   47,920 (  3.8%)\n",
      "  enfermedades_genitourinarias       :   37,398 (  3.0%)\n",
      "  sintomas_signos_anormales          :   34,995 (  2.8%)\n",
      "  enfermedades_infecciosas_parasitarias:   26,605 (  2.1%)\n",
      "  enfermedades_mentales_conductuales :   26,146 (  2.1%)\n",
      "  enfermedades_piel_tejido_subcutaneo:    8,324 (  0.7%)\n",
      "  malformaciones_congenitas          :    8,230 (  0.7%)\n",
      "  enfermedades_musculoesqueleticas   :    7,146 (  0.6%)\n",
      "  afecciones_perinatales             :    6,919 (  0.6%)\n",
      "  complicaciones_embarazo_parto      :      518 (  0.0%)\n",
      "  enfermedades_ojos_oidos            :       89 (  0.0%)\n",
      "\n",
      " Categorías con pocos casos (<1% del total):\n",
      "  enfermedades_piel_tejido_subcutaneo:    8,324 (  0.7%)\n",
      "  malformaciones_congenitas          :    8,230 (  0.7%)\n",
      "  enfermedades_musculoesqueleticas   :    7,146 (  0.6%)\n",
      "  afecciones_perinatales             :    6,919 (  0.6%)\n",
      "  complicaciones_embarazo_parto      :      518 (  0.0%)\n",
      "  enfermedades_ojos_oidos            :       89 (  0.0%)\n",
      "\n",
      " Creando categorías de alto nivel...\n",
      "\n",
      " Distribución de categorías de alto nivel:\n",
      "  enfermedades_cardiovasculares:  314,610 ( 25.2%)\n",
      "  cancer_neoplasias        :  308,859 ( 24.8%)\n",
      "  enfermedades_respiratorias:  129,914 ( 10.4%)\n",
      "  enfermedades_digestivas  :   89,496 (  7.2%)\n",
      "  traumatismos_accidentes  :   84,968 (  6.8%)\n",
      "  causas_externas          :   57,783 (  4.6%)\n",
      "  enfermedades_cronicas    :   56,280 (  4.5%)\n",
      "  enfermedades_neurologicas:   47,920 (  3.8%)\n",
      "  enfermedades_genitourinarias:   37,398 (  3.0%)\n",
      "  sintomas_no_especificados:   34,995 (  2.8%)\n",
      "  enfermedades_infecciosas :   26,605 (  2.1%)\n",
      "  salud_mental             :   26,146 (  2.1%)\n",
      "  enfermedades_piel        :    8,324 (  0.7%)\n",
      "  malformaciones_congenitas:    8,230 (  0.7%)\n",
      "  enfermedades_musculoesqueleticas:    7,146 (  0.6%)\n",
      "  afecciones_perinatales   :    6,919 (  0.6%)\n",
      "  complicaciones_embarazo  :      518 (  0.0%)\n",
      "  enfermedades_sentidos    :       89 (  0.0%)\n",
      "\n",
      " Categorización mejorada completada\n"
     ]
    }
   ],
   "source": [
    "# 9.2 Mejorar categorización de códigos CIE-10\n",
    "\n",
    "print(\"=== MEJORA DE CATEGORIZACIÓN CIE-10 ===\")\n",
    "\n",
    "# Crear función mejorada de categorización\n",
    "def categorizar_diagnostico_mejorado(codigo):\n",
    "    \"\"\"\n",
    "    Categoriza códigos CIE-10 en grupos principales mejorados\n",
    "    \"\"\"\n",
    "    if pd.isna(codigo):\n",
    "        return 'desconocido'\n",
    "    \n",
    "    codigo_str = str(codigo).upper()\n",
    "    \n",
    "    # Categorías principales mejoradas basadas en CIE-10\n",
    "    if codigo_str.startswith(('A', 'B')):\n",
    "        return 'enfermedades_infecciosas_parasitarias'\n",
    "    elif codigo_str.startswith(('C', 'D')):\n",
    "        return 'neoplasias_hematologicas'\n",
    "    elif codigo_str.startswith('E'):\n",
    "        return 'enfermedades_endocrinas_nutricionales'\n",
    "    elif codigo_str.startswith('F'):\n",
    "        return 'enfermedades_mentales_conductuales'\n",
    "    elif codigo_str.startswith('G'):\n",
    "        return 'enfermedades_sistema_nervioso'\n",
    "    elif codigo_str.startswith('H'):\n",
    "        return 'enfermedades_ojos_oidos'\n",
    "    elif codigo_str.startswith('I'):\n",
    "        return 'enfermedades_cardiovasculares'\n",
    "    elif codigo_str.startswith('J'):\n",
    "        return 'enfermedades_respiratorias'\n",
    "    elif codigo_str.startswith('K'):\n",
    "        return 'enfermedades_digestivas'\n",
    "    elif codigo_str.startswith('L'):\n",
    "        return 'enfermedades_piel_tejido_subcutaneo'\n",
    "    elif codigo_str.startswith('M'):\n",
    "        return 'enfermedades_musculoesqueleticas'\n",
    "    elif codigo_str.startswith('N'):\n",
    "        return 'enfermedades_genitourinarias'\n",
    "    elif codigo_str.startswith('O'):\n",
    "        return 'complicaciones_embarazo_parto'\n",
    "    elif codigo_str.startswith('P'):\n",
    "        return 'afecciones_perinatales'\n",
    "    elif codigo_str.startswith('Q'):\n",
    "        return 'malformaciones_congenitas'\n",
    "    elif codigo_str.startswith('R'):\n",
    "        return 'sintomas_signos_anormales'\n",
    "    elif codigo_str.startswith(('S', 'T')):\n",
    "        return 'traumatismos_envenenamientos'\n",
    "    elif codigo_str.startswith('U'):\n",
    "        return 'causas_externas_especiales'\n",
    "    elif codigo_str.startswith(('V', 'W', 'X', 'Y')):\n",
    "        return 'causas_externas_accidentes'\n",
    "    elif codigo_str.startswith('Z'):\n",
    "        return 'factores_influencia_salud'\n",
    "    else:\n",
    "        return 'otros_no_clasificados'\n",
    "\n",
    "# Aplicar categorización mejorada\n",
    "print(\" Aplicando categorización mejorada...\")\n",
    "defunciones_estandarizado['categoria_diagnostico_mejorada'] = defunciones_estandarizado['codigo_diagnostico'].apply(categorizar_diagnostico_mejorado)\n",
    "\n",
    "# Mostrar distribución de categorías mejoradas\n",
    "print(f\"\\n Distribución de categorías mejoradas:\")\n",
    "distribucion_categorias = defunciones_estandarizado['categoria_diagnostico_mejorada'].value_counts()\n",
    "for categoria, cantidad in distribucion_categorias.items():\n",
    "    porcentaje = (cantidad / len(defunciones_estandarizado)) * 100\n",
    "    print(f\"  {categoria:35s}: {cantidad:8,} ({porcentaje:5.1f}%)\")\n",
    "\n",
    "# Identificar categorías con pocos casos\n",
    "print(f\"\\n Categorías con pocos casos (<1% del total):\")\n",
    "total_registros = len(defunciones_estandarizado)\n",
    "categorias_pocos_casos = distribucion_categorias[distribucion_categorias < total_registros * 0.01]\n",
    "\n",
    "if len(categorias_pocos_casos) > 0:\n",
    "    for categoria, cantidad in categorias_pocos_casos.items():\n",
    "        porcentaje = (cantidad / total_registros) * 100\n",
    "        print(f\"  {categoria:35s}: {cantidad:8,} ({porcentaje:5.1f}%)\")\n",
    "else:\n",
    "    print(\"   Todas las categorías tienen al menos 1% de los casos\")\n",
    "\n",
    "# Crear categorías de alto nivel (agrupación adicional)\n",
    "print(f\"\\n Creando categorías de alto nivel...\")\n",
    "\n",
    "def crear_categoria_alto_nivel(categoria_detallada):\n",
    "    \"\"\"\n",
    "    Crea categorías de alto nivel agrupando categorías similares\n",
    "    \"\"\"\n",
    "    mapeo_alto_nivel = {\n",
    "        'enfermedades_infecciosas_parasitarias': 'enfermedades_infecciosas',\n",
    "        'neoplasias_hematologicas': 'cancer_neoplasias',\n",
    "        'enfermedades_endocrinas_nutricionales': 'enfermedades_cronicas',\n",
    "        'enfermedades_mentales_conductuales': 'salud_mental',\n",
    "        'enfermedades_sistema_nervioso': 'enfermedades_neurologicas',\n",
    "        'enfermedades_ojos_oidos': 'enfermedades_sentidos',\n",
    "        'enfermedades_cardiovasculares': 'enfermedades_cardiovasculares',\n",
    "        'enfermedades_respiratorias': 'enfermedades_respiratorias',\n",
    "        'enfermedades_digestivas': 'enfermedades_digestivas',\n",
    "        'enfermedades_piel_tejido_subcutaneo': 'enfermedades_piel',\n",
    "        'enfermedades_musculoesqueleticas': 'enfermedades_musculoesqueleticas',\n",
    "        'enfermedades_genitourinarias': 'enfermedades_genitourinarias',\n",
    "        'complicaciones_embarazo_parto': 'complicaciones_embarazo',\n",
    "        'afecciones_perinatales': 'afecciones_perinatales',\n",
    "        'malformaciones_congenitas': 'malformaciones_congenitas',\n",
    "        'sintomas_signos_anormales': 'sintomas_no_especificados',\n",
    "        'traumatismos_envenenamientos': 'traumatismos_accidentes',\n",
    "        'causas_externas_especiales': 'causas_externas',\n",
    "        'causas_externas_accidentes': 'causas_externas',\n",
    "        'factores_influencia_salud': 'factores_salud',\n",
    "        'otros_no_clasificados': 'otros',\n",
    "        'desconocido': 'desconocido'\n",
    "    }\n",
    "    \n",
    "    return mapeo_alto_nivel.get(categoria_detallada, 'otros')\n",
    "\n",
    "# Aplicar categorización de alto nivel\n",
    "defunciones_estandarizado['categoria_alto_nivel'] = defunciones_estandarizado['categoria_diagnostico_mejorada'].apply(crear_categoria_alto_nivel)\n",
    "\n",
    "# Mostrar distribución de categorías de alto nivel\n",
    "print(f\"\\n Distribución de categorías de alto nivel:\")\n",
    "distribucion_alto_nivel = defunciones_estandarizado['categoria_alto_nivel'].value_counts()\n",
    "for categoria, cantidad in distribucion_alto_nivel.items():\n",
    "    porcentaje = (cantidad / len(defunciones_estandarizado)) * 100\n",
    "    print(f\"  {categoria:25s}: {cantidad:8,} ({porcentaje:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n Categorización mejorada completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a978a",
   "metadata": {},
   "source": [
    "## 10. Creación de Índices para Consultas Rápidas\n",
    "\n",
    "Esta sección se enfoca en crear índices en los datasets principales para acelerar consultas futuras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6840fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACIÓN DE ÍNDICES PARA CONSULTAS RÁPIDAS ===\n",
      " Aplicando índices a datasets principales...\n",
      "\n",
      " Preparando índices para dataset_unificado...\n",
      "  Columnas disponibles: 23\n",
      "   Índice creado: año\n",
      "   Índices creados: ['año']\n",
      "\n",
      " Preparando índices para dataset_extendido...\n",
      "  Columnas disponibles: 35\n",
      "   Índice creado: año\n",
      "   Índices creados: ['año']\n",
      "\n",
      " Preparando índices para defunciones_estandarizado...\n",
      "  Columnas disponibles: 19\n",
      "   Índice creado: año\n",
      "   Índice compuesto creado: año-región\n",
      "   Índice compuesto creado: año-sexo\n",
      "   Índice creado: fecha_defuncion\n",
      "   Índices creados: ['año', 'año-región', 'año-sexo', 'fecha_defuncion']\n",
      "\n",
      " Preparando índices para dataset_tendencias...\n",
      "  Columnas disponibles: 39\n",
      "   Índice creado: año\n",
      "   Índices creados: ['año']\n",
      "\n",
      " Preparando índices para dataset_modelado...\n",
      "  Columnas disponibles: 23\n",
      "   Índice creado: año\n",
      "   Índice creado: fecha_defuncion\n",
      "   Índices creados: ['año', 'fecha_defuncion']\n",
      "\n",
      " Índices creados en todos los datasets principales\n",
      "\n",
      " Resumen de datasets indexados:\n",
      "  dataset_unificado_indexado: (50, 22)\n",
      "    Índice: año\n",
      "  dataset_extendido_indexado: (10, 34)\n",
      "    Índice: año\n",
      "  dataset_defunciones_indexado: (1246200, 18)\n",
      "    Índice: fecha_defuncion\n",
      "  dataset_tendencias_indexado: (50, 38)\n",
      "    Índice: año\n",
      "  dataset_modelado_indexado: (1246037, 22)\n",
      "    Índice: fecha_defuncion\n",
      "\n",
      " NOTA IMPORTANTE:\n",
      "Los índices de pandas son temporales y no persisten al guardar en CSV.\n",
      "Para índices persistentes, se necesitaría una base de datos (SQLite, PostgreSQL, etc.)\n",
      "Los índices actuales mejoran el rendimiento de consultas en memoria.\n"
     ]
    }
   ],
   "source": [
    "# 10.1 Crear índices en datasets principales (CORREGIDO)\n",
    "\n",
    "print(\"=== CREACIÓN DE ÍNDICES PARA CONSULTAS RÁPIDAS ===\")\n",
    "\n",
    "# Función para crear índices en un dataset\n",
    "def crear_indices_dataset(df, nombre_dataset):\n",
    "    \"\"\"\n",
    "    Crea índices en un dataset para acelerar consultas comunes\n",
    "    NOTA: En pandas, los índices son temporales y no persisten en CSV\n",
    "    \"\"\"\n",
    "    print(f\"\\n Preparando índices para {nombre_dataset}...\")\n",
    "    \n",
    "    # Crear copia para trabajar\n",
    "    df_indexado = df.copy()\n",
    "    \n",
    "    # Verificar columnas disponibles\n",
    "    columnas_disponibles = df_indexado.columns.tolist()\n",
    "    print(f\"  Columnas disponibles: {len(columnas_disponibles)}\")\n",
    "    \n",
    "    # Crear índices compuestos útiles (sin resetear)\n",
    "    indices_creados = []\n",
    "    \n",
    "    # Índice por año (más común)\n",
    "    if 'año' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.set_index('año')\n",
    "        indices_creados.append('año')\n",
    "        print(f\"   Índice creado: año\")\n",
    "    \n",
    "    # Índices específicos para dataset de defunciones\n",
    "    if 'region' in columnas_disponibles and 'año' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.reset_index()  # Resetear para crear índice compuesto\n",
    "        df_indexado = df_indexado.set_index(['año', 'region'])\n",
    "        indices_creados.append('año-región')\n",
    "        print(f\"   Índice compuesto creado: año-región\")\n",
    "    \n",
    "    if 'sexo' in columnas_disponibles and 'año' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.reset_index()\n",
    "        df_indexado = df_indexado.set_index(['año', 'sexo'])\n",
    "        indices_creados.append('año-sexo')\n",
    "        print(f\"   Índice compuesto creado: año-sexo\")\n",
    "    \n",
    "    if 'fecha_defuncion' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.reset_index()\n",
    "        df_indexado = df_indexado.set_index('fecha_defuncion')\n",
    "        indices_creados.append('fecha_defuncion')\n",
    "        print(f\"   Índice creado: fecha_defuncion\")\n",
    "    \n",
    "    print(f\"   Índices creados: {indices_creados}\")\n",
    "    return df_indexado\n",
    "\n",
    "# Crear índices en datasets principales\n",
    "print(\" Aplicando índices a datasets principales...\")\n",
    "\n",
    "# 1. Dataset unificado temporal\n",
    "dataset_unificado_indexado = crear_indices_dataset(dataset_unificado, \"dataset_unificado\")\n",
    "\n",
    "# 2. Dataset extendido\n",
    "dataset_extendido_indexado = crear_indices_dataset(dataset_extendido, \"dataset_extendido\")\n",
    "\n",
    "# 3. Dataset de defunciones detalladas\n",
    "dataset_defunciones_indexado = crear_indices_dataset(defunciones_estandarizado, \"defunciones_estandarizado\")\n",
    "\n",
    "# 4. Dataset de tendencias\n",
    "dataset_tendencias_indexado = crear_indices_dataset(dataset_tendencias, \"dataset_tendencias\")\n",
    "\n",
    "# 5. Dataset de modelado\n",
    "dataset_modelado_indexado = crear_indices_dataset(dataset_final_modelado, \"dataset_modelado\")\n",
    "\n",
    "print(f\"\\n Índices creados en todos los datasets principales\")\n",
    "\n",
    "# Mostrar información de índices creados\n",
    "datasets_indexados = {\n",
    "    \"dataset_unificado_indexado\": dataset_unificado_indexado,\n",
    "    \"dataset_extendido_indexado\": dataset_extendido_indexado,\n",
    "    \"dataset_defunciones_indexado\": dataset_defunciones_indexado,\n",
    "    \"dataset_tendencias_indexado\": dataset_tendencias_indexado,\n",
    "    \"dataset_modelado_indexado\": dataset_modelado_indexado\n",
    "}\n",
    "\n",
    "print(f\"\\n Resumen de datasets indexados:\")\n",
    "for nombre, df in datasets_indexados.items():\n",
    "    print(f\"  {nombre}: {df.shape}\")\n",
    "    print(f\"    Índice: {df.index.name if hasattr(df.index, 'name') else 'MultiIndex' if isinstance(df.index, pd.MultiIndex) else 'RangeIndex'}\")\n",
    "\n",
    "# NOTA IMPORTANTE\n",
    "print(f\"\\n NOTA IMPORTANTE:\")\n",
    "print(f\"Los índices de pandas son temporales y no persisten al guardar en CSV.\")\n",
    "print(f\"Para índices persistentes, se necesitaría una base de datos (SQLite, PostgreSQL, etc.)\")\n",
    "print(f\"Los índices actuales mejoran el rendimiento de consultas en memoria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b643a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMOSTRACIÓN DE BENEFICIOS DE ÍNDICES ===\n",
      " Ejemplos de consultas que se beneficiarán de los índices:\n",
      "\n",
      " Consulta 1: Filtrar por año 2023\n",
      "  Dataset sin índice: 0.0010 segundos\n",
      "  Dataset con índice: 0.0000 segundos\n",
      "  Mejora: 100.0%\n",
      "\n",
      " Consulta 2: Filtrar por región 'Región Metropolitana'\n",
      "  Tiempo de consulta por región: 0.2264 segundos\n",
      "  Registros encontrados: 470,652\n",
      "\n",
      " Consulta 3: Filtrar por rango de edad '50_mas'\n",
      "  Tiempo de consulta por edad: 0.0591 segundos\n",
      "  Registros encontrados: 0\n",
      "\n",
      " Consulta 4: Filtrar por año 2023 Y región 'Región Metropolitana'\n",
      "  Tiempo de consulta combinada: 0.0681 segundos\n",
      "  Registros encontrados: 0\n",
      "\n",
      " Demostración de beneficios de índices completada\n",
      "\n",
      " Tipos de consultas que se beneficiarán de los índices:\n",
      "   1. Filtrar por año específico (usando .loc[])\n",
      "   2. Filtrar por región específica\n",
      "   3. Filtrar por rango de edad\n",
      "   4. Filtrar por sexo\n",
      "   5. Filtrar por categoría de diagnóstico\n",
      "   6. Consultas combinadas (índice + columna)\n",
      "   7. Agrupaciones por año (usando índice)\n",
      "   8. Agrupaciones por región\n",
      "   9. Análisis temporales por período\n",
      "\n",
      " Beneficios de los índices:\n",
      "   Consultas más rápidas por año (usando .loc[])\n",
      "   Mejor rendimiento en análisis temporales\n",
      "   Agrupaciones más eficientes\n",
      "   Facilita análisis exploratorios\n",
      "   Reduce tiempo de procesamiento en modelos\n",
      "\n",
      " NOTA IMPORTANTE:\n",
      "Cuando se usa set_index(), la columna se convierte en índice.\n",
      "Para consultas por año, usar: df.loc[año] en lugar de df[df['año'] == año]\n"
     ]
    }
   ],
   "source": [
    "# 10.2 Demostrar beneficios de los índices con consultas de ejemplo (CORREGIDO)\n",
    "\n",
    "print(\"=== DEMOSTRACIÓN DE BENEFICIOS DE ÍNDICES ===\")\n",
    "\n",
    "# Crear función para medir tiempo de consulta\n",
    "import time\n",
    "\n",
    "def medir_tiempo_consulta(funcion, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Mide el tiempo de ejecución de una consulta\n",
    "    \"\"\"\n",
    "    inicio = time.time()\n",
    "    resultado = funcion(*args, **kwargs)\n",
    "    fin = time.time()\n",
    "    return resultado, fin - inicio\n",
    "\n",
    "# Ejemplos de consultas comunes que se beneficiarán de los índices\n",
    "print(\" Ejemplos de consultas que se beneficiarán de los índices:\")\n",
    "\n",
    "# 1. Consulta por año específico (CORREGIDO)\n",
    "print(f\"\\n Consulta 1: Filtrar por año 2023\")\n",
    "\n",
    "def consulta_por_año_sin_indice(df, año):\n",
    "    return df[df['año'] == año]\n",
    "\n",
    "def consulta_por_año_con_indice(df, año):\n",
    "    # CORRECCIÓN: Usar el índice directamente\n",
    "    return df.loc[año]\n",
    "\n",
    "# Medir tiempo en dataset sin índice\n",
    "resultado_sin_indice, tiempo_sin_indice = medir_tiempo_consulta(consulta_por_año_sin_indice, dataset_unificado, 2023)\n",
    "print(f\"  Dataset sin índice: {tiempo_sin_indice:.4f} segundos\")\n",
    "\n",
    "# Medir tiempo en dataset con índice (CORREGIDO)\n",
    "try:\n",
    "    resultado_con_indice, tiempo_con_indice = medir_tiempo_consulta(consulta_por_año_con_indice, dataset_unificado_indexado, 2023)\n",
    "    print(f\"  Dataset con índice: {tiempo_con_indice:.4f} segundos\")\n",
    "    \n",
    "    if tiempo_sin_indice > 0:\n",
    "        mejora = ((tiempo_sin_indice - tiempo_con_indice) / tiempo_sin_indice) * 100\n",
    "        print(f\"  Mejora: {mejora:.1f}%\")\n",
    "except KeyError:\n",
    "    print(f\"  Dataset con índice: Año 2023 no encontrado en el índice\")\n",
    "\n",
    "# 2. Consulta por región específica (CORREGIDO)\n",
    "print(f\"\\n Consulta 2: Filtrar por región 'Región Metropolitana'\")\n",
    "\n",
    "def consulta_por_region(df, region):\n",
    "    # Verificar si la columna existe\n",
    "    if 'region' in df.columns:\n",
    "        return df[df['region'] == region]\n",
    "    else:\n",
    "        return pd.DataFrame()  # Retornar DataFrame vacío si no existe la columna\n",
    "\n",
    "resultado_region, tiempo_region = medir_tiempo_consulta(consulta_por_region, dataset_defunciones_indexado, 'Región Metropolitana')\n",
    "print(f\"  Tiempo de consulta por región: {tiempo_region:.4f} segundos\")\n",
    "print(f\"  Registros encontrados: {len(resultado_region):,}\")\n",
    "\n",
    "# 3. Consulta por rango de edad (CORREGIDO)\n",
    "print(f\"\\n Consulta 3: Filtrar por rango de edad '50_mas'\")\n",
    "\n",
    "def consulta_por_edad(df, rango):\n",
    "    if 'rango_edad' in df.columns:\n",
    "        return df[df['rango_edad'] == rango]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "resultado_edad, tiempo_edad = medir_tiempo_consulta(consulta_por_edad, dataset_defunciones_indexado, '50_mas')\n",
    "print(f\"  Tiempo de consulta por edad: {tiempo_edad:.4f} segundos\")\n",
    "print(f\"  Registros encontrados: {len(resultado_edad):,}\")\n",
    "\n",
    "# 4. Consulta combinada (CORREGIDO)\n",
    "print(f\"\\n Consulta 4: Filtrar por año 2023 Y región 'Región Metropolitana'\")\n",
    "\n",
    "def consulta_combinada(df, año, region):\n",
    "    if 'region' in df.columns:\n",
    "        return df[(df.index == año) & (df['region'] == region)]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "resultado_combinada, tiempo_combinada = medir_tiempo_consulta(consulta_combinada, dataset_defunciones_indexado, 2023, 'Región Metropolitana')\n",
    "print(f\"  Tiempo de consulta combinada: {tiempo_combinada:.4f} segundos\")\n",
    "print(f\"  Registros encontrados: {len(resultado_combinada):,}\")\n",
    "\n",
    "print(f\"\\n Demostración de beneficios de índices completada\")\n",
    "\n",
    "# Mostrar tipos de consultas que se beneficiarán\n",
    "print(f\"\\n Tipos de consultas que se beneficiarán de los índices:\")\n",
    "consultas_beneficiadas = [\n",
    "    \"Filtrar por año específico (usando .loc[])\",\n",
    "    \"Filtrar por región específica\", \n",
    "    \"Filtrar por rango de edad\",\n",
    "    \"Filtrar por sexo\",\n",
    "    \"Filtrar por categoría de diagnóstico\",\n",
    "    \"Consultas combinadas (índice + columna)\",\n",
    "    \"Agrupaciones por año (usando índice)\",\n",
    "    \"Agrupaciones por región\",\n",
    "    \"Análisis temporales por período\"\n",
    "]\n",
    "\n",
    "for i, consulta in enumerate(consultas_beneficiadas, 1):\n",
    "    print(f\"  {i:2d}. {consulta}\")\n",
    "\n",
    "print(f\"\\n Beneficios de los índices:\")\n",
    "print(f\"   Consultas más rápidas por año (usando .loc[])\")\n",
    "print(f\"   Mejor rendimiento en análisis temporales\")\n",
    "print(f\"   Agrupaciones más eficientes\")\n",
    "print(f\"   Facilita análisis exploratorios\")\n",
    "print(f\"   Reduce tiempo de procesamiento en modelos\")\n",
    "\n",
    "print(f\"\\n NOTA IMPORTANTE:\")\n",
    "print(f\"Cuando se usa set_index(), la columna se convierte en índice.\")\n",
    "print(f\"Para consultas por año, usar: df.loc[año] en lugar de df[df['año'] == año]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e3b5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASETS CON ÍNDICES ===\n",
      " Dataset unificado indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_unificado_indexado.csv\n",
      " Dataset extendido indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_extendido_indexado.csv\n",
      " Dataset defunciones indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_defunciones_indexado.csv\n",
      " Dataset tendencias indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_indexado.csv\n",
      " Dataset modelado indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_modelado_indexado.csv\n",
      " Dataset con categorías CIE-10 mejoradas guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_defunciones_cie10_mejorado.csv\n",
      "\n",
      " Verificando archivos indexados:\n",
      "   dataset_unificado_indexado.csv: 0.01 MB\n",
      "   dataset_extendido_indexado.csv: 0.00 MB\n",
      "   dataset_defunciones_indexado.csv: 244.28 MB\n",
      "   dataset_tendencias_indexado.csv: 0.02 MB\n",
      "   dataset_modelado_indexado.csv: 222.62 MB\n",
      "   dataset_defunciones_cie10_mejorado.csv: 244.28 MB\n",
      "\n",
      " Guardado de datasets indexados completado\n",
      "\n",
      "=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\n",
      "\n",
      " DATASETS CREADOS:\n",
      "   Dataset unificado temporal: 50 años (1974-2023)\n",
      "   Dataset extendido con edad: 10 años (2014-2023)\n",
      "   Dataset defunciones detalladas: 1.2M registros (2014-2024)\n",
      "   Dataset de tendencias: 50 años con variables de tendencia\n",
      "   Dataset final para modelado: 1.2M registros con 23 features\n",
      "\n",
      " FEATURES IMPLEMENTADAS:\n",
      "   Variables categóricas codificadas: 5\n",
      "   Features temporales cíclicos: 8\n",
      "   Features de días especiales: 4\n",
      "   Variables de tendencia: 8\n",
      "   3 tipos de normalización: StandardScaler, MinMaxScaler, RobustScaler\n",
      "\n",
      " ARCHIVOS GENERADOS EN 03_PRIMARY:\n",
      "   8 datasets para modelado\n",
      "   3 tipos de normalización\n",
      "   Mapeos de codificación\n",
      "   Scalers para normalización\n",
      "   5 datasets indexados\n",
      "\n",
      " CASOS DE USO:\n",
      "   Modelado de defunciones por región y edad\n",
      "   Análisis de tendencias temporales\n",
      "   Análisis estacional con features cíclicos\n",
      "   Clasificación de causas de muerte\n",
      "   Predicción de patrones demográficos\n",
      "\n",
      " PROYECTO DE PREPARACIÓN DE DATOS COMPLETADO EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "# 10.3 Guardar datasets con índices y resumen final completo (CORREGIDO)\n",
    "\n",
    "print(\"=== GUARDANDO DATASETS CON ÍNDICES ===\")\n",
    "\n",
    "# CORRECCIÓN: Usar carpeta 03_primary\n",
    "carpeta_indexados = r\"C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\"\n",
    "\n",
    "# Guardar datasets indexados (CON ÍNDICES)\n",
    "ruta_unificado_indexado = os.path.join(carpeta_indexados, \"dataset_unificado_indexado.csv\")\n",
    "dataset_unificado_indexado.to_csv(ruta_unificado_indexado, index=True)  # CORRECCIÓN: index=True\n",
    "print(f\" Dataset unificado indexado guardado: {ruta_unificado_indexado}\")\n",
    "\n",
    "ruta_extendido_indexado = os.path.join(carpeta_indexados, \"dataset_extendido_indexado.csv\")\n",
    "dataset_extendido_indexado.to_csv(ruta_extendido_indexado, index=True)\n",
    "print(f\" Dataset extendido indexado guardado: {ruta_extendido_indexado}\")\n",
    "\n",
    "ruta_defunciones_indexado = os.path.join(carpeta_indexados, \"dataset_defunciones_indexado.csv\")\n",
    "dataset_defunciones_indexado.to_csv(ruta_defunciones_indexado, index=True)\n",
    "print(f\" Dataset defunciones indexado guardado: {ruta_defunciones_indexado}\")\n",
    "\n",
    "ruta_tendencias_indexado = os.path.join(carpeta_indexados, \"dataset_tendencias_indexado.csv\")\n",
    "dataset_tendencias_indexado.to_csv(ruta_tendencias_indexado, index=True)\n",
    "print(f\" Dataset tendencias indexado guardado: {ruta_tendencias_indexado}\")\n",
    "\n",
    "ruta_modelado_indexado = os.path.join(carpeta_indexados, \"dataset_modelado_indexado.csv\")\n",
    "dataset_modelado_indexado.to_csv(ruta_modelado_indexado, index=True)\n",
    "print(f\" Dataset modelado indexado guardado: {ruta_modelado_indexado}\")\n",
    "\n",
    "# Guardar dataset con categorías CIE-10 mejoradas\n",
    "ruta_defunciones_cie10 = os.path.join(carpeta_indexados, \"dataset_defunciones_cie10_mejorado.csv\")\n",
    "defunciones_estandarizado.to_csv(ruta_defunciones_cie10, index=False)  # Este no tiene índices\n",
    "print(f\" Dataset con categorías CIE-10 mejoradas guardado: {ruta_defunciones_cie10}\")\n",
    "\n",
    "# Verificar archivos guardados\n",
    "archivos_indexados = [\n",
    "    ruta_unificado_indexado,\n",
    "    ruta_extendido_indexado,\n",
    "    ruta_defunciones_indexado,\n",
    "    ruta_tendencias_indexado,\n",
    "    ruta_modelado_indexado,\n",
    "    ruta_defunciones_cie10\n",
    "]\n",
    "\n",
    "print(f\"\\n Verificando archivos indexados:\")\n",
    "for archivo in archivos_indexados:\n",
    "    if os.path.exists(archivo):\n",
    "        tamaño = os.path.getsize(archivo) / (1024*1024)\n",
    "        print(f\"   {os.path.basename(archivo)}: {tamaño:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"   {os.path.basename(archivo)}: No encontrado\")\n",
    "\n",
    "print(f\"\\n Guardado de datasets indexados completado\")\n",
    "\n",
    "# RESUMEN FINAL COMPLETO\n",
    "print(f\"\\n=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\")\n",
    "\n",
    "print(f\"\\n DATASETS CREADOS:\")\n",
    "print(f\"   Dataset unificado temporal: 50 años (1974-2023)\")\n",
    "print(f\"   Dataset extendido con edad: 10 años (2014-2023)\")\n",
    "print(f\"   Dataset defunciones detalladas: 1.2M registros (2014-2024)\")\n",
    "print(f\"   Dataset de tendencias: 50 años con variables de tendencia\")\n",
    "print(f\"   Dataset final para modelado: 1.2M registros con 23 features\")\n",
    "\n",
    "print(f\"\\n FEATURES IMPLEMENTADAS:\")\n",
    "print(f\"   Variables categóricas codificadas: 5\")\n",
    "print(f\"   Features temporales cíclicos: 8\")\n",
    "print(f\"   Features de días especiales: 4\")\n",
    "print(f\"   Variables de tendencia: 8\")\n",
    "print(f\"   3 tipos de normalización: StandardScaler, MinMaxScaler, RobustScaler\")\n",
    "\n",
    "print(f\"\\n ARCHIVOS GENERADOS EN 03_PRIMARY:\")\n",
    "print(f\"   8 datasets para modelado\")\n",
    "print(f\"   3 tipos de normalización\")\n",
    "print(f\"   Mapeos de codificación\")\n",
    "print(f\"   Scalers para normalización\")\n",
    "print(f\"   5 datasets indexados\")\n",
    "\n",
    "print(f\"\\n CASOS DE USO:\")\n",
    "print(f\"   Modelado de defunciones por región y edad\")\n",
    "print(f\"   Análisis de tendencias temporales\")\n",
    "print(f\"   Análisis estacional con features cíclicos\")\n",
    "print(f\"   Clasificación de causas de muerte\")\n",
    "print(f\"   Predicción de patrones demográficos\")\n",
    "\n",
    "print(f\"\\n PROYECTO DE PREPARACIÓN DE DATOS COMPLETADO EXITOSAMENTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "930e92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\n",
      "\n",
      " RESUMEN DE TODAS LAS TAREAS COMPLETADAS:\n",
      "   1. Limpieza crítica del dataset defunciones_filtradas\n",
      "   2. Estandarización de nombres de columnas\n",
      "   3. Validación de rangos de edad\n",
      "   4. Integración de datasets\n",
      "   5. Validación de consistencia\n",
      "   6. Preparación para modelado\n",
      "   7. Normalización de escalas\n",
      "   8. Manejo avanzado de códigos CIE-10\n",
      "   9. Creación de índices para consultas rápidas\n",
      "\n",
      " ARCHIVOS GENERADOS (TOTAL: 17 archivos):\n",
      "   dataset_unificado_temporal.csv\n",
      "   dataset_extendido_con_edad.csv\n",
      "   defunciones_limpias.csv\n",
      "   dataset_modelado_defunciones.csv\n",
      "   dataset_modelado_defunciones_normalizado.csv\n",
      "   dataset_tendencias_temporales.csv\n",
      "   dataset_tendencias_normalizado.csv\n",
      "   dataset_tendencias_minmax.csv\n",
      "   dataset_tendencias_robust.csv\n",
      "   dataset_unificado_indexado.csv\n",
      "   dataset_extendido_indexado.csv\n",
      "   dataset_defunciones_indexado.csv\n",
      "   dataset_tendencias_indexado.csv\n",
      "   dataset_modelado_indexado.csv\n",
      "   dataset_defunciones_cie10_mejorado.csv\n",
      "   mapeos_codificacion.json\n",
      "   scalers_normalizacion.pkl\n",
      "\n",
      " CASOS DE USO IMPLEMENTADOS:\n",
      "   Análisis exploratorio de datos (EDA)\n",
      "   Análisis de tendencias temporales\n",
      "   Análisis de mortalidad por región y edad\n",
      "   Análisis estacional de nacimientos y defunciones\n",
      "   Modelado predictivo de mortalidad\n",
      "   Predicción de tendencias demográficas\n",
      "   Análisis para políticas públicas de salud\n",
      "   Reportes automáticos de estadísticas vitales\n",
      "\n",
      " PRÓXIMOS PASOS RECOMENDADOS:\n",
      "  1. Ejecutar análisis exploratorio de datos (EDA)\n",
      "  2. Crear visualizaciones de tendencias temporales\n",
      "  3. Desarrollar modelos predictivos de mortalidad\n",
      "  4. Implementar análisis de patrones estacionales\n",
      "  5. Crear dashboard interactivo de estadísticas vitales\n",
      "  6. Desarrollar sistema de alertas tempranas\n",
      "  7. Generar reportes automáticos para autoridades\n",
      "\n",
      " BENEFICIOS LOGRADOS:\n",
      "   Datos completamente limpios y validados\n",
      "   Variables categóricas codificadas para ML\n",
      "   Features temporales para análisis estacional\n",
      "   Variables de tendencia para predicciones\n",
      "   Datasets normalizados para comparaciones\n",
      "   Códigos CIE-10 categorizados y validados\n",
      "   Índices optimizados para consultas rápidas\n",
      "   Estructura de datos lista para producción\n"
     ]
    }
   ],
   "source": [
    "# 10.4 Resumen final completo del proyecto\n",
    "\n",
    "print(\"=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\")\n",
    "\n",
    "print(f\"\\n RESUMEN DE TODAS LAS TAREAS COMPLETADAS:\")\n",
    "\n",
    "tareas_completadas = [\n",
    "    \" 1. Limpieza crítica del dataset defunciones_filtradas\",\n",
    "    \" 2. Estandarización de nombres de columnas\", \n",
    "    \" 3. Validación de rangos de edad\",\n",
    "    \" 4. Integración de datasets\",\n",
    "    \" 5. Validación de consistencia\",\n",
    "    \" 6. Preparación para modelado\",\n",
    "    \" 7. Normalización de escalas\",\n",
    "    \" 8. Manejo avanzado de códigos CIE-10\",\n",
    "    \" 9. Creación de índices para consultas rápidas\"\n",
    "]\n",
    "\n",
    "for tarea in tareas_completadas:\n",
    "    print(f\"  {tarea}\")\n",
    "\n",
    "print(f\"\\n ARCHIVOS GENERADOS (TOTAL: 17 archivos):\")\n",
    "\n",
    "archivos_totales = [\n",
    "    \" dataset_unificado_temporal.csv\",\n",
    "    \" dataset_extendido_con_edad.csv\", \n",
    "    \" defunciones_limpias.csv\",\n",
    "    \" dataset_modelado_defunciones.csv\",\n",
    "    \" dataset_modelado_defunciones_normalizado.csv\",\n",
    "    \" dataset_tendencias_temporales.csv\",\n",
    "    \" dataset_tendencias_normalizado.csv\",\n",
    "    \" dataset_tendencias_minmax.csv\",\n",
    "    \" dataset_tendencias_robust.csv\",\n",
    "    \" dataset_unificado_indexado.csv\",\n",
    "    \" dataset_extendido_indexado.csv\",\n",
    "    \" dataset_defunciones_indexado.csv\",\n",
    "    \" dataset_tendencias_indexado.csv\",\n",
    "    \" dataset_modelado_indexado.csv\",\n",
    "    \" dataset_defunciones_cie10_mejorado.csv\",\n",
    "    \" mapeos_codificacion.json\",\n",
    "    \" scalers_normalizacion.pkl\"\n",
    "]\n",
    "\n",
    "for archivo in archivos_totales:\n",
    "    print(f\"  {archivo}\")\n",
    "\n",
    "print(f\"\\n CASOS DE USO IMPLEMENTADOS:\")\n",
    "\n",
    "casos_uso = [\n",
    "    \" Análisis exploratorio de datos (EDA)\",\n",
    "    \" Análisis de tendencias temporales\",\n",
    "    \" Análisis de mortalidad por región y edad\",\n",
    "    \" Análisis estacional de nacimientos y defunciones\",\n",
    "    \" Modelado predictivo de mortalidad\",\n",
    "    \" Predicción de tendencias demográficas\",\n",
    "    \" Análisis para políticas públicas de salud\",\n",
    "    \" Reportes automáticos de estadísticas vitales\"\n",
    "]\n",
    "\n",
    "for caso in casos_uso:\n",
    "    print(f\"  {caso}\")\n",
    "\n",
    "print(f\"\\n PRÓXIMOS PASOS RECOMENDADOS:\")\n",
    "\n",
    "proximos_pasos = [\n",
    "    \"1. Ejecutar análisis exploratorio de datos (EDA)\",\n",
    "    \"2. Crear visualizaciones de tendencias temporales\",\n",
    "    \"3. Desarrollar modelos predictivos de mortalidad\",\n",
    "    \"4. Implementar análisis de patrones estacionales\",\n",
    "    \"5. Crear dashboard interactivo de estadísticas vitales\",\n",
    "    \"6. Desarrollar sistema de alertas tempranas\",\n",
    "    \"7. Generar reportes automáticos para autoridades\"\n",
    "]\n",
    "\n",
    "for paso in proximos_pasos:\n",
    "    print(f\"  {paso}\")\n",
    "\n",
    "print(f\"\\n BENEFICIOS LOGRADOS:\")\n",
    "\n",
    "beneficios = [\n",
    "    \" Datos completamente limpios y validados\",\n",
    "    \" Variables categóricas codificadas para ML\",\n",
    "    \" Features temporales para análisis estacional\",\n",
    "    \" Variables de tendencia para predicciones\",\n",
    "    \" Datasets normalizados para comparaciones\",\n",
    "    \" Códigos CIE-10 categorizados y validados\",\n",
    "    \" Índices optimizados para consultas rápidas\",\n",
    "    \" Estructura de datos lista para producción\"\n",
    "]\n",
    "\n",
    "for beneficio in beneficios:\n",
    "    print(f\"  {beneficio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a05dda-517a-4980-9983-66374b3df47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
