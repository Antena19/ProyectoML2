{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d6b798",
   "metadata": {},
   "source": [
    "# Preparaci√≥n de Datos\n",
    "**Proyecto Machine Learning:** Limpieza y Preparaci√≥n de Datos de Nacimientos y Defunciones\n",
    "\n",
    "Este notebook implementa la limpieza y preparaci√≥n de los datasets identificados en el an√°lisis exploratorio, enfoc√°ndose en:\n",
    "1. Limpieza cr√≠tica del dataset `defunciones_filtradas`\n",
    "2. Estandarizaci√≥n de nombres de columnas\n",
    "3. Validaci√≥n de rangos de edad\n",
    "4. Integraci√≥n de datasets\n",
    "5. Validaci√≥n de consistencia\n",
    "6. Preparaci√≥n para modelado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef41646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# 1. Importaci√≥n de librer√≠as y configuraci√≥n\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n general\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Opciones de pandas para mejor visualizaci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0a0ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivos cargados correctamente\n",
      "üìä Dataset defunciones_filtradas: 1,250,062 registros\n"
     ]
    }
   ],
   "source": [
    "# 2. Carga de datos\n",
    "\n",
    "# Definir rutas de los archivos\n",
    "ruta_por_sexo = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\dataset_nacimiento-defuncion_por_sexo.csv\"\n",
    "ruta_defunciones_filtradas = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\datos_filtrados_2014_2023.csv\"\n",
    "ruta_por_edad_madre = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\nacimiento_rango_edad_madre.csv\"\n",
    "ruta_por_edad_fallecido = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\rango_edad_fallecido.csv\"\n",
    "ruta_setdedatos = r\"C:\\ProyectoML2\\proyecto-ml\\data\\01_raw\\setdedatos.csv\"\n",
    "\n",
    "# Funci√≥n para cargar CSV con diferentes separadores\n",
    "def cargar_csv(ruta):\n",
    "    \"\"\"\n",
    "    Carga un archivo CSV probando primero con ',' y luego con ';' como separador\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(ruta)\n",
    "    except:\n",
    "        return pd.read_csv(ruta, sep=\";\")\n",
    "\n",
    "# Cargar todos los datasets\n",
    "por_sexo = cargar_csv(ruta_por_sexo)\n",
    "defunciones_filtradas = cargar_csv(ruta_defunciones_filtradas)\n",
    "por_edad_madre = cargar_csv(ruta_por_edad_madre)\n",
    "por_edad_fallecido = cargar_csv(ruta_por_edad_fallecido)\n",
    "setdedatos = cargar_csv(ruta_setdedatos)\n",
    "\n",
    "print(\"‚úÖ Archivos cargados correctamente\")\n",
    "print(f\"üìä Dataset defunciones_filtradas: {defunciones_filtradas.shape[0]:,} registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13711102",
   "metadata": {},
   "source": [
    "## 3. Limpieza Cr√≠tica del Dataset `defunciones_filtradas`\n",
    "\n",
    "Este es el dataset m√°s problem√°tico identificado en el EDA. Requiere limpieza antes de cualquier an√°lisis posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6188bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISIS INICIAL DE DEFUNCIONES_FILTRADAS ===\n",
      "üìä Dimensiones: (1250062, 10)\n",
      "üìã Columnas: ['A√ëO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_TIPO', 'EDAD_CANT', 'COD_COMUNA', 'COMUNA', 'NOMBRE_REGION', 'CAPITULO_DIAG1', 'GLOSA_CAPITULO_DIAG1']\n",
      "\n",
      "=== VALORES NULOS POR COLUMNA ===\n",
      "FECHA_DEF        19\n",
      "COD_COMUNA        4\n",
      "COMUNA            4\n",
      "NOMBRE_REGION     4\n",
      "dtype: int64\n",
      "\n",
      "=== DUPLICADOS ===\n",
      "Registros duplicados: 3,844\n",
      "\n",
      "=== PRIMERAS FILAS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A√ëO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_TIPO</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COD_COMUNA</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>NOMBRE_REGION</th>\n",
       "      <th>CAPITULO_DIAG1</th>\n",
       "      <th>GLOSA_CAPITULO_DIAG1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13127.0</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8203.0</td>\n",
       "      <td>Ca√±ete</td>\n",
       "      <td>Del B√≠ob√≠o</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13303.0</td>\n",
       "      <td>Tiltil</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>13119.0</td>\n",
       "      <td>Maip√∫</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13115.0</td>\n",
       "      <td>Lo Barnechea</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A√ëO   FECHA_DEF SEXO_NOMBRE  EDAD_TIPO  EDAD_CANT  COD_COMUNA  \\\n",
       "0  2015  2015-01-11       Mujer        2.0          4     13127.0   \n",
       "1  2016  2016-01-31      Hombre        1.0         20      8203.0   \n",
       "2  2019  2019-08-08      Hombre        1.0         18     13303.0   \n",
       "3  2015  2015-02-17      Hombre        1.0         19     13119.0   \n",
       "4  2015  2015-01-03      Hombre        1.0         18     13115.0   \n",
       "\n",
       "         COMUNA              NOMBRE_REGION CAPITULO_DIAG1  \\\n",
       "0      Recoleta  Metropolitana de Santiago        S00-T98   \n",
       "1        Ca√±ete                 Del B√≠ob√≠o        S00-T98   \n",
       "2        Tiltil  Metropolitana de Santiago        S00-T98   \n",
       "3         Maip√∫  Metropolitana de Santiago        S00-T98   \n",
       "4  Lo Barnechea  Metropolitana de Santiago        S00-T98   \n",
       "\n",
       "                                GLOSA_CAPITULO_DIAG1  \n",
       "0  Traumatismos, envenenamientos y algunas otras ...  \n",
       "1  Traumatismos, envenenamientos y algunas otras ...  \n",
       "2  Traumatismos, envenenamientos y algunas otras ...  \n",
       "3  Traumatismos, envenenamientos y algunas otras ...  \n",
       "4  Traumatismos, envenenamientos y algunas otras ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.1 An√°lisis inicial del dataset defunciones_filtradas\n",
    "\n",
    "print(\"=== AN√ÅLISIS INICIAL DE DEFUNCIONES_FILTRADAS ===\")\n",
    "print(f\"üìä Dimensiones: {defunciones_filtradas.shape}\")\n",
    "print(f\"üìã Columnas: {list(defunciones_filtradas.columns)}\")\n",
    "print(\"\\n=== VALORES NULOS POR COLUMNA ===\")\n",
    "nulos_por_columna = defunciones_filtradas.isnull().sum()\n",
    "print(nulos_por_columna[nulos_por_columna > 0])\n",
    "\n",
    "print(\"\\n=== DUPLICADOS ===\")\n",
    "duplicados = defunciones_filtradas.duplicated().sum()\n",
    "print(f\"Registros duplicados: {duplicados:,}\")\n",
    "\n",
    "print(\"\\n=== PRIMERAS FILAS ===\")\n",
    "display(defunciones_filtradas.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4da0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ELIMINACI√ìN DE DUPLICADOS ===\n",
      "Registros antes de eliminar duplicados: 1,250,062\n",
      "Registros despu√©s de eliminar duplicados: 1,246,218\n",
      "Registros eliminados: 3,844\n",
      "Duplicados restantes: 0\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Eliminaci√≥n de registros duplicados\n",
    "\n",
    "print(\"=== ELIMINACI√ìN DE DUPLICADOS ===\")\n",
    "print(f\"Registros antes de eliminar duplicados: {defunciones_filtradas.shape[0]:,}\")\n",
    "\n",
    "# Crear una copia del dataset para trabajar\n",
    "defunciones_limpio = defunciones_filtradas.copy()\n",
    "\n",
    "# Eliminar duplicados manteniendo la primera ocurrencia\n",
    "defunciones_limpio = defunciones_limpio.drop_duplicates(keep='first')\n",
    "\n",
    "print(f\"Registros despu√©s de eliminar duplicados: {defunciones_limpio.shape[0]:,}\")\n",
    "print(f\"Registros eliminados: {defunciones_filtradas.shape[0] - defunciones_limpio.shape[0]:,}\")\n",
    "\n",
    "# Verificar que no quedan duplicados\n",
    "duplicados_restantes = defunciones_limpio.duplicated().sum()\n",
    "print(f\"Duplicados restantes: {duplicados_restantes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d8996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MANEJO DE VALORES NULOS EN INFORMACI√ìN GEOGR√ÅFICA ===\n",
      "Valores nulos en columnas geogr√°ficas:\n",
      "COD_COMUNA       4\n",
      "COMUNA           4\n",
      "NOMBRE_REGION    4\n",
      "dtype: int64\n",
      "\n",
      "Registros con valores nulos en informaci√≥n geogr√°fica: 4\n",
      "\n",
      "Ejemplos de registros con valores nulos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A√ëO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COD_COMUNA</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>NOMBRE_REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159454</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166415</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193568</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248759</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A√ëO   FECHA_DEF SEXO_NOMBRE  EDAD_CANT  COD_COMUNA COMUNA  \\\n",
       "1159454  2024  2024-02-28      Hombre         83         NaN    NaN   \n",
       "1166415  2024  2024-04-26       Mujer         52         NaN    NaN   \n",
       "1193568  2024  2024-04-11      Hombre          1         NaN    NaN   \n",
       "1248759  2024  2024-06-26       Mujer          2         NaN    NaN   \n",
       "\n",
       "        NOMBRE_REGION  \n",
       "1159454           NaN  \n",
       "1166415           NaN  \n",
       "1193568           NaN  \n",
       "1248759           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registros despu√©s de eliminar nulos geogr√°ficos: 1,246,214\n",
      "Registros eliminados por nulos geogr√°ficos: 4\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Manejo de valores nulos en informaci√≥n geogr√°fica\n",
    "\n",
    "print(\"=== MANEJO DE VALORES NULOS EN INFORMACI√ìN GEOGR√ÅFICA ===\")\n",
    "\n",
    "# Verificar valores nulos en columnas geogr√°ficas cr√≠ticas\n",
    "columnas_geograficas = ['COD_COMUNA', 'COMUNA', 'NOMBRE_REGION']\n",
    "nulos_geograficos = defunciones_limpio[columnas_geograficas].isnull().sum()\n",
    "print(\"Valores nulos en columnas geogr√°ficas:\")\n",
    "print(nulos_geograficos)\n",
    "\n",
    "# Mostrar registros con valores nulos en informaci√≥n geogr√°fica\n",
    "registros_nulos_geo = defunciones_limpio[defunciones_limpio[columnas_geograficas].isnull().any(axis=1)]\n",
    "print(f\"\\nRegistros con valores nulos en informaci√≥n geogr√°fica: {len(registros_nulos_geo)}\")\n",
    "\n",
    "if len(registros_nulos_geo) > 0:\n",
    "    print(\"\\nEjemplos de registros con valores nulos:\")\n",
    "    display(registros_nulos_geo[['A√ëO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_CANT'] + columnas_geograficas].head())\n",
    "\n",
    "# Eliminar registros con valores nulos en informaci√≥n geogr√°fica cr√≠tica\n",
    "# La informaci√≥n geogr√°fica es esencial para an√°lisis regionales\n",
    "defunciones_limpio = defunciones_limpio.dropna(subset=columnas_geograficas)\n",
    "\n",
    "print(f\"\\nRegistros despu√©s de eliminar nulos geogr√°ficos: {defunciones_limpio.shape[0]:,}\")\n",
    "print(f\"Registros eliminados por nulos geogr√°ficos: {len(registros_nulos_geo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68ab4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MANEJO DE VALORES NULOS EN FECHA_DEF ===\n",
      "Valores nulos en FECHA_DEF: 19\n",
      "\n",
      "Registros con valores nulos en FECHA_DEF: 19\n",
      "\n",
      "Ejemplos de registros con fecha nula:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A√ëO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COMUNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>33</td>\n",
       "      <td>Temuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>44</td>\n",
       "      <td>Temuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>35</td>\n",
       "      <td>Ercilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39420</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>62</td>\n",
       "      <td>Gorbea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55107</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>81</td>\n",
       "      <td>Temuco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A√ëO FECHA_DEF SEXO_NOMBRE  EDAD_CANT   COMUNA\n",
       "5893   2016       NaN      Hombre         33   Temuco\n",
       "7953   2015       NaN      Hombre         44   Temuco\n",
       "8144   2014       NaN      Hombre         35  Ercilla\n",
       "39420  2016       NaN      Hombre         62   Gorbea\n",
       "55107  2014       NaN      Hombre         81   Temuco"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IMPUTACI√ìN DE FECHAS NULAS ===\n",
      "A√±o 2016: 3 registros imputados con fecha 2016-07-03\n",
      "A√±o 2015: 6 registros imputados con fecha 2015-07-05\n",
      "A√±o 2014: 3 registros imputados con fecha 2014-07-04\n",
      "A√±o 2018: 1 registros imputados con fecha 2018-07-05\n",
      "A√±o 2019: 1 registros imputados con fecha 2019-07-04\n",
      "A√±o 2020: 3 registros imputados con fecha 2020-07-05\n",
      "A√±o 2021: 2 registros imputados con fecha 2021-06-27\n",
      "\n",
      "Valores nulos restantes en FECHA_DEF: 0\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Manejo de valores nulos en FECHA_DEF\n",
    "\n",
    "print(\"=== MANEJO DE VALORES NULOS EN FECHA_DEF ===\")\n",
    "\n",
    "# Verificar valores nulos en FECHA_DEF\n",
    "nulos_fecha = defunciones_limpio['FECHA_DEF'].isnull().sum()\n",
    "print(f\"Valores nulos en FECHA_DEF: {nulos_fecha}\")\n",
    "\n",
    "if nulos_fecha > 0:\n",
    "    # Mostrar registros con valores nulos en FECHA_DEF\n",
    "    registros_nulos_fecha = defunciones_limpio[defunciones_limpio['FECHA_DEF'].isnull()]\n",
    "    print(f\"\\nRegistros con valores nulos en FECHA_DEF: {len(registros_nulos_fecha)}\")\n",
    "    print(\"\\nEjemplos de registros con fecha nula:\")\n",
    "    display(registros_nulos_fecha[['A√ëO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_CANT', 'COMUNA']].head())\n",
    "    \n",
    "    # Estrategia: Imputar con fecha media del a√±o correspondiente\n",
    "    # Esto mantiene la informaci√≥n temporal aproximada\n",
    "    print(\"\\n=== IMPUTACI√ìN DE FECHAS NULAS ===\")\n",
    "    \n",
    "    for a√±o in registros_nulos_fecha['A√ëO'].unique():\n",
    "        # Calcular fecha media del a√±o para registros con fecha v√°lida\n",
    "        fechas_validas_a√±o = defunciones_limpio[\n",
    "            (defunciones_limpio['A√ëO'] == a√±o) & \n",
    "            (defunciones_limpio['FECHA_DEF'].notnull())\n",
    "        ]['FECHA_DEF']\n",
    "        \n",
    "        if len(fechas_validas_a√±o) > 0:\n",
    "            # Convertir a datetime para calcular media\n",
    "            fechas_datetime = pd.to_datetime(fechas_validas_a√±o, errors='coerce')\n",
    "            fecha_media = fechas_datetime.mean()\n",
    "            \n",
    "            # Imputar fecha media en registros nulos del a√±o\n",
    "            mask_nulos_a√±o = (defunciones_limpio['A√ëO'] == a√±o) & (defunciones_limpio['FECHA_DEF'].isnull())\n",
    "            defunciones_limpio.loc[mask_nulos_a√±o, 'FECHA_DEF'] = fecha_media.strftime('%Y-%m-%d')\n",
    "            \n",
    "            print(f\"A√±o {a√±o}: {mask_nulos_a√±o.sum()} registros imputados con fecha {fecha_media.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Verificar que no quedan valores nulos\n",
    "    nulos_restantes = defunciones_limpio['FECHA_DEF'].isnull().sum()\n",
    "    print(f\"\\nValores nulos restantes en FECHA_DEF: {nulos_restantes}\")\n",
    "\n",
    "else:\n",
    "    print(\"No hay valores nulos en FECHA_DEF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2644eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN DEL FORMATO DE FECHAS ===\n",
      "Convirtiendo FECHA_DEF a formato datetime...\n",
      "Fechas que no se pudieron convertir: 0\n",
      "\n",
      "=== CREACI√ìN DE VARIABLES TEMPORALES ===\n",
      "Variables temporales creadas:\n",
      "- A√ëO_FECHA: A√±o de la fecha de defunci√≥n\n",
      "- MES: Mes (1-12)\n",
      "- DIA_SEMANA: D√≠a de la semana\n",
      "- TRIMESTRE: Trimestre (1-4)\n",
      "- DIA_A√ëO: D√≠a del a√±o (1-365/366)\n",
      "\n",
      "Inconsistencias entre A√ëO y A√ëO_FECHA: 0\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Estandarizaci√≥n del formato de fechas\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN DEL FORMATO DE FECHAS ===\")\n",
    "\n",
    "# Convertir FECHA_DEF a datetime para an√°lisis temporal\n",
    "print(\"Convirtiendo FECHA_DEF a formato datetime...\")\n",
    "\n",
    "# Convertir a datetime, manejando posibles errores de formato\n",
    "defunciones_limpio['FECHA_DEF'] = pd.to_datetime(defunciones_limpio['FECHA_DEF'], errors='coerce')\n",
    "\n",
    "# Verificar conversi√≥n\n",
    "fechas_invalidas = defunciones_limpio['FECHA_DEF'].isnull().sum()\n",
    "print(f\"Fechas que no se pudieron convertir: {fechas_invalidas}\")\n",
    "\n",
    "if fechas_invalidas > 0:\n",
    "    print(\"Registros con fechas inv√°lidas:\")\n",
    "    registros_fecha_invalida = defunciones_limpio[defunciones_limpio['FECHA_DEF'].isnull()]\n",
    "    display(registros_fecha_invalida[['A√ëO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_CANT']].head())\n",
    "    \n",
    "    # Eliminar registros con fechas inv√°lidas (son muy pocos)\n",
    "    defunciones_limpio = defunciones_limpio.dropna(subset=['FECHA_DEF'])\n",
    "    print(f\"Registros eliminados por fechas inv√°lidas: {fechas_invalidas}\")\n",
    "\n",
    "# Crear variables temporales derivadas para an√°lisis\n",
    "print(\"\\n=== CREACI√ìN DE VARIABLES TEMPORALES ===\")\n",
    "\n",
    "# Extraer a√±o, mes, d√≠a de la semana, trimestre\n",
    "defunciones_limpio['A√ëO_FECHA'] = defunciones_limpio['FECHA_DEF'].dt.year\n",
    "defunciones_limpio['MES'] = defunciones_limpio['FECHA_DEF'].dt.month\n",
    "defunciones_limpio['DIA_SEMANA'] = defunciones_limpio['FECHA_DEF'].dt.day_name()\n",
    "defunciones_limpio['TRIMESTRE'] = defunciones_limpio['FECHA_DEF'].dt.quarter\n",
    "defunciones_limpio['DIA_A√ëO'] = defunciones_limpio['FECHA_DEF'].dt.dayofyear\n",
    "\n",
    "print(\"Variables temporales creadas:\")\n",
    "print(\"- A√ëO_FECHA: A√±o de la fecha de defunci√≥n\")\n",
    "print(\"- MES: Mes (1-12)\")\n",
    "print(\"- DIA_SEMANA: D√≠a de la semana\")\n",
    "print(\"- TRIMESTRE: Trimestre (1-4)\")\n",
    "print(\"- DIA_A√ëO: D√≠a del a√±o (1-365/366)\")\n",
    "\n",
    "# Verificar consistencia entre A√ëO y A√ëO_FECHA\n",
    "inconsistencias_a√±o = (defunciones_limpio['A√ëO'] != defunciones_limpio['A√ëO_FECHA']).sum()\n",
    "print(f\"\\nInconsistencias entre A√ëO y A√ëO_FECHA: {inconsistencias_a√±o}\")\n",
    "\n",
    "if inconsistencias_a√±o > 0:\n",
    "    print(\"Ejemplos de inconsistencias:\")\n",
    "    inconsistencias = defunciones_limpio[defunciones_limpio['A√ëO'] != defunciones_limpio['A√ëO_FECHA']]\n",
    "    display(inconsistencias[['A√ëO', 'FECHA_DEF', 'A√ëO_FECHA']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ab365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA LIMPIEZA DE DEFUNCIONES_FILTRADAS ===\n",
      "üìä Registros originales: 1,250,062\n",
      "üìä Registros despu√©s de limpieza: 1,246,214\n",
      "üìä Registros eliminados: 3,848\n",
      "üìä Porcentaje de datos conservados: 99.69%\n",
      "\n",
      "=== VERIFICACI√ìN FINAL ===\n",
      "Valores nulos por columna:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Duplicados restantes: 0\n",
      "\n",
      "=== INFORMACI√ìN DEL DATASET LIMPIO ===\n",
      "Columnas: 15\n",
      "Rango de fechas: 2014-01-01 00:00:00 a 2024-09-28 00:00:00\n",
      "A√±os cubiertos: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "‚úÖ Dataset defunciones_filtradas limpiado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 3.6 Resumen de la limpieza del dataset defunciones_filtradas\n",
    "\n",
    "print(\"=== RESUMEN DE LA LIMPIEZA DE DEFUNCIONES_FILTRADAS ===\")\n",
    "print(f\"üìä Registros originales: {defunciones_filtradas.shape[0]:,}\")\n",
    "print(f\"üìä Registros despu√©s de limpieza: {defunciones_limpio.shape[0]:,}\")\n",
    "print(f\"üìä Registros eliminados: {defunciones_filtradas.shape[0] - defunciones_limpio.shape[0]:,}\")\n",
    "print(f\"üìä Porcentaje de datos conservados: {(defunciones_limpio.shape[0] / defunciones_filtradas.shape[0]) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n=== VERIFICACI√ìN FINAL ===\")\n",
    "print(\"Valores nulos por columna:\")\n",
    "nulos_finales = defunciones_limpio.isnull().sum()\n",
    "print(nulos_finales[nulos_finales > 0])\n",
    "\n",
    "print(f\"\\nDuplicados restantes: {defunciones_limpio.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== INFORMACI√ìN DEL DATASET LIMPIO ===\")\n",
    "print(f\"Columnas: {defunciones_limpio.shape[1]}\")\n",
    "print(f\"Rango de fechas: {defunciones_limpio['FECHA_DEF'].min()} a {defunciones_limpio['FECHA_DEF'].max()}\")\n",
    "print(f\"A√±os cubiertos: {sorted(defunciones_limpio['A√ëO'].unique())}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset defunciones_filtradas limpiado exitosamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fdf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASET LIMPIO ===\n",
      "‚úÖ Dataset guardado exitosamente en: C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\defunciones_limpias.csv\n",
      "üìä Tama√±o del archivo: 163.54 MB\n",
      "‚úÖ Verificaci√≥n: Archivo guardado correctamente\n",
      "\n",
      "üìã Muestra del archivo guardado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A√ëO</th>\n",
       "      <th>FECHA_DEF</th>\n",
       "      <th>SEXO_NOMBRE</th>\n",
       "      <th>EDAD_TIPO</th>\n",
       "      <th>EDAD_CANT</th>\n",
       "      <th>COD_COMUNA</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>NOMBRE_REGION</th>\n",
       "      <th>CAPITULO_DIAG1</th>\n",
       "      <th>GLOSA_CAPITULO_DIAG1</th>\n",
       "      <th>A√ëO_FECHA</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA_SEMANA</th>\n",
       "      <th>TRIMESTRE</th>\n",
       "      <th>DIA_A√ëO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13127.0</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8203.0</td>\n",
       "      <td>Ca√±ete</td>\n",
       "      <td>Del B√≠ob√≠o</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13303.0</td>\n",
       "      <td>Tiltil</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>13119.0</td>\n",
       "      <td>Maip√∫</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13115.0</td>\n",
       "      <td>Lo Barnechea</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>S00-T98</td>\n",
       "      <td>Traumatismos, envenenamientos y algunas otras ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A√ëO   FECHA_DEF SEXO_NOMBRE  EDAD_TIPO  EDAD_CANT  COD_COMUNA  \\\n",
       "0  2015  2015-01-11       Mujer        2.0          4     13127.0   \n",
       "1  2016  2016-01-31      Hombre        1.0         20      8203.0   \n",
       "2  2019  2019-08-08      Hombre        1.0         18     13303.0   \n",
       "3  2015  2015-02-17      Hombre        1.0         19     13119.0   \n",
       "4  2015  2015-01-03      Hombre        1.0         18     13115.0   \n",
       "\n",
       "         COMUNA              NOMBRE_REGION CAPITULO_DIAG1  \\\n",
       "0      Recoleta  Metropolitana de Santiago        S00-T98   \n",
       "1        Ca√±ete                 Del B√≠ob√≠o        S00-T98   \n",
       "2        Tiltil  Metropolitana de Santiago        S00-T98   \n",
       "3         Maip√∫  Metropolitana de Santiago        S00-T98   \n",
       "4  Lo Barnechea  Metropolitana de Santiago        S00-T98   \n",
       "\n",
       "                                GLOSA_CAPITULO_DIAG1  A√ëO_FECHA  MES  \\\n",
       "0  Traumatismos, envenenamientos y algunas otras ...       2015    1   \n",
       "1  Traumatismos, envenenamientos y algunas otras ...       2016    1   \n",
       "2  Traumatismos, envenenamientos y algunas otras ...       2019    8   \n",
       "3  Traumatismos, envenenamientos y algunas otras ...       2015    2   \n",
       "4  Traumatismos, envenenamientos y algunas otras ...       2015    1   \n",
       "\n",
       "  DIA_SEMANA  TRIMESTRE  DIA_A√ëO  \n",
       "0     Sunday          1       11  \n",
       "1     Sunday          1       31  \n",
       "2   Thursday          3      220  \n",
       "3    Tuesday          1       48  \n",
       "4   Saturday          1        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.7 Guardar dataset limpio para uso posterior\n",
    "\n",
    "print(\"=== GUARDANDO DATASET LIMPIO ===\")\n",
    "\n",
    "# Crear la carpeta 02_intermediate si no existe\n",
    "import os\n",
    "carpeta_intermediate = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\"\n",
    "if not os.path.exists(carpeta_intermediate):\n",
    "    os.makedirs(carpeta_intermediate)\n",
    "    print(f\"üìÅ Carpeta creada: {carpeta_intermediate}\")\n",
    "\n",
    "# Guardar el dataset limpio en formato CSV\n",
    "ruta_guardado = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\defunciones_limpias.csv\"\n",
    "defunciones_limpio.to_csv(ruta_guardado, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset guardado exitosamente en: {ruta_guardado}\")\n",
    "print(f\"üìä Tama√±o del archivo: {os.path.getsize(ruta_guardado) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Verificar que el archivo se guard√≥ correctamente\n",
    "if os.path.exists(ruta_guardado):\n",
    "    print(\"‚úÖ Verificaci√≥n: Archivo guardado correctamente\")\n",
    "    \n",
    "    # Cargar una muestra para verificar\n",
    "    muestra_verificacion = pd.read_csv(ruta_guardado, nrows=5)\n",
    "    print(\"\\nüìã Muestra del archivo guardado:\")\n",
    "    display(muestra_verificacion)\n",
    "else:\n",
    "    print(\"‚ùå Error: No se pudo guardar el archivo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117bc3e",
   "metadata": {},
   "source": [
    "## 4. Estandarizaci√≥n de Nombres de Columnas\n",
    "\n",
    "Esta secci√≥n se enfoca en unificar y estandarizar los nombres de columnas entre todos los datasets para mantener consistencia en el proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a305d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISIS DE NOMBRES DE COLUMNAS ===\n",
      "\n",
      "üìã POR_SEXO:\n",
      "   Columnas: ['A√±o', 'Nacimiento (Hombre)', 'Nacimiento (Mujer)', 'Defuncion(Hombre)', 'Defuncion (Mujer)']\n",
      "   Dimensiones: (9, 5)\n",
      "\n",
      "üìã DEFUNCIONES_LIMPIO:\n",
      "   Columnas: ['A√ëO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_TIPO', 'EDAD_CANT', 'COD_COMUNA', 'COMUNA', 'NOMBRE_REGION', 'CAPITULO_DIAG1', 'GLOSA_CAPITULO_DIAG1', 'A√ëO_FECHA', 'MES', 'DIA_SEMANA', 'TRIMESTRE', 'DIA_A√ëO']\n",
      "   Dimensiones: (1246214, 15)\n",
      "\n",
      "üìã POR_EDAD_MADRE:\n",
      "   Columnas: ['A√±o', 'Menores de 15 a√±os', '15 a 19 a√±os', '20 a 24 a√±os', '25 a 29 a√±os', '30 a 34 a√±os', '35 a 39 a√±os', '40 a 44 a√±os', '45 a 49 a√±os', '50 y m√°s a√±os']\n",
      "   Dimensiones: (14, 10)\n",
      "\n",
      "üìã POR_EDAD_FALLECIDO:\n",
      "   Columnas: ['A√±o', 'Menores de 1 a√±o', '1 a 4', '5 a 9', '10 a 14', '15 a 19', '20 a 24', '25 a 29', '30 a 34', '35 a 39', '40 a 44', '45 a 49', '50 o mas']\n",
      "   Dimensiones: (14, 13)\n",
      "\n",
      "üìã SETDEDATOS:\n",
      "   Columnas: ['a√±o', 'Nacimientos', 'Defunciones']\n",
      "   Dimensiones: (50, 3)\n",
      "\n",
      "=== PROBLEMAS IDENTIFICADOS ===\n",
      "1. Inconsistencia en 'A√±o' vs 'a√±o'\n",
      "2. Espacios inconsistentes en nombres (ej: 'Defuncion(Hombre)' vs 'Defuncion (Mujer)')\n",
      "3. Nombres de regiones con/sin tildes\n",
      "4. Nombres de columnas muy largos o poco descriptivos\n"
     ]
    }
   ],
   "source": [
    "# 4.1 An√°lisis de nombres de columnas en todos los datasets\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE NOMBRES DE COLUMNAS ===\")\n",
    "\n",
    "# Crear diccionario con todos los datasets para an√°lisis\n",
    "datasets_para_estandarizar = {\n",
    "    \"por_sexo\": por_sexo,\n",
    "    \"defunciones_limpio\": defunciones_limpio,\n",
    "    \"por_edad_madre\": por_edad_madre,\n",
    "    \"por_edad_fallecido\": por_edad_fallecido,\n",
    "    \"setdedatos\": setdedatos\n",
    "}\n",
    "\n",
    "# Mostrar nombres de columnas de cada dataset\n",
    "for nombre_dataset, df in datasets_para_estandarizar.items():\n",
    "    print(f\"\\nüìã {nombre_dataset.upper()}:\")\n",
    "    print(f\"   Columnas: {list(df.columns)}\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "\n",
    "print(\"\\n=== PROBLEMAS IDENTIFICADOS ===\")\n",
    "print(\"1. Inconsistencia en 'A√±o' vs 'a√±o'\")\n",
    "print(\"2. Espacios inconsistentes en nombres (ej: 'Defuncion(Hombre)' vs 'Defuncion (Mujer)')\")\n",
    "print(\"3. Nombres de regiones con/sin tildes\")\n",
    "print(\"4. Nombres de columnas muy largos o poco descriptivos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9f0e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN: POR_SEXO ===\n",
      "Columnas originales:\n",
      "['A√±o', 'Nacimiento (Hombre)', 'Nacimiento (Mujer)', 'Defuncion(Hombre)', 'Defuncion (Mujer)']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['a√±o', 'nacimientos_hombres', 'nacimientos_mujeres', 'defunciones_hombres', 'defunciones_mujeres']\n",
      "\n",
      "‚úÖ Dataset por_sexo estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Estandarizaci√≥n de nombres de columnas - Dataset por_sexo\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN: POR_SEXO ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "por_sexo_estandarizado = por_sexo.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(por_sexo_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_por_sexo = {\n",
    "    'A√±o': 'a√±o',\n",
    "    'Nacimiento (Hombre)': 'nacimientos_hombres',\n",
    "    'Nacimiento (Mujer)': 'nacimientos_mujeres', \n",
    "    'Defuncion(Hombre)': 'defunciones_hombres',\n",
    "    'Defuncion (Mujer)': 'defunciones_mujeres'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "por_sexo_estandarizado = por_sexo_estandarizado.rename(columns=mapeo_por_sexo)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(por_sexo_estandarizado.columns))\n",
    "\n",
    "print(\"\\n‚úÖ Dataset por_sexo estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2a761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN: DEFUNCIONES_LIMPIO ===\n",
      "Columnas originales:\n",
      "['A√ëO', 'FECHA_DEF', 'SEXO_NOMBRE', 'EDAD_TIPO', 'EDAD_CANT', 'COD_COMUNA', 'COMUNA', 'NOMBRE_REGION', 'CAPITULO_DIAG1', 'GLOSA_CAPITULO_DIAG1', 'A√ëO_FECHA', 'MES', 'DIA_SEMANA', 'TRIMESTRE', 'DIA_A√ëO']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['a√±o', 'fecha_defuncion', 'sexo', 'tipo_edad', 'edad_cantidad', 'codigo_comuna', 'comuna', 'region', 'codigo_diagnostico', 'descripcion_diagnostico', 'a√±o_fecha', 'mes', 'dia_semana', 'trimestre', 'dia_a√±o']\n",
      "\n",
      "‚úÖ Dataset defunciones_limpio estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Estandarizaci√≥n de nombres de columnas - Dataset defunciones_limpio\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN: DEFUNCIONES_LIMPIO ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "defunciones_estandarizado = defunciones_limpio.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(defunciones_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_defunciones = {\n",
    "    'A√ëO': 'a√±o',\n",
    "    'FECHA_DEF': 'fecha_defuncion',\n",
    "    'SEXO_NOMBRE': 'sexo',\n",
    "    'EDAD_TIPO': 'tipo_edad',\n",
    "    'EDAD_CANT': 'edad_cantidad',\n",
    "    'COD_COMUNA': 'codigo_comuna',\n",
    "    'COMUNA': 'comuna',\n",
    "    'NOMBRE_REGION': 'region',\n",
    "    'CAPITULO_DIAG1': 'codigo_diagnostico',\n",
    "    'GLOSA_CAPITULO_DIAG1': 'descripcion_diagnostico',\n",
    "    'A√ëO_FECHA': 'a√±o_fecha',\n",
    "    'MES': 'mes',\n",
    "    'DIA_SEMANA': 'dia_semana',\n",
    "    'TRIMESTRE': 'trimestre',\n",
    "    'DIA_A√ëO': 'dia_a√±o'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "defunciones_estandarizado = defunciones_estandarizado.rename(columns=mapeo_defunciones)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(defunciones_estandarizado.columns))\n",
    "\n",
    "print(\"\\n‚úÖ Dataset defunciones_limpio estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da32304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN: POR_EDAD_MADRE ===\n",
      "Columnas originales:\n",
      "['A√±o', 'Menores de 15 a√±os', '15 a 19 a√±os', '20 a 24 a√±os', '25 a 29 a√±os', '30 a 34 a√±os', '35 a 39 a√±os', '40 a 44 a√±os', '45 a 49 a√±os', '50 y m√°s a√±os']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['a√±o', 'nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      "‚úÖ Dataset por_edad_madre estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.4 Estandarizaci√≥n de nombres de columnas - Dataset por_edad_madre\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN: POR_EDAD_MADRE ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "por_edad_madre_estandarizado = por_edad_madre.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(por_edad_madre_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_edad_madre = {\n",
    "    'A√±o': 'a√±o',\n",
    "    'Menores de 15 a√±os': 'nacimientos_menores_15',\n",
    "    '15 a 19 a√±os': 'nacimientos_15_19',\n",
    "    '20 a 24 a√±os': 'nacimientos_20_24',\n",
    "    '25 a 29 a√±os': 'nacimientos_25_29',\n",
    "    '30 a 34 a√±os': 'nacimientos_30_34',\n",
    "    '35 a 39 a√±os': 'nacimientos_35_39',\n",
    "    '40 a 44 a√±os': 'nacimientos_40_44',\n",
    "    '45 a 49 a√±os': 'nacimientos_45_49',\n",
    "    '50 y m√°s a√±os': 'nacimientos_50_mas'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "por_edad_madre_estandarizado = por_edad_madre_estandarizado.rename(columns=mapeo_edad_madre)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(por_edad_madre_estandarizado.columns))\n",
    "\n",
    "print(\"\\n‚úÖ Dataset por_edad_madre estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4384733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN: POR_EDAD_FALLECIDO ===\n",
      "Columnas originales:\n",
      "['A√±o', 'Menores de 1 a√±o', '1 a 4', '5 a 9', '10 a 14', '15 a 19', '20 a 24', '25 a 29', '30 a 34', '35 a 39', '40 a 44', '45 a 49', '50 o mas']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['a√±o', 'defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      "‚úÖ Dataset por_edad_fallecido estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.5 Estandarizaci√≥n de nombres de columnas - Dataset por_edad_fallecido\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN: POR_EDAD_FALLECIDO ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "por_edad_fallecido_estandarizado = por_edad_fallecido.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(por_edad_fallecido_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_edad_fallecido = {\n",
    "    'A√±o': 'a√±o',\n",
    "    'Menores de 1 a√±o': 'defunciones_menores_1',\n",
    "    '1 a 4': 'defunciones_1_4',\n",
    "    '5 a 9': 'defunciones_5_9',\n",
    "    '10 a 14': 'defunciones_10_14',\n",
    "    '15 a 19': 'defunciones_15_19',\n",
    "    '20 a 24': 'defunciones_20_24',\n",
    "    '25 a 29': 'defunciones_25_29',\n",
    "    '30 a 34': 'defunciones_30_34',\n",
    "    '35 a 39': 'defunciones_35_39',\n",
    "    '40 a 44': 'defunciones_40_44',\n",
    "    '45 a 49': 'defunciones_45_49',\n",
    "    '50 o mas': 'defunciones_50_mas'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "por_edad_fallecido_estandarizado = por_edad_fallecido_estandarizado.rename(columns=mapeo_edad_fallecido)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(por_edad_fallecido_estandarizado.columns))\n",
    "\n",
    "print(\"\\n‚úÖ Dataset por_edad_fallecido estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b230d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN: SETDEDATOS ===\n",
      "Columnas originales:\n",
      "['a√±o', 'Nacimientos', 'Defunciones']\n",
      "\n",
      "Columnas estandarizadas:\n",
      "['a√±o', 'nacimientos_totales', 'defunciones_totales']\n",
      "\n",
      "‚úÖ Dataset setdedatos estandarizado\n"
     ]
    }
   ],
   "source": [
    "# 4.6 Estandarizaci√≥n de nombres de columnas - Dataset setdedatos\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN: SETDEDATOS ===\")\n",
    "\n",
    "# Crear copia para trabajar\n",
    "setdedatos_estandarizado = setdedatos.copy()\n",
    "\n",
    "print(\"Columnas originales:\")\n",
    "print(list(setdedatos_estandarizado.columns))\n",
    "\n",
    "# Definir mapeo de nombres de columnas\n",
    "mapeo_setdedatos = {\n",
    "    'a√±o': 'a√±o',  # Ya est√° en min√∫sculas\n",
    "    'Nacimientos': 'nacimientos_totales',\n",
    "    'Defunciones': 'defunciones_totales'\n",
    "}\n",
    "\n",
    "# Renombrar columnas\n",
    "setdedatos_estandarizado = setdedatos_estandarizado.rename(columns=mapeo_setdedatos)\n",
    "\n",
    "print(\"\\nColumnas estandarizadas:\")\n",
    "print(list(setdedatos_estandarizado.columns))\n",
    "\n",
    "print(\"\\n‚úÖ Dataset setdedatos estandarizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc8c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN DE NOMBRES DE REGIONES ===\n",
      "Regiones √∫nicas encontradas:\n",
      " 1. De Ais√©n del Gral. C. Ib√°√±ez del Campo\n",
      " 2. De Antofagasta\n",
      " 3. De Arica y Parinacota\n",
      " 4. De Atacama\n",
      " 5. De Coquimbo\n",
      " 6. De La Araucan√≠a\n",
      " 7. De Los Lagos\n",
      " 8. De Los R√≠os\n",
      " 9. De Magallanes y de La Ant√°rtica Chilena\n",
      "10. De Tarapac√°\n",
      "11. De Valpara√≠so\n",
      "12. De √ëuble\n",
      "13. Del B√≠ob√≠o\n",
      "14. Del Libertador B. O'Higgins\n",
      "15. Del Maule\n",
      "16. Ignorada\n",
      "17. Metropolitana de Santiago\n",
      "\n",
      "Regiones despu√©s de estandarizaci√≥n:\n",
      " 1. De Ais√©n del Gral. C. Ib√°√±ez del Campo\n",
      " 2. De Antofagasta\n",
      " 3. De Arica y Parinacota\n",
      " 4. De Atacama\n",
      " 5. De Coquimbo\n",
      " 6. De La Araucan√≠a\n",
      " 7. De Los Lagos\n",
      " 8. De Los R√≠os\n",
      " 9. De Magallanes y de La Ant√°rtica Chilena\n",
      "10. De Tarapac√°\n",
      "11. De Valpara√≠so\n",
      "12. De √ëuble\n",
      "13. Del Biob√≠o\n",
      "14. Del Libertador General Bernardo O'Higgins\n",
      "15. Del Maule\n",
      "16. Ignorada\n",
      "17. Regi√≥n Metropolitana\n",
      "\n",
      "‚úÖ Nombres de regiones estandarizados\n"
     ]
    }
   ],
   "source": [
    "# 4.7 Estandarizaci√≥n de nombres de regiones\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN DE NOMBRES DE REGIONES ===\")\n",
    "\n",
    "# Analizar nombres √∫nicos de regiones en el dataset de defunciones\n",
    "regiones_unicas = defunciones_estandarizado['region'].unique()\n",
    "print(\"Regiones √∫nicas encontradas:\")\n",
    "for i, region in enumerate(sorted(regiones_unicas), 1):\n",
    "    print(f\"{i:2d}. {region}\")\n",
    "\n",
    "# Definir mapeo para estandarizar nombres de regiones\n",
    "mapeo_regiones = {\n",
    "    'Del B√≠ob√≠o': 'Del Biob√≠o',  # Quitar tilde\n",
    "    'Metropolitana de Santiago': 'Regi√≥n Metropolitana',\n",
    "    'De Tarapac√°': 'De Tarapac√°',  # Ya est√° correcto\n",
    "    'De Antofagasta': 'De Antofagasta',  # Ya est√° correcto\n",
    "    'De Atacama': 'De Atacama',  # Ya est√° correcto\n",
    "    'De Coquimbo': 'De Coquimbo',  # Ya est√° correcto\n",
    "    'De Valpara√≠so': 'De Valpara√≠so',  # Ya est√° correcto\n",
    "    'Del Libertador B. O\\'Higgins': 'Del Libertador General Bernardo O\\'Higgins',\n",
    "    'Del Maule': 'Del Maule',  # Ya est√° correcto\n",
    "    'De √ëuble': 'De √ëuble',  # Ya est√° correcto\n",
    "    'De La Araucan√≠a': 'De La Araucan√≠a',  # Ya est√° correcto\n",
    "    'De Los R√≠os': 'De Los R√≠os',  # Ya est√° correcto\n",
    "    'De Los Lagos': 'De Los Lagos',  # Ya est√° correcto\n",
    "    'De Ays√©n del General Carlos Ib√°√±ez del Campo': 'De Ays√©n del General Carlos Ib√°√±ez del Campo',  # Ya est√° correcto\n",
    "    'De Magallanes y de la Ant√°rtica Chilena': 'De Magallanes y de la Ant√°rtica Chilena'  # Ya est√° correcto\n",
    "}\n",
    "\n",
    "# Aplicar mapeo de regiones\n",
    "defunciones_estandarizado['region'] = defunciones_estandarizado['region'].replace(mapeo_regiones)\n",
    "\n",
    "print(\"\\nRegiones despu√©s de estandarizaci√≥n:\")\n",
    "regiones_estandarizadas = defunciones_estandarizado['region'].unique()\n",
    "for i, region in enumerate(sorted(regiones_estandarizadas), 1):\n",
    "    print(f\"{i:2d}. {region}\")\n",
    "\n",
    "print(\"\\n‚úÖ Nombres de regiones estandarizados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ff8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA ESTANDARIZACI√ìN DE NOMBRES DE COLUMNAS ===\n",
      "üìã Nombres de columnas estandarizados:\n",
      "\n",
      "POR_SEXO_ESTANDARIZADO:\n",
      "   Columnas: ['a√±o', 'nacimientos_hombres', 'nacimientos_mujeres', 'defunciones_hombres', 'defunciones_mujeres']\n",
      "\n",
      "DEFUNCIONES_ESTANDARIZADO:\n",
      "   Columnas: ['a√±o', 'fecha_defuncion', 'sexo', 'tipo_edad', 'edad_cantidad', 'codigo_comuna', 'comuna', 'region', 'codigo_diagnostico', 'descripcion_diagnostico', 'a√±o_fecha', 'mes', 'dia_semana', 'trimestre', 'dia_a√±o']\n",
      "\n",
      "POR_EDAD_MADRE_ESTANDARIZADO:\n",
      "   Columnas: ['a√±o', 'nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      "POR_EDAD_FALLECIDO_ESTANDARIZADO:\n",
      "   Columnas: ['a√±o', 'defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      "SETDEDATOS_ESTANDARIZADO:\n",
      "   Columnas: ['a√±o', 'nacimientos_totales', 'defunciones_totales']\n",
      "\n",
      "=== BENEFICIOS DE LA ESTANDARIZACI√ìN ===\n",
      "‚úÖ Todos los datasets usan 'a√±o' en min√∫sculas\n",
      "‚úÖ Nombres de columnas m√°s descriptivos y consistentes\n",
      "‚úÖ Espacios y caracteres especiales estandarizados\n",
      "‚úÖ Nombres de regiones unificados\n",
      "‚úÖ Facilita la integraci√≥n y an√°lisis posterior\n",
      "\n",
      "=== DATASETS ESTANDARIZADOS DISPONIBLES ===\n",
      "Los siguientes datasets est√°n listos para an√°lisis:\n",
      "  - por_sexo_estandarizado\n",
      "  - defunciones_estandarizado\n",
      "  - por_edad_madre_estandarizado\n",
      "  - por_edad_fallecido_estandarizado\n",
      "  - setdedatos_estandarizado\n",
      "\n",
      "‚úÖ Estandarizaci√≥n de nombres de columnas completada\n"
     ]
    }
   ],
   "source": [
    "# 4.8 Resumen de la estandarizaci√≥n de nombres de columnas\n",
    "\n",
    "print(\"=== RESUMEN DE LA ESTANDARIZACI√ìN DE NOMBRES DE COLUMNAS ===\")\n",
    "\n",
    "# Crear diccionario con todos los datasets estandarizados\n",
    "datasets_estandarizados = {\n",
    "    \"por_sexo_estandarizado\": por_sexo_estandarizado,\n",
    "    \"defunciones_estandarizado\": defunciones_estandarizado,\n",
    "    \"por_edad_madre_estandarizado\": por_edad_madre_estandarizado,\n",
    "    \"por_edad_fallecido_estandarizado\": por_edad_fallecido_estandarizado,\n",
    "    \"setdedatos_estandarizado\": setdedatos_estandarizado\n",
    "}\n",
    "\n",
    "print(\"üìã Nombres de columnas estandarizados:\")\n",
    "for nombre_dataset, df in datasets_estandarizados.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Columnas: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== BENEFICIOS DE LA ESTANDARIZACI√ìN ===\")\n",
    "print(\"‚úÖ Todos los datasets usan 'a√±o' en min√∫sculas\")\n",
    "print(\"‚úÖ Nombres de columnas m√°s descriptivos y consistentes\")\n",
    "print(\"‚úÖ Espacios y caracteres especiales estandarizados\")\n",
    "print(\"‚úÖ Nombres de regiones unificados\")\n",
    "print(\"‚úÖ Facilita la integraci√≥n y an√°lisis posterior\")\n",
    "\n",
    "print(\"\\n=== DATASETS ESTANDARIZADOS DISPONIBLES ===\")\n",
    "print(\"Los siguientes datasets est√°n listos para an√°lisis:\")\n",
    "for nombre in datasets_estandarizados.keys():\n",
    "    print(f\"  - {nombre}\")\n",
    "\n",
    "print(\"\\n‚úÖ Estandarizaci√≥n de nombres de columnas completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d4e9b",
   "metadata": {},
   "source": [
    "## 5. Validaci√≥n de Rangos de Edad\n",
    "\n",
    "Esta secci√≥n se enfoca en verificar la consistencia de los rangos de edad entre datasets y validar que los valores de edad sean l√≥gicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3d34145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISIS DE RANGOS DE EDAD - NACIMIENTOS ===\n",
      "üìã Rangos de edad en nacimientos (por_edad_madre_estandarizado):\n",
      "Columnas de edad: ['nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      "üìä Estad√≠sticas por rango de edad de madre:\n",
      "  nacimientos_menores_15   : Min=   158, Max=   963, Promedio=   558\n",
      "  nacimientos_15_19        : Min=  6428, Max= 38047, Promedio= 20607\n",
      "  nacimientos_20_24        : Min= 28334, Max= 59884, Promedio= 46498\n",
      "  nacimientos_25_29        : Min= 45178, Max= 63210, Promedio= 57008\n",
      "  nacimientos_30_34        : Min= 50523, Max= 57520, Promedio= 54143\n",
      "  nacimientos_35_39        : Min= 30989, Max= 34942, Promedio= 32793\n",
      "  nacimientos_40_44        : Min=  8257, Max=  9545, Promedio=  8869\n",
      "  nacimientos_45_49        : Min=   441, Max=   602, Promedio=   502\n",
      "  nacimientos_50_mas       : Min=     5, Max=    32, Promedio=    17\n",
      "\n",
      "üîç Verificaci√≥n de formato de nombres:\n",
      "  ‚úÖ Formato consistente: nacimientos_menores_15\n",
      "  ‚úÖ Formato consistente: nacimientos_15_19\n",
      "  ‚úÖ Formato consistente: nacimientos_20_24\n",
      "  ‚úÖ Formato consistente: nacimientos_25_29\n",
      "  ‚úÖ Formato consistente: nacimientos_30_34\n",
      "  ‚úÖ Formato consistente: nacimientos_35_39\n",
      "  ‚úÖ Formato consistente: nacimientos_40_44\n",
      "  ‚úÖ Formato consistente: nacimientos_45_49\n",
      "  ‚ö†Ô∏è  Posible inconsistencia en: nacimientos_50_mas\n"
     ]
    }
   ],
   "source": [
    "# 5.1 An√°lisis de rangos de edad en datasets de nacimientos\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE RANGOS DE EDAD - NACIMIENTOS ===\")\n",
    "\n",
    "# Analizar rangos de edad en dataset por_edad_madre\n",
    "print(\"üìã Rangos de edad en nacimientos (por_edad_madre_estandarizado):\")\n",
    "columnas_edad_madre = [col for col in por_edad_madre_estandarizado.columns if col != 'a√±o']\n",
    "print(\"Columnas de edad:\", columnas_edad_madre)\n",
    "\n",
    "# Mostrar estad√≠sticas b√°sicas de cada rango\n",
    "print(\"\\nüìä Estad√≠sticas por rango de edad de madre:\")\n",
    "for col in columnas_edad_madre:\n",
    "    min_val = por_edad_madre_estandarizado[col].min()\n",
    "    max_val = por_edad_madre_estandarizado[col].max()\n",
    "    mean_val = por_edad_madre_estandarizado[col].mean()\n",
    "    print(f\"  {col:25s}: Min={min_val:6.0f}, Max={max_val:6.0f}, Promedio={mean_val:6.0f}\")\n",
    "\n",
    "# Verificar consistencia en el formato de nombres\n",
    "print(\"\\nüîç Verificaci√≥n de formato de nombres:\")\n",
    "for col in columnas_edad_madre:\n",
    "    if 'mas' in col or 'm√°s' in col:\n",
    "        print(f\"  ‚ö†Ô∏è  Posible inconsistencia en: {col}\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Formato consistente: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "972b4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISIS DE RANGOS DE EDAD - DEFUNCIONES ===\n",
      "üìã Rangos de edad en defunciones (por_edad_fallecido_estandarizado):\n",
      "Columnas de edad: ['defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      "üìä Estad√≠sticas por rango de edad de fallecido:\n",
      "  defunciones_menores_1    : Min=  1022, Max=  1908, Promedio=  1512\n",
      "  defunciones_1_4          : Min=   204, Max=   312, Promedio=   253\n",
      "  defunciones_5_9          : Min=   129, Max=   188, Promedio=   161\n",
      "  defunciones_10_14        : Min=   162, Max=   238, Promedio=   200\n",
      "  defunciones_15_19        : Min=   465, Max=   733, Promedio=   574\n",
      "  defunciones_20_24        : Min=   857, Max=  1065, Promedio=   932\n",
      "  defunciones_25_29        : Min=   955, Max=  1276, Promedio=  1101\n",
      "  defunciones_30_34        : Min=  1088, Max=  1618, Promedio=  1255\n",
      "  defunciones_35_39        : Min=  1347, Max=  1803, Promedio=  1516\n",
      "  defunciones_40_44        : Min=  1847, Max=  2391, Promedio=  2081\n",
      "  defunciones_45_49        : Min=  2710, Max=  3589, Promedio=  3017\n",
      "  defunciones_50_mas       : Min= 81954, Max=123781, Promedio= 97781\n",
      "\n",
      "üîç Verificaci√≥n de formato de nombres:\n",
      "  ‚úÖ Formato consistente: defunciones_menores_1\n",
      "  ‚úÖ Formato consistente: defunciones_1_4\n",
      "  ‚úÖ Formato consistente: defunciones_5_9\n",
      "  ‚úÖ Formato consistente: defunciones_10_14\n",
      "  ‚úÖ Formato consistente: defunciones_15_19\n",
      "  ‚úÖ Formato consistente: defunciones_20_24\n",
      "  ‚úÖ Formato consistente: defunciones_25_29\n",
      "  ‚úÖ Formato consistente: defunciones_30_34\n",
      "  ‚úÖ Formato consistente: defunciones_35_39\n",
      "  ‚úÖ Formato consistente: defunciones_40_44\n",
      "  ‚úÖ Formato consistente: defunciones_45_49\n",
      "  ‚ö†Ô∏è  Posible inconsistencia en: defunciones_50_mas\n",
      "\n",
      "üìä An√°lisis de EDAD_CANT en defunciones detalladas:\n",
      "Valores √∫nicos de edad_cantidad: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84), np.int64(85), np.int64(86), np.int64(87), np.int64(88), np.int64(89), np.int64(90), np.int64(91), np.int64(92), np.int64(93), np.int64(94), np.int64(95), np.int64(96), np.int64(97), np.int64(98), np.int64(99), np.int64(100), np.int64(101), np.int64(102), np.int64(103), np.int64(104), np.int64(105), np.int64(106), np.int64(107), np.int64(108), np.int64(109), np.int64(110), np.int64(111), np.int64(112), np.int64(113), np.int64(114), np.int64(115), np.int64(116), np.int64(117), np.int64(118), np.int64(121), np.int64(123), np.int64(126), np.int64(999)]\n",
      "Rango de edad_cantidad: 0 - 999\n",
      "Valores nulos en edad_cantidad: 0\n"
     ]
    }
   ],
   "source": [
    "# 5.2 An√°lisis de rangos de edad en datasets de defunciones\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE RANGOS DE EDAD - DEFUNCIONES ===\")\n",
    "\n",
    "# Analizar rangos de edad en dataset por_edad_fallecido\n",
    "print(\"üìã Rangos de edad en defunciones (por_edad_fallecido_estandarizado):\")\n",
    "columnas_edad_fallecido = [col for col in por_edad_fallecido_estandarizado.columns if col != 'a√±o']\n",
    "print(\"Columnas de edad:\", columnas_edad_fallecido)\n",
    "\n",
    "# Mostrar estad√≠sticas b√°sicas de cada rango\n",
    "print(\"\\nüìä Estad√≠sticas por rango de edad de fallecido:\")\n",
    "for col in columnas_edad_fallecido:\n",
    "    min_val = por_edad_fallecido_estandarizado[col].min()\n",
    "    max_val = por_edad_fallecido_estandarizado[col].max()\n",
    "    mean_val = por_edad_fallecido_estandarizado[col].mean()\n",
    "    print(f\"  {col:25s}: Min={min_val:6.0f}, Max={max_val:6.0f}, Promedio={mean_val:6.0f}\")\n",
    "\n",
    "# Verificar consistencia en el formato de nombres\n",
    "print(\"\\nüîç Verificaci√≥n de formato de nombres:\")\n",
    "for col in columnas_edad_fallecido:\n",
    "    if 'mas' in col or 'm√°s' in col:\n",
    "        print(f\"  ‚ö†Ô∏è  Posible inconsistencia en: {col}\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Formato consistente: {col}\")\n",
    "\n",
    "# Analizar valores de EDAD_CANT en dataset de defunciones detalladas\n",
    "print(\"\\nüìä An√°lisis de EDAD_CANT en defunciones detalladas:\")\n",
    "print(f\"Valores √∫nicos de edad_cantidad: {sorted(defunciones_estandarizado['edad_cantidad'].unique())}\")\n",
    "print(f\"Rango de edad_cantidad: {defunciones_estandarizado['edad_cantidad'].min()} - {defunciones_estandarizado['edad_cantidad'].max()}\")\n",
    "print(f\"Valores nulos en edad_cantidad: {defunciones_estandarizado['edad_cantidad'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a695853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACI√ìN DE RANGOS DE EDAD ENTRE DATASETS ===\n",
      "üìã Rangos de edad en nacimientos:\n",
      "  nacimientos_menores_15    ‚Üí 0-14\n",
      "  nacimientos_15_19         ‚Üí 15-19\n",
      "  nacimientos_20_24         ‚Üí 20-24\n",
      "  nacimientos_25_29         ‚Üí 25-29\n",
      "  nacimientos_30_34         ‚Üí 30-34\n",
      "  nacimientos_35_39         ‚Üí 35-39\n",
      "  nacimientos_40_44         ‚Üí 40-44\n",
      "  nacimientos_45_49         ‚Üí 45-49\n",
      "  nacimientos_50_mas        ‚Üí 50+\n",
      "\n",
      "üìã Rangos de edad en defunciones:\n",
      "  defunciones_menores_1     ‚Üí 0-1\n",
      "  defunciones_1_4           ‚Üí 1-4\n",
      "  defunciones_5_9           ‚Üí 5-9\n",
      "  defunciones_10_14         ‚Üí 10-14\n",
      "  defunciones_15_19         ‚Üí 15-19\n",
      "  defunciones_20_24         ‚Üí 20-24\n",
      "  defunciones_25_29         ‚Üí 25-29\n",
      "  defunciones_30_34         ‚Üí 30-34\n",
      "  defunciones_35_39         ‚Üí 35-39\n",
      "  defunciones_40_44         ‚Üí 40-44\n",
      "  defunciones_45_49         ‚Üí 45-49\n",
      "  defunciones_50_mas        ‚Üí 50+\n",
      "\n",
      "üîç Rangos de edad comunes: ['15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50+']\n",
      "üìä Rangos √∫nicos en nacimientos: ['0-14']\n",
      "üìä Rangos √∫nicos en defunciones: ['0-1', '1-4', '10-14', '5-9']\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Comparaci√≥n de rangos de edad entre datasets\n",
    "\n",
    "print(\"=== COMPARACI√ìN DE RANGOS DE EDAD ENTRE DATASETS ===\")\n",
    "\n",
    "# Crear mapeo de rangos de edad para comparaci√≥n\n",
    "rangos_nacimientos = {\n",
    "    'nacimientos_menores_15': '0-14',\n",
    "    'nacimientos_15_19': '15-19', \n",
    "    'nacimientos_20_24': '20-24',\n",
    "    'nacimientos_25_29': '25-29',\n",
    "    'nacimientos_30_34': '30-34',\n",
    "    'nacimientos_35_39': '35-39',\n",
    "    'nacimientos_40_44': '40-44',\n",
    "    'nacimientos_45_49': '45-49',\n",
    "    'nacimientos_50_mas': '50+'\n",
    "}\n",
    "\n",
    "rangos_defunciones = {\n",
    "    'defunciones_menores_1': '0-1',\n",
    "    'defunciones_1_4': '1-4',\n",
    "    'defunciones_5_9': '5-9',\n",
    "    'defunciones_10_14': '10-14',\n",
    "    'defunciones_15_19': '15-19',\n",
    "    'defunciones_20_24': '20-24',\n",
    "    'defunciones_25_29': '25-29',\n",
    "    'defunciones_30_34': '30-34',\n",
    "    'defunciones_35_39': '35-39',\n",
    "    'defunciones_40_44': '40-44',\n",
    "    'defunciones_45_49': '45-49',\n",
    "    'defunciones_50_mas': '50+'\n",
    "}\n",
    "\n",
    "print(\"üìã Rangos de edad en nacimientos:\")\n",
    "for col, rango in rangos_nacimientos.items():\n",
    "    print(f\"  {col:25s} ‚Üí {rango}\")\n",
    "\n",
    "print(\"\\nüìã Rangos de edad en defunciones:\")\n",
    "for col, rango in rangos_defunciones.items():\n",
    "    print(f\"  {col:25s} ‚Üí {rango}\")\n",
    "\n",
    "# Identificar rangos superpuestos\n",
    "rangos_comunes = set(rangos_nacimientos.values()) & set(rangos_defunciones.values())\n",
    "print(f\"\\nüîç Rangos de edad comunes: {sorted(rangos_comunes)}\")\n",
    "\n",
    "# Identificar rangos √∫nicos\n",
    "rangos_unicos_nacimientos = set(rangos_nacimientos.values()) - set(rangos_defunciones.values())\n",
    "rangos_unicos_defunciones = set(rangos_defunciones.values()) - set(rangos_nacimientos.values())\n",
    "\n",
    "print(f\"üìä Rangos √∫nicos en nacimientos: {sorted(rangos_unicos_nacimientos)}\")\n",
    "print(f\"üìä Rangos √∫nicos en defunciones: {sorted(rangos_unicos_defunciones)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "220a2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACI√ìN DE VALORES DE EDAD EN DATASET DETALLADO ===\n",
      "üìä Distribuci√≥n de edad_cantidad:\n",
      "count    1.246214e+06\n",
      "mean     7.221377e+01\n",
      "std      1.880039e+01\n",
      "min      0.000000e+00\n",
      "25%      6.300000e+01\n",
      "50%      7.600000e+01\n",
      "75%      8.600000e+01\n",
      "max      9.990000e+02\n",
      "Name: edad_cantidad, dtype: float64\n",
      "\n",
      "üîç Eliminando edades imposibles (>120 a√±os):\n",
      "Registros con edad > 120 a√±os: 14\n",
      "Ejemplos de edades imposibles:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a√±o</th>\n",
       "      <th>fecha_defuncion</th>\n",
       "      <th>sexo</th>\n",
       "      <th>edad_cantidad</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De La Araucan√≠a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24752</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De Tarapac√°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32330</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-30</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De La Araucan√≠a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41877</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>121</td>\n",
       "      <td>De Los R√≠os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43947</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>999</td>\n",
       "      <td>De √ëuble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a√±o fecha_defuncion    sexo  edad_cantidad           region\n",
       "4545   2014      2014-06-30  Hombre            999  De La Araucan√≠a\n",
       "24752  2014      2014-04-19  Hombre            999      De Tarapac√°\n",
       "32330  2015      2015-10-30  Hombre            999  De La Araucan√≠a\n",
       "41877  2018      2018-04-18  Hombre            121      De Los R√≠os\n",
       "43947  2014      2014-03-21  Hombre            999         De √ëuble"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Eliminados 14 registros con edad > 120 a√±os\n",
      "üìä Dataset actualizado: 1,246,200 registros\n",
      "\n",
      "‚úÖ TODAS LAS EDADES SON V√ÅLIDAS\n",
      "üìä Rango de edades: 0 - 118 a√±os\n",
      "\n",
      "ÔøΩÔøΩ Distribuci√≥n por grupos de edad:\n",
      "  0-1 a√±os    :  6,358 (  0.5%)\n",
      "  2-4 a√±os    :  6,135 (  0.5%)\n",
      "  5-17 a√±os   : 11,417 (  0.9%)\n",
      "  18-64 a√±os  : 331,208 ( 26.6%)\n",
      "  65+ a√±os    : 891,071 ( 71.5%)\n",
      "\n",
      "üîç Validaci√≥n de rangos l√≥gicos:\n",
      "Registros con edad negativa: 0\n",
      "\n",
      "‚úÖ Validaci√≥n completada: Dataset limpio con edades v√°lidas\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Validaci√≥n de valores de edad en dataset detallado (MODIFICADO)\n",
    "\n",
    "print(\"=== VALIDACI√ìN DE VALORES DE EDAD EN DATASET DETALLADO ===\")\n",
    "\n",
    "# Analizar distribuci√≥n de valores de edad_cantidad\n",
    "print(\"üìä Distribuci√≥n de edad_cantidad:\")\n",
    "print(defunciones_estandarizado['edad_cantidad'].describe())\n",
    "\n",
    "# 1. ELIMINAR edades imposibles (>120 a√±os)\n",
    "print(\"\\nüîç Eliminando edades imposibles (>120 a√±os):\")\n",
    "edades_imposibles = defunciones_estandarizado[defunciones_estandarizado['edad_cantidad'] > 120]\n",
    "print(f\"Registros con edad > 120 a√±os: {len(edades_imposibles)}\")\n",
    "\n",
    "if len(edades_imposibles) > 0:\n",
    "    print(\"Ejemplos de edades imposibles:\")\n",
    "    display(edades_imposibles[['a√±o', 'fecha_defuncion', 'sexo', 'edad_cantidad', 'region']].head())\n",
    "    \n",
    "    # Eliminar estos registros\n",
    "    defunciones_estandarizado = defunciones_estandarizado[defunciones_estandarizado['edad_cantidad'] <= 120]\n",
    "    print(f\"\\n‚úÖ Eliminados {len(edades_imposibles)} registros con edad > 120 a√±os\")\n",
    "    print(f\"üìä Dataset actualizado: {len(defunciones_estandarizado):,} registros\")\n",
    "\n",
    "# 2. NO detectar outliers por edad (todas las edades son v√°lidas)\n",
    "print(f\"\\n‚úÖ TODAS LAS EDADES SON V√ÅLIDAS\")\n",
    "print(f\"üìä Rango de edades: {defunciones_estandarizado['edad_cantidad'].min()} - {defunciones_estandarizado['edad_cantidad'].max()} a√±os\")\n",
    "\n",
    "# 3. Mostrar distribuci√≥n por grupos de edad\n",
    "print(f\"\\nÔøΩÔøΩ Distribuci√≥n por grupos de edad:\")\n",
    "defunciones_estandarizado['grupo_edad'] = pd.cut(defunciones_estandarizado['edad_cantidad'], \n",
    "                                                bins=[0, 1, 5, 18, 65, 120], \n",
    "                                                labels=['0-1 a√±os', '2-4 a√±os', '5-17 a√±os', '18-64 a√±os', '65+ a√±os'])\n",
    "distribucion_grupos = defunciones_estandarizado['grupo_edad'].value_counts().sort_index()\n",
    "for grupo, cantidad in distribucion_grupos.items():\n",
    "    porcentaje = (cantidad / len(defunciones_estandarizado)) * 100\n",
    "    print(f\"  {grupo:12s}: {cantidad:6,} ({porcentaje:5.1f}%)\")\n",
    "\n",
    "# 4. Solo validar rangos l√≥gicos b√°sicos\n",
    "print(f\"\\nüîç Validaci√≥n de rangos l√≥gicos:\")\n",
    "edades_negativas = defunciones_estandarizado[defunciones_estandarizado['edad_cantidad'] < 0]\n",
    "print(f\"Registros con edad negativa: {len(edades_negativas)}\")\n",
    "\n",
    "if len(edades_negativas) > 0:\n",
    "    print(\"Ejemplos de edades negativas:\")\n",
    "    display(edades_negativas[['a√±o', 'fecha_defuncion', 'sexo', 'edad_cantidad']].head())\n",
    "\n",
    "print(f\"\\n‚úÖ Validaci√≥n completada: Dataset limpio con edades v√°lidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ceee0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTANDARIZACI√ìN FINAL DE RANGOS DE EDAD ===\n",
      "üìã Creando datasets con rangos de edad estandarizados...\n",
      "‚úÖ Dataset nacimientos por edad: ya estandarizado\n",
      "‚úÖ Dataset defunciones por edad: ya estandarizado\n",
      "\n",
      "ÔøΩÔøΩ Distribuci√≥n de rangos de edad en defunciones detalladas:\n",
      "rango_edad\n",
      "100_mas       11429\n",
      "10_14          3344\n",
      "15_19          6463\n",
      "1_4           11459\n",
      "20_24         10257\n",
      "25_29         12511\n",
      "30_34         14136\n",
      "35_39         16647\n",
      "40_44         22356\n",
      "45_49         31723\n",
      "50_54         47168\n",
      "55_59         67120\n",
      "5_9            4362\n",
      "60_64         87673\n",
      "65_69        108708\n",
      "70_74        131625\n",
      "75_79        152925\n",
      "80_84        168669\n",
      "85_89        167254\n",
      "90_94        121052\n",
      "95_99         49308\n",
      "menores_1        11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Registros con edad problem√°tica: 0\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Estandarizaci√≥n final de rangos de edad\n",
    "\n",
    "print(\"=== ESTANDARIZACI√ìN FINAL DE RANGOS DE EDAD ===\")\n",
    "\n",
    "# Crear datasets finales con rangos de edad estandarizados\n",
    "print(\"üìã Creando datasets con rangos de edad estandarizados...\")\n",
    "\n",
    "# Dataset de nacimientos por edad (ya est√° estandarizado)\n",
    "nacimientos_edad_final = por_edad_madre_estandarizado.copy()\n",
    "print(\"‚úÖ Dataset nacimientos por edad: ya estandarizado\")\n",
    "\n",
    "# Dataset de defunciones por edad (ya est√° estandarizado)\n",
    "defunciones_edad_final = por_edad_fallecido_estandarizado.copy()\n",
    "print(\"‚úÖ Dataset defunciones por edad: ya estandarizado\")\n",
    "\n",
    "# Crear funci√≥n para categorizar edad en rangos est√°ndar\n",
    "def categorizar_edad(edad):\n",
    "    \"\"\"\n",
    "    Categoriza la edad en rangos est√°ndar para an√°lisis\n",
    "    \"\"\"\n",
    "    if pd.isna(edad):\n",
    "        return 'desconocida'\n",
    "    elif edad < 0:\n",
    "        return 'edad_invalida'\n",
    "    elif edad < 1:\n",
    "        return 'menores_1'\n",
    "    elif edad < 5:\n",
    "        return '1_4'\n",
    "    elif edad < 10:\n",
    "        return '5_9'\n",
    "    elif edad < 15:\n",
    "        return '10_14'\n",
    "    elif edad < 20:\n",
    "        return '15_19'\n",
    "    elif edad < 25:\n",
    "        return '20_24'\n",
    "    elif edad < 30:\n",
    "        return '25_29'\n",
    "    elif edad < 35:\n",
    "        return '30_34'\n",
    "    elif edad < 40:\n",
    "        return '35_39'\n",
    "    elif edad < 45:\n",
    "        return '40_44'\n",
    "    elif edad < 50:\n",
    "        return '45_49'\n",
    "    elif edad < 55:\n",
    "        return '50_54'\n",
    "    elif edad < 60:\n",
    "        return '55_59'\n",
    "    elif edad < 65:\n",
    "        return '60_64'\n",
    "    elif edad < 70:\n",
    "        return '65_69'\n",
    "    elif edad < 75:\n",
    "        return '70_74'\n",
    "    elif edad < 80:\n",
    "        return '75_79'\n",
    "    elif edad < 85:\n",
    "        return '80_84'\n",
    "    elif edad < 90:\n",
    "        return '85_89'\n",
    "    elif edad < 95:\n",
    "        return '90_94'\n",
    "    elif edad < 100:\n",
    "        return '95_99'\n",
    "    else:\n",
    "        return '100_mas'\n",
    "\n",
    "# Aplicar categorizaci√≥n al dataset de defunciones detalladas\n",
    "defunciones_estandarizado['rango_edad'] = defunciones_estandarizado['edad_cantidad'].apply(categorizar_edad)\n",
    "\n",
    "print(\"\\nÔøΩÔøΩ Distribuci√≥n de rangos de edad en defunciones detalladas:\")\n",
    "distribucion_rangos = defunciones_estandarizado['rango_edad'].value_counts().sort_index()\n",
    "print(distribucion_rangos)\n",
    "\n",
    "# Verificar que no hay valores problem√°ticos\n",
    "valores_problematicos = defunciones_estandarizado[defunciones_estandarizado['rango_edad'].isin(['desconocida', 'edad_invalida'])]\n",
    "print(f\"\\nRegistros con edad problem√°tica: {len(valores_problematicos)}\")\n",
    "\n",
    "if len(valores_problematicos) > 0:\n",
    "    print(\"Ejemplos de registros problem√°ticos:\")\n",
    "    display(valores_problematicos[['a√±o', 'fecha_defuncion', 'sexo', 'edad_cantidad', 'rango_edad']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd878a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA VALIDACI√ìN DE RANGOS DE EDAD ===\n",
      "ÔøΩÔøΩ Datasets con rangos de edad validados:\n",
      "\n",
      "NACIMIENTOS_EDAD_FINAL:\n",
      "   Dimensiones: (14, 10)\n",
      "   Columnas relacionadas con edad: ['nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas']\n",
      "\n",
      "DEFUNCIONES_EDAD_FINAL:\n",
      "   Dimensiones: (14, 13)\n",
      "   Columnas relacionadas con edad: ['defunciones_menores_1', 'defunciones_1_4', 'defunciones_5_9', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_mas']\n",
      "\n",
      "DEFUNCIONES_ESTANDARIZADO:\n",
      "   Dimensiones: (1246200, 17)\n",
      "   Columnas relacionadas con edad: ['tipo_edad', 'edad_cantidad', 'grupo_edad', 'rango_edad']\n",
      "\n",
      "=== BENEFICIOS DE LA VALIDACI√ìN ===\n",
      "‚úÖ Rangos de edad consistentes entre datasets\n",
      "‚úÖ Formato estandarizado ('50_mas' en lugar de '50 y m√°s' o '50 o mas')\n",
      "‚úÖ Validaci√≥n de valores l√≥gicos de edad\n",
      "‚úÖ Eliminaci√≥n de edades imposibles (>120 a√±os)\n",
      "‚úÖ Preservaci√≥n de todos los casos de menores de 18 a√±os\n",
      "‚úÖ Nueva columna 'rango_edad' para an√°lisis categ√≥rico\n",
      "‚úÖ Funci√≥n de categorizaci√≥n reutilizable con rangos detallados\n",
      "\n",
      "=== RANGOS DE EDAD EST√ÅNDAR (ACTUALIZADOS) ===\n",
      "Rangos est√°ndar implementados:\n",
      "   1. menores_1\n",
      "   2. 1_4\n",
      "   3. 5_9\n",
      "   4. 10_14\n",
      "   5. 15_19\n",
      "   6. 20_24\n",
      "   7. 25_29\n",
      "   8. 30_34\n",
      "   9. 35_39\n",
      "  10. 40_44\n",
      "  11. 45_49\n",
      "  12. 50_54\n",
      "  13. 55_59\n",
      "  14. 60_64\n",
      "  15. 65_69\n",
      "  16. 70_74\n",
      "  17. 75_79\n",
      "  18. 80_84\n",
      "  19. 85_89\n",
      "  20. 90_94\n",
      "  21. 95_99\n",
      "  22. 100_mas\n",
      "\n",
      "=== CORRECCIONES APLICADAS ===\n",
      "ÔøΩÔøΩ Eliminados registros con edad > 120 a√±os (errores de captura)\n",
      "üîß Preservados todos los casos de menores de 18 a√±os\n",
      "üîß Agregados rangos detallados para adultos mayores (50-100+ a√±os)\n",
      "üîß Eliminada detecci√≥n de outliers por edad (todas las edades son v√°lidas)\n",
      "\n",
      "‚úÖ Validaci√≥n de rangos de edad completada\n"
     ]
    }
   ],
   "source": [
    "# 5.6 Resumen de la validaci√≥n de rangos de edad\n",
    "\n",
    "print(\"=== RESUMEN DE LA VALIDACI√ìN DE RANGOS DE EDAD ===\")\n",
    "\n",
    "# Crear diccionario con datasets finales de edad\n",
    "datasets_edad_finales = {\n",
    "    \"nacimientos_edad_final\": nacimientos_edad_final,\n",
    "    \"defunciones_edad_final\": defunciones_edad_final,\n",
    "    \"defunciones_estandarizado\": defunciones_estandarizado  # Incluye nueva columna rango_edad\n",
    "}\n",
    "\n",
    "print(\"ÔøΩÔøΩ Datasets con rangos de edad validados:\")\n",
    "for nombre_dataset, df in datasets_edad_finales.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    columnas_edad = [col for col in df.columns if 'edad' in col.lower() or 'nacimientos_' in col or 'defunciones_' in col]\n",
    "    print(f\"   Columnas relacionadas con edad: {columnas_edad}\")\n",
    "\n",
    "print(\"\\n=== BENEFICIOS DE LA VALIDACI√ìN ===\")\n",
    "print(\"‚úÖ Rangos de edad consistentes entre datasets\")\n",
    "print(\"‚úÖ Formato estandarizado ('50_mas' en lugar de '50 y m√°s' o '50 o mas')\")\n",
    "print(\"‚úÖ Validaci√≥n de valores l√≥gicos de edad\")\n",
    "print(\"‚úÖ Eliminaci√≥n de edades imposibles (>120 a√±os)\")\n",
    "print(\"‚úÖ Preservaci√≥n de todos los casos de menores de 18 a√±os\")\n",
    "print(\"‚úÖ Nueva columna 'rango_edad' para an√°lisis categ√≥rico\")\n",
    "print(\"‚úÖ Funci√≥n de categorizaci√≥n reutilizable con rangos detallados\")\n",
    "\n",
    "print(\"\\n=== RANGOS DE EDAD EST√ÅNDAR (ACTUALIZADOS) ===\")\n",
    "rangos_estandar = [\n",
    "    'menores_1', '1_4', '5_9', '10_14', '15_19', '20_24', \n",
    "    '25_29', '30_34', '35_39', '40_44', '45_49', '50_54',\n",
    "    '55_59', '60_64', '65_69', '70_74', '75_79', '80_84',\n",
    "    '85_89', '90_94', '95_99', '100_mas'\n",
    "]\n",
    "print(\"Rangos est√°ndar implementados:\")\n",
    "for i, rango in enumerate(rangos_estandar, 1):\n",
    "    print(f\"  {i:2d}. {rango}\")\n",
    "\n",
    "print(\"\\n=== CORRECCIONES APLICADAS ===\")\n",
    "print(\"ÔøΩÔøΩ Eliminados registros con edad > 120 a√±os (errores de captura)\")\n",
    "print(\"üîß Preservados todos los casos de menores de 18 a√±os\")\n",
    "print(\"üîß Agregados rangos detallados para adultos mayores (50-100+ a√±os)\")\n",
    "print(\"üîß Eliminada detecci√≥n de outliers por edad (todas las edades son v√°lidas)\")\n",
    "\n",
    "print(\"\\n‚úÖ Validaci√≥n de rangos de edad completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d41b52",
   "metadata": {},
   "source": [
    "## 6. Integraci√≥n de Datasets\n",
    "\n",
    "Esta secci√≥n se enfoca en crear un dataset unificado temporal combinando informaci√≥n de diferentes fuentes y generando variables derivadas √∫tiles para an√°lisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8351ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISIS DE PER√çODOS TEMPORALES ===\n",
      "üìÖ Per√≠odos temporales por dataset:\n",
      "\n",
      "SETDEDATOS_ESTANDARIZADO:\n",
      "   A√±os: 1974 - 2023 (50 a√±os)\n",
      "   Rango completo: [np.int64(1974), np.int64(1975), np.int64(1976), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1983), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1990), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "POR_SEXO_ESTANDARIZADO:\n",
      "   A√±os: 2015 - 2023 (9 a√±os)\n",
      "   Rango completo: [np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "NACIMIENTOS_EDAD_FINAL:\n",
      "   A√±os: 2010 - 2023 (14 a√±os)\n",
      "   Rango completo: [np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "DEFUNCIONES_EDAD_FINAL:\n",
      "   A√±os: 2010 - 2023 (14 a√±os)\n",
      "   Rango completo: [np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "DEFUNCIONES_ESTANDARIZADO:\n",
      "   A√±os: 2014 - 2024 (11 a√±os)\n",
      "   Rango completo: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "üîç An√°lisis de cobertura temporal:\n",
      "A√±os en setdedatos (1974-2023): 50 a√±os\n",
      "A√±os en por_sexo (2015-2023): 9 a√±os\n",
      "A√±os en nacimientos_edad (2010-2023): 14 a√±os\n",
      "A√±os en defunciones_edad (2010-2023): 14 a√±os\n",
      "\n",
      "A√±os comunes a todos los datasets: [np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)] (9 a√±os)\n",
      "A√±os √∫nicos en setdedatos: [np.int64(1974), np.int64(1975), np.int64(1976), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1983), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1990), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014)]\n",
      "A√±os √∫nicos en por_sexo: []\n"
     ]
    }
   ],
   "source": [
    "# 6.1 An√°lisis de per√≠odos temporales en todos los datasets\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE PER√çODOS TEMPORALES ===\")\n",
    "\n",
    "# Analizar rangos de a√±os en cada dataset\n",
    "datasets_temporales = {\n",
    "    \"setdedatos_estandarizado\": setdedatos_estandarizado,\n",
    "    \"por_sexo_estandarizado\": por_sexo_estandarizado,\n",
    "    \"nacimientos_edad_final\": nacimientos_edad_final,\n",
    "    \"defunciones_edad_final\": defunciones_edad_final,\n",
    "    \"defunciones_estandarizado\": defunciones_estandarizado\n",
    "}\n",
    "\n",
    "print(\"üìÖ Per√≠odos temporales por dataset:\")\n",
    "for nombre_dataset, df in datasets_temporales.items():\n",
    "    a√±os = sorted(df['a√±o'].unique())\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   A√±os: {a√±os[0]} - {a√±os[-1]} ({len(a√±os)} a√±os)\")\n",
    "    print(f\"   Rango completo: {a√±os}\")\n",
    "\n",
    "# Identificar a√±os comunes y √∫nicos\n",
    "a√±os_setdedatos = set(setdedatos_estandarizado['a√±o'].unique())\n",
    "a√±os_por_sexo = set(por_sexo_estandarizado['a√±o'].unique())\n",
    "a√±os_nacimientos_edad = set(nacimientos_edad_final['a√±o'].unique())\n",
    "a√±os_defunciones_edad = set(defunciones_edad_final['a√±o'].unique())\n",
    "\n",
    "print(f\"\\nüîç An√°lisis de cobertura temporal:\")\n",
    "print(f\"A√±os en setdedatos (1974-2023): {len(a√±os_setdedatos)} a√±os\")\n",
    "print(f\"A√±os en por_sexo (2015-2023): {len(a√±os_por_sexo)} a√±os\")\n",
    "print(f\"A√±os en nacimientos_edad (2010-2023): {len(a√±os_nacimientos_edad)} a√±os\")\n",
    "print(f\"A√±os en defunciones_edad (2010-2023): {len(a√±os_defunciones_edad)} a√±os\")\n",
    "\n",
    "# A√±os comunes para integraci√≥n\n",
    "a√±os_comunes = a√±os_setdedatos & a√±os_por_sexo & a√±os_nacimientos_edad & a√±os_defunciones_edad\n",
    "print(f\"\\nA√±os comunes a todos los datasets: {sorted(a√±os_comunes)} ({len(a√±os_comunes)} a√±os)\")\n",
    "\n",
    "# A√±os √∫nicos en cada dataset\n",
    "a√±os_unicos_setdedatos = a√±os_setdedatos - a√±os_por_sexo\n",
    "a√±os_unicos_por_sexo = a√±os_por_sexo - a√±os_setdedatos\n",
    "print(f\"A√±os √∫nicos en setdedatos: {sorted(a√±os_unicos_setdedatos)}\")\n",
    "print(f\"A√±os √∫nicos en por_sexo: {sorted(a√±os_unicos_por_sexo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fee72419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACI√ìN DE DATASET UNIFICADO TEMPORAL ===\n",
      "üìä Dataset base (setdedatos): 50 registros, 3 columnas\n",
      "\n",
      "üîó Integrando informaci√≥n por sexo...\n",
      "üìä Despu√©s de integrar por_sexo: 50 registros, 7 columnas\n",
      "\n",
      "üìã Columnas del dataset unificado:\n",
      "['a√±o', 'nacimientos_totales', 'defunciones_totales', 'nacimientos_hombres', 'nacimientos_mujeres', 'defunciones_hombres', 'defunciones_mujeres']\n",
      "\n",
      "üìÖ A√±os con informaci√≥n completa (2015-2023): 9 a√±os\n",
      "üìÖ A√±os con informaci√≥n parcial (1974-2014): 41 a√±os\n",
      "\n",
      "Primeras filas del dataset unificado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a√±o</th>\n",
       "      <th>nacimientos_totales</th>\n",
       "      <th>defunciones_totales</th>\n",
       "      <th>nacimientos_hombres</th>\n",
       "      <th>nacimientos_mujeres</th>\n",
       "      <th>defunciones_hombres</th>\n",
       "      <th>defunciones_mujeres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>171992</td>\n",
       "      <td>121270</td>\n",
       "      <td>87713.0</td>\n",
       "      <td>84262.0</td>\n",
       "      <td>63174.0</td>\n",
       "      <td>58085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189310</td>\n",
       "      <td>136958</td>\n",
       "      <td>96011.0</td>\n",
       "      <td>93284.0</td>\n",
       "      <td>71676.0</td>\n",
       "      <td>65275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>177255</td>\n",
       "      <td>137439</td>\n",
       "      <td>90355.0</td>\n",
       "      <td>86883.0</td>\n",
       "      <td>73308.0</td>\n",
       "      <td>64119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>194952</td>\n",
       "      <td>125833</td>\n",
       "      <td>99908.0</td>\n",
       "      <td>95025.0</td>\n",
       "      <td>67453.0</td>\n",
       "      <td>58367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>210188</td>\n",
       "      <td>109658</td>\n",
       "      <td>107353.0</td>\n",
       "      <td>102812.0</td>\n",
       "      <td>57632.0</td>\n",
       "      <td>52010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>221731</td>\n",
       "      <td>106796</td>\n",
       "      <td>113039.0</td>\n",
       "      <td>108668.0</td>\n",
       "      <td>56093.0</td>\n",
       "      <td>50684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>219186</td>\n",
       "      <td>106388</td>\n",
       "      <td>111660.0</td>\n",
       "      <td>107501.0</td>\n",
       "      <td>55773.0</td>\n",
       "      <td>50593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>231749</td>\n",
       "      <td>104026</td>\n",
       "      <td>117801.0</td>\n",
       "      <td>113920.0</td>\n",
       "      <td>54761.0</td>\n",
       "      <td>49239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>244670</td>\n",
       "      <td>103327</td>\n",
       "      <td>124713.0</td>\n",
       "      <td>119936.0</td>\n",
       "      <td>54693.0</td>\n",
       "      <td>48615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014</td>\n",
       "      <td>250997</td>\n",
       "      <td>101960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a√±o  nacimientos_totales  defunciones_totales  nacimientos_hombres  \\\n",
       "0  2023               171992               121270              87713.0   \n",
       "1  2022               189310               136958              96011.0   \n",
       "2  2021               177255               137439              90355.0   \n",
       "3  2020               194952               125833              99908.0   \n",
       "4  2019               210188               109658             107353.0   \n",
       "5  2018               221731               106796             113039.0   \n",
       "6  2017               219186               106388             111660.0   \n",
       "7  2016               231749               104026             117801.0   \n",
       "8  2015               244670               103327             124713.0   \n",
       "9  2014               250997               101960                  NaN   \n",
       "\n",
       "   nacimientos_mujeres  defunciones_hombres  defunciones_mujeres  \n",
       "0              84262.0              63174.0              58085.0  \n",
       "1              93284.0              71676.0              65275.0  \n",
       "2              86883.0              73308.0              64119.0  \n",
       "3              95025.0              67453.0              58367.0  \n",
       "4             102812.0              57632.0              52010.0  \n",
       "5             108668.0              56093.0              50684.0  \n",
       "6             107501.0              55773.0              50593.0  \n",
       "7             113920.0              54761.0              49239.0  \n",
       "8             119936.0              54693.0              48615.0  \n",
       "9                  NaN                  NaN                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6.2 Crear dataset unificado temporal b√°sico\n",
    "\n",
    "print(\"=== CREACI√ìN DE DATASET UNIFICADO TEMPORAL ===\")\n",
    "\n",
    "# Crear dataset base con informaci√≥n de setdedatos (serie m√°s larga: 1974-2023)\n",
    "dataset_unificado = setdedatos_estandarizado.copy()\n",
    "print(f\"üìä Dataset base (setdedatos): {dataset_unificado.shape[0]} registros, {dataset_unificado.shape[1]} columnas\")\n",
    "\n",
    "# Agregar informaci√≥n de por_sexo para a√±os 2015-2023\n",
    "print(\"\\nüîó Integrando informaci√≥n por sexo...\")\n",
    "dataset_unificado = dataset_unificado.merge(\n",
    "    por_sexo_estandarizado, \n",
    "    on='a√±o', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"üìä Despu√©s de integrar por_sexo: {dataset_unificado.shape[0]} registros, {dataset_unificado.shape[1]} columnas\")\n",
    "\n",
    "# Verificar integraci√≥n\n",
    "print(\"\\nüìã Columnas del dataset unificado:\")\n",
    "print(list(dataset_unificado.columns))\n",
    "\n",
    "# Mostrar a√±os con informaci√≥n completa vs parcial\n",
    "a√±os_completa = dataset_unificado[dataset_unificado['nacimientos_hombres'].notna()]['a√±o'].tolist()\n",
    "a√±os_parcial = dataset_unificado[dataset_unificado['nacimientos_hombres'].isna()]['a√±o'].tolist()\n",
    "\n",
    "print(f\"\\nüìÖ A√±os con informaci√≥n completa (2015-2023): {len(a√±os_completa)} a√±os\")\n",
    "print(f\"üìÖ A√±os con informaci√≥n parcial (1974-2014): {len(a√±os_parcial)} a√±os\")\n",
    "\n",
    "print(\"\\nPrimeras filas del dataset unificado:\")\n",
    "display(dataset_unificado.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9744cf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERACI√ìN DE VARIABLES DERIVADAS ===\n",
      "üìä Calculando variables derivadas...\n",
      "‚úÖ Variables derivadas creadas:\n",
      "  - tasa_natalidad\n",
      "  - tasa_mortalidad\n",
      "  - ratio_nacimientos_sexo\n",
      "  - ratio_defunciones_sexo\n",
      "  - crecimiento_natural\n",
      "  - porcentaje_crecimiento_natural\n",
      "  - dif_nacimientos_a√±o_anterior\n",
      "  - dif_defunciones_a√±o_anterior\n",
      "  - pct_cambio_nacimientos\n",
      "  - pct_cambio_defunciones\n",
      "\n",
      "üìä Dataset unificado final: 50 registros, 17 columnas\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Generar variables derivadas - Tasas y ratios\n",
    "\n",
    "print(\"=== GENERACI√ìN DE VARIABLES DERIVADAS ===\")\n",
    "\n",
    "# Crear variables derivadas √∫tiles para an√°lisis\n",
    "print(\"üìä Calculando variables derivadas...\")\n",
    "\n",
    "# 1. Tasas de natalidad y mortalidad (por cada 1000 habitantes)\n",
    "# Nota: Para c√°lculos precisos necesitar√≠amos poblaci√≥n, pero podemos usar aproximaciones\n",
    "dataset_unificado['tasa_natalidad'] = (dataset_unificado['nacimientos_totales'] / 1000).round(2)\n",
    "dataset_unificado['tasa_mortalidad'] = (dataset_unificado['defunciones_totales'] / 1000).round(2)\n",
    "\n",
    "# 2. Ratio de nacimientos por sexo (hombres/mujeres)\n",
    "dataset_unificado['ratio_nacimientos_sexo'] = (\n",
    "    dataset_unificado['nacimientos_hombres'] / dataset_unificado['nacimientos_mujeres']\n",
    ").round(3)\n",
    "\n",
    "# 3. Ratio de defunciones por sexo (hombres/mujeres)\n",
    "dataset_unificado['ratio_defunciones_sexo'] = (\n",
    "    dataset_unificado['defunciones_hombres'] / dataset_unificado['defunciones_mujeres']\n",
    ").round(3)\n",
    "\n",
    "# 4. Crecimiento natural (nacimientos - defunciones)\n",
    "dataset_unificado['crecimiento_natural'] = (\n",
    "    dataset_unificado['nacimientos_totales'] - dataset_unificado['defunciones_totales']\n",
    ")\n",
    "\n",
    "# 5. Porcentaje de crecimiento natural\n",
    "dataset_unificado['porcentaje_crecimiento_natural'] = (\n",
    "    (dataset_unificado['crecimiento_natural'] / dataset_unificado['nacimientos_totales']) * 100\n",
    ").round(2)\n",
    "\n",
    "# 6. Diferencia a√±o a a√±o en nacimientos y defunciones\n",
    "dataset_unificado['dif_nacimientos_a√±o_anterior'] = dataset_unificado['nacimientos_totales'].diff()\n",
    "dataset_unificado['dif_defunciones_a√±o_anterior'] = dataset_unificado['defunciones_totales'].diff()\n",
    "\n",
    "# 7. Porcentaje de cambio a√±o a a√±o\n",
    "dataset_unificado['pct_cambio_nacimientos'] = (\n",
    "    (dataset_unificado['dif_nacimientos_a√±o_anterior'] / dataset_unificado['nacimientos_totales'].shift(1)) * 100\n",
    ").round(2)\n",
    "\n",
    "dataset_unificado['pct_cambio_defunciones'] = (\n",
    "    (dataset_unificado['dif_defunciones_a√±o_anterior'] / dataset_unificado['defunciones_totales'].shift(1)) * 100\n",
    ").round(2)\n",
    "\n",
    "print(\"‚úÖ Variables derivadas creadas:\")\n",
    "variables_derivadas = [\n",
    "    'tasa_natalidad', 'tasa_mortalidad', 'ratio_nacimientos_sexo', 'ratio_defunciones_sexo',\n",
    "    'crecimiento_natural', 'porcentaje_crecimiento_natural', 'dif_nacimientos_a√±o_anterior',\n",
    "    'dif_defunciones_a√±o_anterior', 'pct_cambio_nacimientos', 'pct_cambio_defunciones'\n",
    "]\n",
    "\n",
    "for var in variables_derivadas:\n",
    "    print(f\"  - {var}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset unificado final: {dataset_unificado.shape[0]} registros, {dataset_unificado.shape[1]} columnas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ad7082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTEGRACI√ìN DE INFORMACI√ìN POR RANGOS DE EDAD ===\n",
      "ÔøΩÔøΩ A√±os comunes para integraci√≥n por edad: [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "ÔøΩÔøΩ Total a√±os comunes: 14\n",
      "\n",
      "ÔøΩÔøΩ Usando rangos detallados de defunciones_estandarizado...\n",
      "‚úÖ Dataset defunciones con rangos detallados: (11, 23)\n",
      "üìã Rangos disponibles: ['defunciones_100_mas', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_1_4', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_54', 'defunciones_55_59', 'defunciones_5_9', 'defunciones_60_64', 'defunciones_65_69', 'defunciones_70_74', 'defunciones_75_79', 'defunciones_80_84', 'defunciones_85_89', 'defunciones_90_94', 'defunciones_95_99', 'defunciones_menores_1']\n",
      "\n",
      "‚úÖ Dataset extendido con rangos detallados: (10, 32)\n",
      "üìÖ A√±os incluidos: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "\n",
      "üìã Columnas del dataset extendido:\n",
      "   1. nacimientos_menores_15\n",
      "   2. nacimientos_15_19\n",
      "   3. nacimientos_20_24\n",
      "   4. nacimientos_25_29\n",
      "   5. nacimientos_30_34\n",
      "   6. nacimientos_35_39\n",
      "   7. nacimientos_40_44\n",
      "   8. nacimientos_45_49\n",
      "   9. nacimientos_50_mas\n",
      "  10. defunciones_100_mas\n",
      "  11. defunciones_10_14\n",
      "  12. defunciones_15_19\n",
      "  13. defunciones_1_4\n",
      "  14. defunciones_20_24\n",
      "  15. defunciones_25_29\n",
      "  16. defunciones_30_34\n",
      "  17. defunciones_35_39\n",
      "  18. defunciones_40_44\n",
      "  19. defunciones_45_49\n",
      "  20. defunciones_50_54\n",
      "  21. defunciones_55_59\n",
      "  22. defunciones_5_9\n",
      "  23. defunciones_60_64\n",
      "  24. defunciones_65_69\n",
      "  25. defunciones_70_74\n",
      "  26. defunciones_75_79\n",
      "  27. defunciones_80_84\n",
      "  28. defunciones_85_89\n",
      "  29. defunciones_90_94\n",
      "  30. defunciones_95_99\n",
      "  31. defunciones_menores_1\n",
      "\n",
      "‚úÖ Integraci√≥n por rangos de edad detallados completada\n"
     ]
    }
   ],
   "source": [
    "# 6.4 Integrar informaci√≥n por rangos de edad (CORREGIDO)\n",
    "\n",
    "print(\"=== INTEGRACI√ìN DE INFORMACI√ìN POR RANGOS DE EDAD ===\")\n",
    "\n",
    "# Verificar a√±os comunes entre datasets de edad\n",
    "a√±os_nacimientos_edad = set(nacimientos_edad_final['a√±o'])\n",
    "a√±os_defunciones_edad = set(defunciones_edad_final['a√±o'])\n",
    "a√±os_comunes_edad = a√±os_nacimientos_edad & a√±os_defunciones_edad\n",
    "\n",
    "print(f\"ÔøΩÔøΩ A√±os comunes para integraci√≥n por edad: {sorted(a√±os_comunes_edad)}\")\n",
    "print(f\"ÔøΩÔøΩ Total a√±os comunes: {len(a√±os_comunes_edad)}\")\n",
    "\n",
    "# IMPORTANTE: Usar los rangos detallados de defunciones_estandarizado\n",
    "print(f\"\\nÔøΩÔøΩ Usando rangos detallados de defunciones_estandarizado...\")\n",
    "\n",
    "# Crear dataset de defunciones por edad con rangos detallados\n",
    "defunciones_edad_detalladas = defunciones_estandarizado.groupby('a√±o')['rango_edad'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Renombrar columnas para consistencia\n",
    "defunciones_edad_detalladas.columns = [f'defunciones_{col}' for col in defunciones_edad_detalladas.columns]\n",
    "\n",
    "# Resetear √≠ndice para tener 'a√±o' como columna\n",
    "defunciones_edad_detalladas = defunciones_edad_detalladas.reset_index()\n",
    "\n",
    "print(f\"‚úÖ Dataset defunciones con rangos detallados: {defunciones_edad_detalladas.shape}\")\n",
    "print(f\"üìã Rangos disponibles: {list(defunciones_edad_detalladas.columns[1:])}\")\n",
    "\n",
    "# Filtrar por a√±os comunes\n",
    "defunciones_edad_detalladas = defunciones_edad_detalladas[defunciones_edad_detalladas['a√±o'].isin(a√±os_comunes_edad)]\n",
    "\n",
    "# Integrar datasets\n",
    "dataset_extendido = nacimientos_edad_final.merge(\n",
    "    defunciones_edad_detalladas, \n",
    "    on='a√±o', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset extendido con rangos detallados: {dataset_extendido.shape}\")\n",
    "print(f\"üìÖ A√±os incluidos: {sorted(dataset_extendido['a√±o'].tolist())}\")\n",
    "\n",
    "# Mostrar columnas del dataset extendido\n",
    "print(f\"\\nüìã Columnas del dataset extendido:\")\n",
    "columnas_edad = [col for col in dataset_extendido.columns if 'edad' in col.lower() or 'nacimientos_' in col or 'defunciones_' in col]\n",
    "for i, col in enumerate(columnas_edad, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Integraci√≥n por rangos de edad detallados completada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b26ada8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VARIABLES DERIVADAS ADICIONALES POR EDAD ===\n",
      "üìä Calculando totales...\n",
      "‚úÖ Total nacimientos: 2,110,436\n",
      "‚úÖ Total defunciones: 1,151,279\n",
      "‚úÖ Concentraci√≥n defunciones 65+ a√±os calculada usando 8 rangos\n"
     ]
    }
   ],
   "source": [
    "# 6.5 Generar variables derivadas adicionales por edad (ACTUALIZADO)\n",
    "\n",
    "print(\"=== VARIABLES DERIVADAS ADICIONALES POR EDAD ===\")\n",
    "\n",
    "# Calcular totales de nacimientos y defunciones\n",
    "print(\"üìä Calculando totales...\")\n",
    "\n",
    "# Calcular total de nacimientos (suma de todos los rangos)\n",
    "columnas_nacimientos = [col for col in dataset_extendido.columns if col.startswith('nacimientos_')]\n",
    "dataset_extendido['total_nacimientos'] = dataset_extendido[columnas_nacimientos].sum(axis=1)\n",
    "\n",
    "# Calcular total de defunciones (suma de todos los rangos)\n",
    "columnas_defunciones = [col for col in dataset_extendido.columns if col.startswith('defunciones_')]\n",
    "dataset_extendido['total_defunciones'] = dataset_extendido[columnas_defunciones].sum(axis=1)\n",
    "\n",
    "print(f\"‚úÖ Total nacimientos: {dataset_extendido['total_nacimientos'].sum():,}\")\n",
    "print(f\"‚úÖ Total defunciones: {dataset_extendido['total_defunciones'].sum():,}\")\n",
    "\n",
    "# Calcular porcentajes y ratios (igual que antes)\n",
    "# ... resto del c√≥digo igual ...\n",
    "\n",
    "# Concentraci√≥n de defunciones en adultos mayores (65+ a√±os) - AHORA S√ç FUNCIONA\n",
    "columnas_65_mas = [col for col in columnas_defunciones if any(rango in col for rango in ['65_69', '70_74', '75_79', '80_84', '85_89', '90_94', '95_99', '100_mas'])]\n",
    "\n",
    "if columnas_65_mas:\n",
    "    dataset_extendido['concentracion_defunciones_65_mas'] = dataset_extendido[columnas_65_mas].sum(axis=1) / dataset_extendido['total_defunciones'] * 100\n",
    "    print(f\"‚úÖ Concentraci√≥n defunciones 65+ a√±os calculada usando {len(columnas_65_mas)} rangos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd82babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASETS INTEGRADOS ===\n",
      "‚úÖ Dataset unificado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_unificado_temporal.csv\n",
      "üìä Dimensiones: (50, 17)\n",
      "‚úÖ Dataset extendido guardado: C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_extendido_con_edad.csv\n",
      "üìä Dimensiones: (10, 35)\n",
      "\n",
      "‚úÖ Verificaci√≥n: Ambos archivos guardados correctamente\n",
      "\n",
      "üìã Muestra del dataset unificado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a√±o</th>\n",
       "      <th>nacimientos_totales</th>\n",
       "      <th>defunciones_totales</th>\n",
       "      <th>ratio_nacimientos_sexo</th>\n",
       "      <th>crecimiento_natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>171992</td>\n",
       "      <td>121270</td>\n",
       "      <td>1.041</td>\n",
       "      <td>50722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189310</td>\n",
       "      <td>136958</td>\n",
       "      <td>1.029</td>\n",
       "      <td>52352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>177255</td>\n",
       "      <td>137439</td>\n",
       "      <td>1.040</td>\n",
       "      <td>39816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>194952</td>\n",
       "      <td>125833</td>\n",
       "      <td>1.051</td>\n",
       "      <td>69119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>210188</td>\n",
       "      <td>109658</td>\n",
       "      <td>1.044</td>\n",
       "      <td>100530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a√±o  nacimientos_totales  defunciones_totales  ratio_nacimientos_sexo  \\\n",
       "0  2023               171992               121270                   1.041   \n",
       "1  2022               189310               136958                   1.029   \n",
       "2  2021               177255               137439                   1.040   \n",
       "3  2020               194952               125833                   1.051   \n",
       "4  2019               210188               109658                   1.044   \n",
       "\n",
       "   crecimiento_natural  \n",
       "0                50722  \n",
       "1                52352  \n",
       "2                39816  \n",
       "3                69119  \n",
       "4               100530  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Muestra del dataset extendido:\n",
      "Columnas disponibles en dataset extendido:\n",
      "['a√±o', 'nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34', 'nacimientos_35_39', 'nacimientos_40_44', 'nacimientos_45_49', 'nacimientos_50_mas', 'defunciones_100_mas', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_1_4', 'defunciones_20_24', 'defunciones_25_29', 'defunciones_30_34', 'defunciones_35_39', 'defunciones_40_44', 'defunciones_45_49', 'defunciones_50_54', 'defunciones_55_59', 'defunciones_5_9', 'defunciones_60_64', 'defunciones_65_69', 'defunciones_70_74', 'defunciones_75_79', 'defunciones_80_84', 'defunciones_85_89', 'defunciones_90_94', 'defunciones_95_99', 'defunciones_menores_1', 'total_nacimientos', 'total_defunciones', 'concentracion_defunciones_65_mas']\n",
      "\n",
      "Mostrando columnas disponibles: ['a√±o', 'total_nacimientos', 'total_defunciones', 'nacimientos_25_29']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a√±o</th>\n",
       "      <th>total_nacimientos</th>\n",
       "      <th>total_defunciones</th>\n",
       "      <th>nacimientos_25_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>171715</td>\n",
       "      <td>121646</td>\n",
       "      <td>45178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189023</td>\n",
       "      <td>136467</td>\n",
       "      <td>50637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>177067</td>\n",
       "      <td>137208</td>\n",
       "      <td>47769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a√±o  total_nacimientos  total_defunciones  nacimientos_25_29\n",
       "0  2023             171715             121646              45178\n",
       "1  2022             189023             136467              50637\n",
       "2  2021             177067             137208              47769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Estad√≠sticas de datasets guardados:\n",
      "  Dataset unificado: 5 filas, 17 columnas\n",
      "  Dataset extendido: 3 filas, 35 columnas\n",
      "  A√±os en dataset extendido: [2021, 2022, 2023]\n"
     ]
    }
   ],
   "source": [
    "# 6.6 Guardar datasets integrados\n",
    "\n",
    "print(\"=== GUARDANDO DATASETS INTEGRADOS ===\")\n",
    "\n",
    "# Guardar dataset unificado b√°sico\n",
    "ruta_unificado = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_unificado_temporal.csv\"\n",
    "dataset_unificado.to_csv(ruta_unificado, index=False)\n",
    "print(f\"‚úÖ Dataset unificado guardado: {ruta_unificado}\")\n",
    "print(f\"üìä Dimensiones: {dataset_unificado.shape}\")\n",
    "\n",
    "# Guardar dataset extendido con informaci√≥n por edad\n",
    "ruta_extendido = r\"C:\\ProyectoML2\\proyecto-ml\\data\\02_intermediate\\dataset_extendido_con_edad.csv\"\n",
    "dataset_extendido.to_csv(ruta_extendido, index=False)\n",
    "print(f\"‚úÖ Dataset extendido guardado: {ruta_extendido}\")\n",
    "print(f\"üìä Dimensiones: {dataset_extendido.shape}\")\n",
    "\n",
    "# Verificar archivos guardados\n",
    "if os.path.exists(ruta_unificado) and os.path.exists(ruta_extendido):\n",
    "    print(\"\\n‚úÖ Verificaci√≥n: Ambos archivos guardados correctamente\")\n",
    "    \n",
    "    # Mostrar muestra del dataset unificado\n",
    "    print(\"\\nüìã Muestra del dataset unificado:\")\n",
    "    muestra_unificado = pd.read_csv(ruta_unificado, nrows=5)\n",
    "    columnas_unificado = ['a√±o', 'nacimientos_totales', 'defunciones_totales', 'ratio_nacimientos_sexo', 'crecimiento_natural']\n",
    "    # Verificar que las columnas existen\n",
    "    columnas_disponibles_unificado = [col for col in columnas_unificado if col in muestra_unificado.columns]\n",
    "    if columnas_disponibles_unificado:\n",
    "        display(muestra_unificado[columnas_disponibles_unificado])\n",
    "    else:\n",
    "        print(\"Columnas disponibles:\", muestra_unificado.columns.tolist())\n",
    "    \n",
    "    # Mostrar muestra del dataset extendido\n",
    "    print(\"\\nüìã Muestra del dataset extendido:\")\n",
    "    muestra_extendido = pd.read_csv(ruta_extendido, nrows=3)\n",
    "    \n",
    "    # Mostrar todas las columnas disponibles primero\n",
    "    print(\"Columnas disponibles en dataset extendido:\")\n",
    "    print(muestra_extendido.columns.tolist())\n",
    "    \n",
    "    # Seleccionar columnas que existan para mostrar\n",
    "    columnas_candidatas = ['a√±o', 'total_nacimientos', 'total_defunciones', 'nacimientos_25_29', 'defunciones_50_mas', 'concentracion_nacimientos_25_34']\n",
    "    columnas_disponibles_extendido = [col for col in columnas_candidatas if col in muestra_extendido.columns]\n",
    "    \n",
    "    if columnas_disponibles_extendido:\n",
    "        print(f\"\\nMostrando columnas disponibles: {columnas_disponibles_extendido}\")\n",
    "        display(muestra_extendido[columnas_disponibles_extendido])\n",
    "    else:\n",
    "        # Mostrar primeras columnas disponibles\n",
    "        print(\"\\nMostrando primeras columnas disponibles:\")\n",
    "        display(muestra_extendido.iloc[:, :6])  # Primeras 6 columnas\n",
    "    \n",
    "    # Mostrar estad√≠sticas b√°sicas\n",
    "    print(f\"\\nüìä Estad√≠sticas de datasets guardados:\")\n",
    "    print(f\"  Dataset unificado: {muestra_unificado.shape[0]} filas, {muestra_unificado.shape[1]} columnas\")\n",
    "    print(f\"  Dataset extendido: {muestra_extendido.shape[0]} filas, {muestra_extendido.shape[1]} columnas\")\n",
    "    \n",
    "    # Mostrar a√±os incluidos\n",
    "    if 'a√±o' in muestra_extendido.columns:\n",
    "        print(f\"  A√±os en dataset extendido: {sorted(muestra_extendido['a√±o'].tolist())}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Error: No se pudieron guardar los archivos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18e84394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA INTEGRACI√ìN DE DATASETS ===\n",
      "üìã Datasets integrados creados:\n",
      "\n",
      "DATASET_UNIFICADO:\n",
      "   Dimensiones: (50, 17)\n",
      "   A√±os cubiertos: 1974 - 2023\n",
      "   Total a√±os: 50\n",
      "\n",
      "DATASET_EXTENDIDO:\n",
      "   Dimensiones: (10, 35)\n",
      "   A√±os cubiertos: 2014 - 2023\n",
      "   Total a√±os: 10\n",
      "\n",
      "üìä Variables derivadas creadas:\n",
      "  Variables temporales: 9\n",
      "  Variables por edad: 3\n",
      "  Total variables derivadas: 12\n",
      "\n",
      "üìã Rangos de edad implementados:\n",
      "  Rangos de nacimientos: 9\n",
      "  Rangos de defunciones: 22\n",
      "  Rangos de defunciones detallados: desde defunciones_100_mas hasta defunciones_menores_1\n",
      "\n",
      "üìã Ejemplos de rangos detallados:\n",
      "  Nacimientos: ['nacimientos_menores_15', 'nacimientos_15_19', 'nacimientos_20_24', 'nacimientos_25_29', 'nacimientos_30_34']...\n",
      "  Defunciones: ['defunciones_100_mas', 'defunciones_10_14', 'defunciones_15_19', 'defunciones_1_4', 'defunciones_20_24']...\n",
      "  Defunciones adultos mayores: ['defunciones_100_mas', 'defunciones_65_69', 'defunciones_70_74', 'defunciones_75_79', 'defunciones_80_84', 'defunciones_85_89', 'defunciones_90_94', 'defunciones_95_99']\n",
      "\n",
      "=== BENEFICIOS DE LA INTEGRACI√ìN ===\n",
      "‚úÖ Dataset unificado temporal (1974-2023)\n",
      "‚úÖ Dataset extendido con informaci√≥n por edad (a√±os limitados)\n",
      "‚úÖ Variables derivadas para an√°lisis demogr√°fico\n",
      "‚úÖ Tasas de natalidad y mortalidad calculadas\n",
      "‚úÖ Ratios por sexo y edad\n",
      "‚úÖ Indicadores de crecimiento natural\n",
      "‚úÖ Concentraci√≥n de eventos por edad\n",
      "‚úÖ Rangos de defunciones detallados (hasta 100+ a√±os)\n",
      "‚úÖ Totales calculados autom√°ticamente\n",
      "\n",
      "=== NOTAS IMPORTANTES ===\n",
      "üìù Dataset extendido tiene a√±os limitados debido a disponibilidad de datos por edad\n",
      "üìù Rangos de defunciones incluyen categor√≠as detalladas hasta 100+ a√±os\n",
      "üìù Variables de concentraci√≥n calculadas para an√°lisis demogr√°fico\n",
      "\n",
      "‚úÖ Integraci√≥n de datasets completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 6.7 Resumen de la integraci√≥n de datasets\n",
    "\n",
    "print(\"=== RESUMEN DE LA INTEGRACI√ìN DE DATASETS ===\")\n",
    "\n",
    "# Resumen de datasets creados\n",
    "datasets_integrados = {\n",
    "    \"dataset_unificado\": dataset_unificado,\n",
    "    \"dataset_extendido\": dataset_extendido\n",
    "}\n",
    "\n",
    "print(\"üìã Datasets integrados creados:\")\n",
    "for nombre_dataset, df in datasets_integrados.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    print(f\"   A√±os cubiertos: {df['a√±o'].min()} - {df['a√±o'].max()}\")\n",
    "    print(f\"   Total a√±os: {len(df['a√±o'].unique())}\")\n",
    "\n",
    "# Resumen de variables derivadas\n",
    "print(f\"\\nüìä Variables derivadas creadas:\")\n",
    "variables_temporales = [col for col in dataset_unificado.columns if col.startswith(('tasa_', 'ratio_', 'crecimiento_', 'dif_', 'pct_cambio_'))]\n",
    "variables_edad = [col for col in dataset_extendido.columns if col.startswith(('pct_', 'ratio_', 'concentracion_', 'total_'))]\n",
    "\n",
    "print(f\"  Variables temporales: {len(variables_temporales)}\")\n",
    "print(f\"  Variables por edad: {len(variables_edad)}\")\n",
    "print(f\"  Total variables derivadas: {len(variables_temporales) + len(variables_edad)}\")\n",
    "\n",
    "# Resumen de rangos de edad\n",
    "print(f\"\\nüìã Rangos de edad implementados:\")\n",
    "rangos_defunciones = [col for col in dataset_extendido.columns if col.startswith('defunciones_') and not col.startswith('defunciones_totales')]\n",
    "rangos_nacimientos = [col for col in dataset_extendido.columns if col.startswith('nacimientos_') and not col.startswith('nacimientos_totales')]\n",
    "\n",
    "print(f\"  Rangos de nacimientos: {len(rangos_nacimientos)}\")\n",
    "print(f\"  Rangos de defunciones: {len(rangos_defunciones)}\")\n",
    "print(f\"  Rangos de defunciones detallados: desde {rangos_defunciones[0]} hasta {rangos_defunciones[-1]}\")\n",
    "\n",
    "# Mostrar algunos rangos espec√≠ficos\n",
    "print(f\"\\nüìã Ejemplos de rangos detallados:\")\n",
    "print(f\"  Nacimientos: {rangos_nacimientos[:5]}...\")\n",
    "print(f\"  Defunciones: {rangos_defunciones[:5]}...\")\n",
    "\n",
    "# Calcular rangos de adultos mayores por separado\n",
    "rangos_adultos_mayores = []\n",
    "for r in rangos_defunciones:\n",
    "    if any(x in r for x in ['65_69', '70_74', '75_79', '80_84', '85_89', '90_94', '95_99', '100_mas']):\n",
    "        rangos_adultos_mayores.append(r)\n",
    "\n",
    "print(f\"  Defunciones adultos mayores: {rangos_adultos_mayores}\")\n",
    "\n",
    "print(f\"\\n=== BENEFICIOS DE LA INTEGRACI√ìN ===\")\n",
    "print(\"‚úÖ Dataset unificado temporal (1974-2023)\")\n",
    "print(\"‚úÖ Dataset extendido con informaci√≥n por edad (a√±os limitados)\")\n",
    "print(\"‚úÖ Variables derivadas para an√°lisis demogr√°fico\")\n",
    "print(\"‚úÖ Tasas de natalidad y mortalidad calculadas\")\n",
    "print(\"‚úÖ Ratios por sexo y edad\")\n",
    "print(\"‚úÖ Indicadores de crecimiento natural\")\n",
    "print(\"‚úÖ Concentraci√≥n de eventos por edad\")\n",
    "print(\"‚úÖ Rangos de defunciones detallados (hasta 100+ a√±os)\")\n",
    "print(\"‚úÖ Totales calculados autom√°ticamente\")\n",
    "\n",
    "print(f\"\\n=== NOTAS IMPORTANTES ===\")\n",
    "print(\"üìù Dataset extendido tiene a√±os limitados debido a disponibilidad de datos por edad\")\n",
    "print(\"üìù Rangos de defunciones incluyen categor√≠as detalladas hasta 100+ a√±os\")\n",
    "print(\"üìù Variables de concentraci√≥n calculadas para an√°lisis demogr√°fico\")\n",
    "\n",
    "print(f\"\\n‚úÖ Integraci√≥n de datasets completada exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cf87b",
   "metadata": {},
   "source": [
    "## 7. Validaci√≥n de Consistencia\n",
    "\n",
    "Esta secci√≥n se enfoca en verificar la consistencia entre datasets y detectar valores an√≥malos que puedan indicar errores de captura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1ecec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACI√ìN DE SUMA DE NACIMIENTOS POR SEXO ===\n",
      "üîç Verificando consistencia en nacimientos...\n",
      "üìä A√±os verificados: 9\n",
      "üìä Inconsistencias menores (<0.1%): 9\n",
      "ÔøΩÔøΩ Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      "‚úÖ Inconsistencias menores (aceptables):\n",
      "  A√±o 2023: Diferencia = 17.0 (0.010%)\n",
      "  A√±o 2022: Diferencia = 15.0 (0.008%)\n",
      "  A√±o 2021: Diferencia = 17.0 (0.010%)\n",
      "  A√±o 2020: Diferencia = 19.0 (0.010%)\n",
      "  A√±o 2019: Diferencia = 23.0 (0.011%)\n",
      "  A√±o 2018: Diferencia = 24.0 (0.011%)\n",
      "  A√±o 2017: Diferencia = 25.0 (0.011%)\n",
      "  A√±o 2016: Diferencia = 28.0 (0.012%)\n",
      "  A√±o 2015: Diferencia = 21.0 (0.009%)\n",
      "\n",
      "ÔøΩÔøΩ Ejemplo de verificaci√≥n (a√±o 2023):\n",
      "  Nacimientos hombres: 87,713.0\n",
      "  Nacimientos mujeres: 84,262.0\n",
      "  Suma por sexo: 171,975.0\n",
      "  Total registrado: 171,992.0\n",
      "  Diferencia: 17.0 (0.010%)\n",
      "\n",
      "üìù CONCLUSI√ìN:\n",
      "‚úÖ Todas las inconsistencias son menores y aceptables\n",
      "‚úÖ Los datos son consistentes para an√°lisis\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Verificar suma de nacimientos por sexo vs totales\n",
    "\n",
    "print(\"=== VERIFICACI√ìN DE SUMA DE NACIMIENTOS POR SEXO ===\")\n",
    "\n",
    "# Verificar que la suma de nacimientos por sexo coincida con los totales\n",
    "print(\"üîç Verificando consistencia en nacimientos...\")\n",
    "\n",
    "# Para a√±os con informaci√≥n completa (2015-2023)\n",
    "a√±os_completos = dataset_unificado[dataset_unificado['nacimientos_hombres'].notna()]['a√±o'].tolist()\n",
    "\n",
    "inconsistencias_nacimientos = []\n",
    "\n",
    "for a√±o in a√±os_completos:\n",
    "    fila = dataset_unificado[dataset_unificado['a√±o'] == a√±o].iloc[0]\n",
    "    \n",
    "    # Calcular suma por sexo\n",
    "    suma_por_sexo = fila['nacimientos_hombres'] + fila['nacimientos_mujeres']\n",
    "    total_registrado = fila['nacimientos_totales']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_sexo - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_nacimientos.append({\n",
    "        'a√±o': a√±o,\n",
    "        'suma_por_sexo': suma_por_sexo,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\"üìä A√±os verificados: {len(a√±os_completos)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_nacimientos if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_nacimientos if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\"üìä Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\"ÔøΩÔøΩ Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n‚úÖ Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n‚ö†Ô∏è Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificaci√≥n\n",
    "print(f\"\\nÔøΩÔøΩ Ejemplo de verificaci√≥n (a√±o 2023):\")\n",
    "ejemplo_2023 = dataset_unificado[dataset_unificado['a√±o'] == 2023].iloc[0]\n",
    "suma_ejemplo = ejemplo_2023['nacimientos_hombres'] + ejemplo_2023['nacimientos_mujeres']\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['nacimientos_totales'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['nacimientos_totales']) * 100\n",
    "\n",
    "print(f\"  Nacimientos hombres: {ejemplo_2023['nacimientos_hombres']:,}\")\n",
    "print(f\"  Nacimientos mujeres: {ejemplo_2023['nacimientos_mujeres']:,}\")\n",
    "print(f\"  Suma por sexo: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['nacimientos_totales']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Conclusi√≥n\n",
    "print(f\"\\nüìù CONCLUSI√ìN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\"‚úÖ Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\"‚úÖ Los datos son consistentes para an√°lisis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hay inconsistencias significativas que requieren revisi√≥n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20b06c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACI√ìN DE SUMA DE DEFUNCIONES POR SEXO ===\n",
      "üîç Verificando consistencia en defunciones...\n",
      "üìä A√±os verificados: 9\n",
      "üìä Inconsistencias menores (<0.1%): 9\n",
      "ÔøΩÔøΩ Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      "‚úÖ Inconsistencias menores (aceptables):\n",
      "  A√±o 2023: Diferencia = 11.0 (0.009%)\n",
      "  A√±o 2022: Diferencia = 7.0 (0.005%)\n",
      "  A√±o 2021: Diferencia = 12.0 (0.009%)\n",
      "  A√±o 2020: Diferencia = 13.0 (0.010%)\n",
      "  A√±o 2019: Diferencia = 16.0 (0.015%)\n",
      "  A√±o 2018: Diferencia = 19.0 (0.018%)\n",
      "  A√±o 2017: Diferencia = 22.0 (0.021%)\n",
      "  A√±o 2016: Diferencia = 26.0 (0.025%)\n",
      "  A√±o 2015: Diferencia = 19.0 (0.018%)\n",
      "\n",
      "ÔøΩÔøΩ Ejemplo de verificaci√≥n (a√±o 2023):\n",
      "  Defunciones hombres: 63,174.0\n",
      "  Defunciones mujeres: 58,085.0\n",
      "  Suma por sexo: 121,259.0\n",
      "  Total registrado: 121,270.0\n",
      "  Diferencia: 11.0 (0.009%)\n",
      "\n",
      "üìù CONCLUSI√ìN:\n",
      "‚úÖ Todas las inconsistencias son menores y aceptables\n",
      "‚úÖ Los datos de defunciones son consistentes para an√°lisis\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Verificar suma de defunciones por sexo vs totales\n",
    "\n",
    "print(\"=== VERIFICACI√ìN DE SUMA DE DEFUNCIONES POR SEXO ===\")\n",
    "\n",
    "# Verificar que la suma de defunciones por sexo coincida con los totales\n",
    "print(\"üîç Verificando consistencia en defunciones...\")\n",
    "\n",
    "inconsistencias_defunciones = []\n",
    "\n",
    "for a√±o in a√±os_completos:\n",
    "    fila = dataset_unificado[dataset_unificado['a√±o'] == a√±o].iloc[0]\n",
    "    \n",
    "    # Calcular suma por sexo\n",
    "    suma_por_sexo = fila['defunciones_hombres'] + fila['defunciones_mujeres']\n",
    "    total_registrado = fila['defunciones_totales']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_sexo - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_defunciones.append({\n",
    "        'a√±o': a√±o,\n",
    "        'suma_por_sexo': suma_por_sexo,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\"üìä A√±os verificados: {len(a√±os_completos)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_defunciones if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_defunciones if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\"üìä Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\"ÔøΩÔøΩ Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n‚úÖ Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n‚ö†Ô∏è Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificaci√≥n\n",
    "print(f\"\\nÔøΩÔøΩ Ejemplo de verificaci√≥n (a√±o 2023):\")\n",
    "ejemplo_2023 = dataset_unificado[dataset_unificado['a√±o'] == 2023].iloc[0]\n",
    "suma_ejemplo = ejemplo_2023['defunciones_hombres'] + ejemplo_2023['defunciones_mujeres']\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['defunciones_totales'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['defunciones_totales']) * 100\n",
    "\n",
    "print(f\"  Defunciones hombres: {ejemplo_2023['defunciones_hombres']:,}\")\n",
    "print(f\"  Defunciones mujeres: {ejemplo_2023['defunciones_mujeres']:,}\")\n",
    "print(f\"  Suma por sexo: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['defunciones_totales']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Conclusi√≥n\n",
    "print(f\"\\nüìù CONCLUSI√ìN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\"‚úÖ Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\"‚úÖ Los datos de defunciones son consistentes para an√°lisis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hay inconsistencias significativas que requieren revisi√≥n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e730337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACI√ìN DE SUMA DE NACIMIENTOS POR EDAD ===\n",
      "üîç Verificando consistencia en nacimientos por edad...\n",
      "ÔøΩÔøΩ A√±os disponibles para verificaci√≥n por edad: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "üìä A√±os verificados: 10\n",
      "üìä Inconsistencias menores (<0.1%): 10\n",
      " Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      "‚úÖ Inconsistencias menores (aceptables):\n",
      "  A√±o 2014: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2015: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2016: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2017: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2018: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2019: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2020: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2021: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2022: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2023: Diferencia = 0.0 (0.000%)\n",
      "\n",
      " Ejemplo de verificaci√≥n (a√±o 2023):\n",
      "  Suma por rangos de edad: 171,715.0\n",
      "  Total registrado: 171,715.0\n",
      "  Diferencia: 0.0 (0.000%)\n",
      "\n",
      "üìã Rangos de edad incluidos en verificaci√≥n:\n",
      "   1. nacimientos_menores_15\n",
      "   2. nacimientos_15_19\n",
      "   3. nacimientos_20_24\n",
      "   4. nacimientos_25_29\n",
      "   5. nacimientos_30_34\n",
      "   6. nacimientos_35_39\n",
      "   7. nacimientos_40_44\n",
      "   8. nacimientos_45_49\n",
      "   9. nacimientos_50_mas\n",
      "\n",
      "üìù CONCLUSI√ìN:\n",
      "‚úÖ Todas las inconsistencias son menores y aceptables\n",
      "‚úÖ Los datos de nacimientos por edad son consistentes para an√°lisis\n"
     ]
    }
   ],
   "source": [
    "# 7.3 Verificar suma de nacimientos por edad vs totales\n",
    "\n",
    "print(\"=== VERIFICACI√ìN DE SUMA DE NACIMIENTOS POR EDAD ===\")\n",
    "\n",
    "# Verificar que la suma de nacimientos por edad coincida con los totales\n",
    "print(\"üîç Verificando consistencia en nacimientos por edad...\")\n",
    "\n",
    "# Usar a√±os disponibles en dataset_extendido\n",
    "a√±os_edad = sorted(dataset_extendido['a√±o'].tolist())\n",
    "print(f\"ÔøΩÔøΩ A√±os disponibles para verificaci√≥n por edad: {a√±os_edad}\")\n",
    "\n",
    "inconsistencias_nacimientos_edad = []\n",
    "\n",
    "for a√±o in a√±os_edad:\n",
    "    fila = dataset_extendido[dataset_extendido['a√±o'] == a√±o].iloc[0]\n",
    "    \n",
    "    # Calcular suma por rangos de edad\n",
    "    columnas_nacimientos_edad = [col for col in fila.index if col.startswith('nacimientos_') and col != 'total_nacimientos']\n",
    "    suma_por_edad = fila[columnas_nacimientos_edad].sum()\n",
    "    total_registrado = fila['total_nacimientos']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_edad - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_nacimientos_edad.append({\n",
    "        'a√±o': a√±o,\n",
    "        'suma_por_edad': suma_por_edad,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\"üìä A√±os verificados: {len(a√±os_edad)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_nacimientos_edad if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_nacimientos_edad if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\"üìä Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\" Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n‚úÖ Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n‚ö†Ô∏è Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificaci√≥n\n",
    "print(f\"\\n Ejemplo de verificaci√≥n (a√±o 2023):\")\n",
    "ejemplo_2023 = dataset_extendido[dataset_extendido['a√±o'] == 2023].iloc[0]\n",
    "columnas_nacimientos_edad = [col for col in ejemplo_2023.index if col.startswith('nacimientos_') and col != 'total_nacimientos']\n",
    "suma_ejemplo = ejemplo_2023[columnas_nacimientos_edad].sum()\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['total_nacimientos'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['total_nacimientos']) * 100\n",
    "\n",
    "print(f\"  Suma por rangos de edad: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['total_nacimientos']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Mostrar rangos de edad incluidos\n",
    "print(f\"\\nüìã Rangos de edad incluidos en verificaci√≥n:\")\n",
    "for i, col in enumerate(columnas_nacimientos_edad, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Conclusi√≥n\n",
    "print(f\"\\nüìù CONCLUSI√ìN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\"‚úÖ Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\"‚úÖ Los datos de nacimientos por edad son consistentes para an√°lisis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hay inconsistencias significativas que requieren revisi√≥n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74457ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACI√ìN DE SUMA DE DEFUNCIONES POR EDAD ===\n",
      "üîç Verificando consistencia en defunciones por edad...\n",
      "ÔøΩÔøΩ A√±os disponibles para verificaci√≥n por edad: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "üìä A√±os verificados: 10\n",
      "üìä Inconsistencias menores (<0.1%): 10\n",
      "‚ö†Ô∏è Inconsistencias significativas (>0.1%): 0\n",
      "\n",
      "‚úÖ Inconsistencias menores (aceptables):\n",
      "  A√±o 2014: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2015: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2016: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2017: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2018: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2019: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2020: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2021: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2022: Diferencia = 0.0 (0.000%)\n",
      "  A√±o 2023: Diferencia = 0.0 (0.000%)\n",
      "\n",
      "ÔøΩÔøΩ Ejemplo de verificaci√≥n (a√±o 2023):\n",
      "  Suma por rangos de edad: 121,646.0\n",
      "  Total registrado: 121,646.0\n",
      "  Diferencia: 0.0 (0.000%)\n",
      "\n",
      "üìã Rangos de edad incluidos en verificaci√≥n:\n",
      "   1. defunciones_100_mas\n",
      "   2. defunciones_10_14\n",
      "   3. defunciones_15_19\n",
      "   4. defunciones_1_4\n",
      "   5. defunciones_20_24\n",
      "   6. defunciones_25_29\n",
      "   7. defunciones_30_34\n",
      "   8. defunciones_35_39\n",
      "   9. defunciones_40_44\n",
      "  10. defunciones_45_49\n",
      "  11. defunciones_50_54\n",
      "  12. defunciones_55_59\n",
      "  13. defunciones_5_9\n",
      "  14. defunciones_60_64\n",
      "  15. defunciones_65_69\n",
      "  16. defunciones_70_74\n",
      "  17. defunciones_75_79\n",
      "  18. defunciones_80_84\n",
      "  19. defunciones_85_89\n",
      "  20. defunciones_90_94\n",
      "  21. defunciones_95_99\n",
      "  22. defunciones_menores_1\n",
      "\n",
      "üìä Estad√≠sticas de rangos de defunciones:\n",
      "  Total rangos verificados: 22\n",
      "  Rango m√°s bajo: defunciones_100_mas\n",
      "  Rango m√°s alto: defunciones_menores_1\n",
      "\n",
      "üìù CONCLUSI√ìN:\n",
      "‚úÖ Todas las inconsistencias son menores y aceptables\n",
      "‚úÖ Los datos de defunciones por edad son consistentes para an√°lisis\n",
      "‚úÖ Los 22 rangos detallados funcionan correctamente\n"
     ]
    }
   ],
   "source": [
    "# 7.4 Verificar suma de defunciones por edad vs totales\n",
    "\n",
    "print(\"=== VERIFICACI√ìN DE SUMA DE DEFUNCIONES POR EDAD ===\")\n",
    "\n",
    "# Verificar que la suma de defunciones por edad coincida con los totales\n",
    "print(\"üîç Verificando consistencia en defunciones por edad...\")\n",
    "\n",
    "# Usar a√±os disponibles en dataset_extendido\n",
    "a√±os_edad = sorted(dataset_extendido['a√±o'].tolist())\n",
    "print(f\"ÔøΩÔøΩ A√±os disponibles para verificaci√≥n por edad: {a√±os_edad}\")\n",
    "\n",
    "inconsistencias_defunciones_edad = []\n",
    "\n",
    "for a√±o in a√±os_edad:\n",
    "    fila = dataset_extendido[dataset_extendido['a√±o'] == a√±o].iloc[0]\n",
    "    \n",
    "    # Calcular suma por rangos de edad\n",
    "    columnas_defunciones_edad = [col for col in fila.index if col.startswith('defunciones_') and col != 'total_defunciones']\n",
    "    suma_por_edad = fila[columnas_defunciones_edad].sum()\n",
    "    total_registrado = fila['total_defunciones']\n",
    "    \n",
    "    # Verificar diferencia\n",
    "    diferencia = abs(suma_por_edad - total_registrado)\n",
    "    porcentaje_diferencia = (diferencia / total_registrado) * 100\n",
    "    \n",
    "    inconsistencias_defunciones_edad.append({\n",
    "        'a√±o': a√±o,\n",
    "        'suma_por_edad': suma_por_edad,\n",
    "        'total_registrado': total_registrado,\n",
    "        'diferencia': diferencia,\n",
    "        'porcentaje': porcentaje_diferencia\n",
    "    })\n",
    "\n",
    "print(f\"üìä A√±os verificados: {len(a√±os_edad)}\")\n",
    "\n",
    "# Clasificar inconsistencias\n",
    "inconsistencias_significativas = [inc for inc in inconsistencias_defunciones_edad if inc['porcentaje'] > 0.1]\n",
    "inconsistencias_menores = [inc for inc in inconsistencias_defunciones_edad if inc['porcentaje'] <= 0.1]\n",
    "\n",
    "print(f\"üìä Inconsistencias menores (<0.1%): {len(inconsistencias_menores)}\")\n",
    "print(f\"‚ö†Ô∏è Inconsistencias significativas (>0.1%): {len(inconsistencias_significativas)}\")\n",
    "\n",
    "# Mostrar resumen de inconsistencias menores\n",
    "if inconsistencias_menores:\n",
    "    print(f\"\\n‚úÖ Inconsistencias menores (aceptables):\")\n",
    "    for inc in inconsistencias_menores:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar inconsistencias significativas si las hay\n",
    "if inconsistencias_significativas:\n",
    "    print(f\"\\n‚ö†Ô∏è Inconsistencias significativas (revisar):\")\n",
    "    for inc in inconsistencias_significativas:\n",
    "        print(f\"  A√±o {inc['a√±o']}: Diferencia = {inc['diferencia']:,} ({inc['porcentaje']:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplo de verificaci√≥n\n",
    "print(f\"\\nÔøΩÔøΩ Ejemplo de verificaci√≥n (a√±o 2023):\")\n",
    "ejemplo_2023 = dataset_extendido[dataset_extendido['a√±o'] == 2023].iloc[0]\n",
    "columnas_defunciones_edad = [col for col in ejemplo_2023.index if col.startswith('defunciones_') and col != 'total_defunciones']\n",
    "suma_ejemplo = ejemplo_2023[columnas_defunciones_edad].sum()\n",
    "diferencia_ejemplo = abs(suma_ejemplo - ejemplo_2023['total_defunciones'])\n",
    "porcentaje_ejemplo = (diferencia_ejemplo / ejemplo_2023['total_defunciones']) * 100\n",
    "\n",
    "print(f\"  Suma por rangos de edad: {suma_ejemplo:,}\")\n",
    "print(f\"  Total registrado: {ejemplo_2023['total_defunciones']:,}\")\n",
    "print(f\"  Diferencia: {diferencia_ejemplo:,} ({porcentaje_ejemplo:.3f}%)\")\n",
    "\n",
    "# Mostrar rangos de edad incluidos\n",
    "print(f\"\\nüìã Rangos de edad incluidos en verificaci√≥n:\")\n",
    "for i, col in enumerate(columnas_defunciones_edad, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Mostrar estad√≠sticas de rangos\n",
    "print(f\"\\nüìä Estad√≠sticas de rangos de defunciones:\")\n",
    "print(f\"  Total rangos verificados: {len(columnas_defunciones_edad)}\")\n",
    "print(f\"  Rango m√°s bajo: {min(columnas_defunciones_edad)}\")\n",
    "print(f\"  Rango m√°s alto: {max(columnas_defunciones_edad)}\")\n",
    "\n",
    "# Conclusi√≥n\n",
    "print(f\"\\nüìù CONCLUSI√ìN:\")\n",
    "if len(inconsistencias_significativas) == 0:\n",
    "    print(\"‚úÖ Todas las inconsistencias son menores y aceptables\")\n",
    "    print(\"‚úÖ Los datos de defunciones por edad son consistentes para an√°lisis\")\n",
    "    print(\"‚úÖ Los 22 rangos detallados funcionan correctamente\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hay inconsistencias significativas que requieren revisi√≥n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ae11c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETECCI√ìN DE OUTLIERS ===\n",
      "üîç Analizando outliers en variables principales...\n",
      "\n",
      "üìä Resumen de outliers detectados:\n",
      "\n",
      "NACIMIENTOS_TOTALES:\n",
      "  Outliers detectados: 3 (6.0%)\n",
      "  L√≠mites: [191990.8, 295932.8]\n",
      "  Valores outliers: [171992, 177255, 189310]\n",
      "\n",
      "DEFUNCIONES_TOTALES:\n",
      "  Outliers detectados: 2 (4.0%)\n",
      "  L√≠mites: [40617.5, 131139.5]\n",
      "  Valores outliers: [136958, 137439]\n",
      "\n",
      "NACIMIENTOS_HOMBRES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  L√≠mites: [70469.0, 138581.0]\n",
      "\n",
      "NACIMIENTOS_MUJERES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  L√≠mites: [70208.0, 131744.0]\n",
      "\n",
      "DEFUNCIONES_HOMBRES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  L√≠mites: [38253.0, 84973.0]\n",
      "\n",
      "DEFUNCIONES_MUJERES:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  L√≠mites: [38932.0, 70028.0]\n",
      "\n",
      "CRECIMIENTO_NATURAL:\n",
      "  Outliers detectados: 4 (8.0%)\n",
      "  L√≠mites: [89589.0, 236759.0]\n",
      "  Valores outliers: [39816, 50722, 52352, 69119]\n",
      "\n",
      "RATIO_NACIMIENTOS_SEXO:\n",
      "  Outliers detectados: 3 (33.3%)\n",
      "  L√≠mites: [1.0, 1.0]\n",
      "  Valores outliers: [1.029, 1.034, 1.051]\n",
      "\n",
      "RATIO_DEFUNCIONES_SEXO:\n",
      "  Outliers detectados: 0 (0.0%)\n",
      "  L√≠mites: [1.1, 1.2]\n",
      "\n",
      "PCT_CAMBIO_NACIMIENTOS:\n",
      "  Outliers detectados: 2 (4.1%)\n",
      "  L√≠mites: [-9.1, 9.8]\n",
      "  Valores outliers: [9.98, 10.07]\n",
      "\n",
      "PCT_CAMBIO_DEFUNCIONES:\n",
      "  Outliers detectados: 3 (6.1%)\n",
      "  L√≠mites: [-8.8, 7.0]\n",
      "  Valores outliers: [-12.85, 9.65, 12.94]\n",
      "\n",
      "üîç A√±os con valores at√≠picos:\n",
      "A√±os con outliers: [np.int64(1976), np.int64(2016), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "\n",
      "üìã A√±o 1976 - Valores at√≠picos:\n",
      "  pct_cambio_defunciones: 9.65 (OUTLIER)\n",
      "\n",
      "üìã A√±o 2016 - Valores at√≠picos:\n",
      "  ratio_nacimientos_sexo: 1.034 (OUTLIER)\n",
      "\n",
      "üìã A√±o 2019 - Valores at√≠picos:\n",
      "  pct_cambio_defunciones: -12.85 (OUTLIER)\n",
      "\n",
      "üìã A√±o 2020 - Valores at√≠picos:\n",
      "  crecimiento_natural: 69,119.0 (OUTLIER)\n",
      "  ratio_nacimientos_sexo: 1.051 (OUTLIER)\n",
      "  pct_cambio_nacimientos: 9.98 (OUTLIER)\n",
      "\n",
      "üìã A√±o 2021 - Valores at√≠picos:\n",
      "  nacimientos_totales: 177,255.0 (OUTLIER)\n",
      "  defunciones_totales: 137,439.0 (OUTLIER)\n",
      "  crecimiento_natural: 39,816.0 (OUTLIER)\n",
      "\n",
      "üìã A√±o 2022 - Valores at√≠picos:\n",
      "  nacimientos_totales: 189,310.0 (OUTLIER)\n",
      "  defunciones_totales: 136,958.0 (OUTLIER)\n",
      "  crecimiento_natural: 52,352.0 (OUTLIER)\n",
      "  ratio_nacimientos_sexo: 1.029 (OUTLIER)\n",
      "  pct_cambio_nacimientos: 10.07 (OUTLIER)\n",
      "  pct_cambio_defunciones: 12.94 (OUTLIER)\n",
      "\n",
      "üìã A√±o 2023 - Valores at√≠picos:\n",
      "  nacimientos_totales: 171,992.0 (OUTLIER)\n",
      "  crecimiento_natural: 50,722.0 (OUTLIER)\n",
      "\n",
      "üìä An√°lisis de patrones temporales:\n",
      "\n",
      "NACIMIENTOS_TOTALES:\n",
      "  A√±os con outliers: [np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "  ‚ö†Ô∏è Concentraci√≥n en pocos a√±os - revisar datos de esos per√≠odos\n",
      "\n",
      "DEFUNCIONES_TOTALES:\n",
      "  A√±os con outliers: [np.int64(2021), np.int64(2022)]\n",
      "  ‚ö†Ô∏è Concentraci√≥n en pocos a√±os - revisar datos de esos per√≠odos\n",
      "\n",
      "CRECIMIENTO_NATURAL:\n",
      "  A√±os con outliers: [np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n",
      "  ‚úÖ Outliers distribuidos en m√∫ltiples a√±os\n",
      "\n",
      "RATIO_NACIMIENTOS_SEXO:\n",
      "  A√±os con outliers: [np.int64(2016), np.int64(2020), np.int64(2022)]\n",
      "  ‚ö†Ô∏è Concentraci√≥n en pocos a√±os - revisar datos de esos per√≠odos\n",
      "\n",
      "PCT_CAMBIO_NACIMIENTOS:\n",
      "  A√±os con outliers: [np.int64(2020), np.int64(2022)]\n",
      "  ‚ö†Ô∏è Concentraci√≥n en pocos a√±os - revisar datos de esos per√≠odos\n",
      "\n",
      "PCT_CAMBIO_DEFUNCIONES:\n",
      "  A√±os con outliers: [np.int64(1976), np.int64(2019), np.int64(2022)]\n",
      "  ‚ö†Ô∏è Concentraci√≥n en pocos a√±os - revisar datos de esos per√≠odos\n"
     ]
    }
   ],
   "source": [
    "# 7.5 Detecci√≥n de outliers en variables num√©ricas\n",
    "\n",
    "print(\"=== DETECCI√ìN DE OUTLIERS ===\")\n",
    "\n",
    "# Funci√≥n para detectar outliers usando el m√©todo IQR\n",
    "def detectar_outliers_iqr(serie, nombre_variable):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el m√©todo del rango intercuart√≠lico (IQR)\n",
    "    \"\"\"\n",
    "    Q1 = serie.quantile(0.25)\n",
    "    Q3 = serie.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = serie[(serie < limite_inferior) | (serie > limite_superior)]\n",
    "    \n",
    "    return {\n",
    "        'variable': nombre_variable,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'limite_inferior': limite_inferior,\n",
    "        'limite_superior': limite_superior,\n",
    "        'outliers': outliers,\n",
    "        'cantidad_outliers': len(outliers),\n",
    "        'porcentaje_outliers': (len(outliers) / len(serie)) * 100\n",
    "    }\n",
    "\n",
    "# Variables num√©ricas principales para an√°lisis de outliers\n",
    "variables_analisis = [\n",
    "    'nacimientos_totales', 'defunciones_totales', 'nacimientos_hombres', 'nacimientos_mujeres',\n",
    "    'defunciones_hombres', 'defunciones_mujeres', 'crecimiento_natural', 'ratio_nacimientos_sexo',\n",
    "    'ratio_defunciones_sexo', 'pct_cambio_nacimientos', 'pct_cambio_defunciones'\n",
    "]\n",
    "\n",
    "print(\"üîç Analizando outliers en variables principales...\")\n",
    "\n",
    "resultados_outliers = []\n",
    "\n",
    "for var in variables_analisis:\n",
    "    if var in dataset_unificado.columns:\n",
    "        serie = dataset_unificado[var].dropna()\n",
    "        resultado = detectar_outliers_iqr(serie, var)\n",
    "        resultados_outliers.append(resultado)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\nüìä Resumen de outliers detectados:\")\n",
    "for resultado in resultados_outliers:\n",
    "    print(f\"\\n{resultado['variable'].upper()}:\")\n",
    "    print(f\"  Outliers detectados: {resultado['cantidad_outliers']} ({resultado['porcentaje_outliers']:.1f}%)\")\n",
    "    print(f\"  L√≠mites: [{resultado['limite_inferior']:.1f}, {resultado['limite_superior']:.1f}]\")\n",
    "    \n",
    "    if resultado['cantidad_outliers'] > 0:\n",
    "        print(f\"  Valores outliers: {sorted(resultado['outliers'].tolist())}\")\n",
    "\n",
    "# Identificar a√±os con m√∫ltiples outliers (CORREGIDO)\n",
    "print(f\"\\nüîç A√±os con valores at√≠picos:\")\n",
    "a√±os_outliers = set()\n",
    "\n",
    "for resultado in resultados_outliers:\n",
    "    if resultado['cantidad_outliers'] > 0:\n",
    "        # CORRECCI√ìN: Usar el √≠ndice correcto\n",
    "        for idx in resultado['outliers'].index:\n",
    "            a√±o_outlier = dataset_unificado.loc[idx, 'a√±o']\n",
    "            a√±os_outliers.add(a√±o_outlier)\n",
    "\n",
    "if a√±os_outliers:\n",
    "    print(f\"A√±os con outliers: {sorted(a√±os_outliers)}\")\n",
    "    \n",
    "    # Mostrar detalles de a√±os problem√°ticos (CORREGIDO)\n",
    "    for a√±o in sorted(a√±os_outliers):\n",
    "        print(f\"\\nüìã A√±o {a√±o} - Valores at√≠picos:\")\n",
    "        fila = dataset_unificado[dataset_unificado['a√±o'] == a√±o].iloc[0]\n",
    "        \n",
    "        for resultado in resultados_outliers:\n",
    "            if resultado['cantidad_outliers'] > 0:\n",
    "                # Verificar si este a√±o tiene outliers en esta variable\n",
    "                a√±o_idx = dataset_unificado[dataset_unificado['a√±o'] == a√±o].index[0]\n",
    "                if a√±o_idx in resultado['outliers'].index:\n",
    "                    valor = fila[resultado['variable']]\n",
    "                    print(f\"  {resultado['variable']}: {valor:,} (OUTLIER)\")\n",
    "else:\n",
    "    print(\"No se detectaron a√±os con m√∫ltiples outliers\")\n",
    "\n",
    "# An√°lisis adicional: identificar patrones temporales\n",
    "print(f\"\\nüìä An√°lisis de patrones temporales:\")\n",
    "for resultado in resultados_outliers:\n",
    "    if resultado['cantidad_outliers'] > 0:\n",
    "        print(f\"\\n{resultado['variable'].upper()}:\")\n",
    "        # Obtener a√±os de outliers\n",
    "        a√±os_outliers_var = [dataset_unificado.loc[idx, 'a√±o'] for idx in resultado['outliers'].index]\n",
    "        print(f\"  A√±os con outliers: {sorted(a√±os_outliers_var)}\")\n",
    "        \n",
    "        # Analizar si hay patrones (ej: concentraci√≥n en ciertos a√±os)\n",
    "        if len(set(a√±os_outliers_var)) <= 3:\n",
    "            print(f\"  ‚ö†Ô∏è Concentraci√≥n en pocos a√±os - revisar datos de esos per√≠odos\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Outliers distribuidos en m√∫ltiples a√±os\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcbcf6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACI√ìN DE VALORES L√ìGICOS Y RANGOS ===\n",
      "üîç Validando valores l√≥gicos...\n",
      "üìä Registros con nacimientos negativos: 0\n",
      "üìä Registros con defunciones negativas: 0\n",
      "ÔøΩÔøΩ Registros con ratio nacimientos extremo (<0.8 o >1.2): 0\n",
      "ÔøΩÔøΩ Registros con ratio defunciones extremo (<0.8 o >1.2): 0\n",
      "üìä Registros con cambio nacimientos >50%: 0\n",
      "üìä Registros con cambio defunciones >50%: 0\n",
      "\n",
      "üîç Verificando consistencia temporal...\n",
      "üìä A√±os con cambios grandes en nacimientos (>50,000): 0\n",
      "üìä A√±os con cambios grandes en defunciones (>50,000): 0\n",
      "\n",
      "üîç Verificando rangos de valores esperados...\n",
      "üìä A√±os con inconsistencias en nacimientos (>100 diferencia): 0\n",
      "ÔøΩÔøΩ A√±os con inconsistencias en defunciones (>100 diferencia): 0\n",
      "\n",
      "üìù RESUMEN DE VALIDACI√ìN:\n",
      "‚úÖ Nacimientos negativos: 0\n",
      "‚úÖ Defunciones negativas: 0\n",
      "‚úÖ Ratios extremos nacimientos: 0\n",
      "‚úÖ Ratios extremos defunciones: 0\n",
      "‚úÖ Cambios extremos nacimientos: 0\n",
      "‚úÖ Cambios extremos defunciones: 0\n",
      "‚úÖ Cambios grandes temporales: 0\n",
      "‚úÖ Inconsistencias internas: 0\n",
      "\n",
      "üéâ ¬°TODOS LOS VALORES SON L√ìGICOS Y CONSISTENTES!\n"
     ]
    }
   ],
   "source": [
    "# 7.6 Validaci√≥n de valores l√≥gicos y rangos\n",
    "\n",
    "print(\"=== VALIDACI√ìN DE VALORES L√ìGICOS Y RANGOS ===\")\n",
    "\n",
    "# Validar valores l√≥gicos en variables clave\n",
    "print(\"üîç Validando valores l√≥gicos...\")\n",
    "\n",
    "# 1. Verificar que nacimientos y defunciones sean positivos\n",
    "nacimientos_negativos = dataset_unificado[dataset_unificado['nacimientos_totales'] < 0]\n",
    "defunciones_negativas = dataset_unificado[dataset_unificado['defunciones_totales'] < 0]\n",
    "\n",
    "print(f\"üìä Registros con nacimientos negativos: {len(nacimientos_negativos)}\")\n",
    "print(f\"üìä Registros con defunciones negativas: {len(defunciones_negativas)}\")\n",
    "\n",
    "# 2. Verificar ratios de sexo (deben estar entre 0.8 y 1.2 aproximadamente)\n",
    "ratios_nacimientos_extremos = dataset_unificado[\n",
    "    (dataset_unificado['ratio_nacimientos_sexo'] < 0.8) | \n",
    "    (dataset_unificado['ratio_nacimientos_sexo'] > 1.2)\n",
    "]\n",
    "\n",
    "ratios_defunciones_extremos = dataset_unificado[\n",
    "    (dataset_unificado['ratio_defunciones_sexo'] < 0.8) | \n",
    "    (dataset_unificado['ratio_defunciones_sexo'] > 1.2)\n",
    "]\n",
    "\n",
    "print(f\"ÔøΩÔøΩ Registros con ratio nacimientos extremo (<0.8 o >1.2): {len(ratios_nacimientos_extremos)}\")\n",
    "print(f\"ÔøΩÔøΩ Registros con ratio defunciones extremo (<0.8 o >1.2): {len(ratios_defunciones_extremos)}\")\n",
    "\n",
    "# 3. Verificar cambios porcentuales extremos (>50% cambio a√±o a a√±o)\n",
    "# CORRECCI√ìN: Usar abs() correctamente\n",
    "cambios_nacimientos_extremos = dataset_unificado[\n",
    "    (dataset_unificado['pct_cambio_nacimientos'].abs() > 50)\n",
    "]\n",
    "\n",
    "cambios_defunciones_extremos = dataset_unificado[\n",
    "    (dataset_unificado['pct_cambio_defunciones'].abs() > 50)\n",
    "]\n",
    "\n",
    "print(f\"üìä Registros con cambio nacimientos >50%: {len(cambios_nacimientos_extremos)}\")\n",
    "print(f\"üìä Registros con cambio defunciones >50%: {len(cambios_defunciones_extremos)}\")\n",
    "\n",
    "# Mostrar ejemplos de valores problem√°ticos\n",
    "if len(ratios_nacimientos_extremos) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Ejemplos de ratios de nacimientos extremos:\")\n",
    "    display(ratios_nacimientos_extremos[['a√±o', 'nacimientos_hombres', 'nacimientos_mujeres', 'ratio_nacimientos_sexo']].head())\n",
    "\n",
    "if len(cambios_nacimientos_extremos) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Ejemplos de cambios extremos en nacimientos:\")\n",
    "    display(cambios_nacimientos_extremos[['a√±o', 'nacimientos_totales', 'dif_nacimientos_a√±o_anterior', 'pct_cambio_nacimientos']].head())\n",
    "\n",
    "# 4. Verificar consistencia temporal (no debe haber saltos imposibles)\n",
    "print(f\"\\nüîç Verificando consistencia temporal...\")\n",
    "\n",
    "# CORRECCI√ìN: Calcular diferencias a√±o a a√±o correctamente\n",
    "dataset_unificado['dif_nacimientos_abs'] = dataset_unificado['nacimientos_totales'].diff().abs()\n",
    "dataset_unificado['dif_defunciones_abs'] = dataset_unificado['defunciones_totales'].diff().abs()\n",
    "\n",
    "# Identificar cambios muy grandes (m√°s de 50,000 en un a√±o)\n",
    "cambios_grandes_nacimientos = dataset_unificado[dataset_unificado['dif_nacimientos_abs'] > 50000]\n",
    "cambios_grandes_defunciones = dataset_unificado[dataset_unificado['dif_defunciones_abs'] > 50000]\n",
    "\n",
    "print(f\"üìä A√±os con cambios grandes en nacimientos (>50,000): {len(cambios_grandes_nacimientos)}\")\n",
    "print(f\"üìä A√±os con cambios grandes en defunciones (>50,000): {len(cambios_grandes_defunciones)}\")\n",
    "\n",
    "if len(cambios_grandes_nacimientos) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è A√±os con cambios grandes en nacimientos:\")\n",
    "    display(cambios_grandes_nacimientos[['a√±o', 'nacimientos_totales', 'dif_nacimientos_a√±o_anterior', 'dif_nacimientos_abs']])\n",
    "\n",
    "if len(cambios_grandes_defunciones) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è A√±os con cambios grandes en defunciones:\")\n",
    "    display(cambios_grandes_defunciones[['a√±o', 'defunciones_totales', 'dif_defunciones_a√±o_anterior', 'dif_defunciones_abs']])\n",
    "\n",
    "# 5. Verificaci√≥n adicional: rangos de valores esperados\n",
    "print(f\"\\nüîç Verificando rangos de valores esperados...\")\n",
    "\n",
    "# Verificar que los totales sean consistentes con la suma por sexo\n",
    "dataset_unificado['suma_nacimientos_sexo'] = dataset_unificado['nacimientos_hombres'] + dataset_unificado['nacimientos_mujeres']\n",
    "dataset_unificado['suma_defunciones_sexo'] = dataset_unificado['defunciones_hombres'] + dataset_unificado['defunciones_mujeres']\n",
    "\n",
    "# Calcular diferencias\n",
    "dataset_unificado['diff_nacimientos'] = abs(dataset_unificado['nacimientos_totales'] - dataset_unificado['suma_nacimientos_sexo'])\n",
    "dataset_unificado['diff_defunciones'] = abs(dataset_unificado['defunciones_totales'] - dataset_unificado['suma_defunciones_sexo'])\n",
    "\n",
    "# Identificar inconsistencias significativas\n",
    "inconsistencias_nacimientos = dataset_unificado[dataset_unificado['diff_nacimientos'] > 100]\n",
    "inconsistencias_defunciones = dataset_unificado[dataset_unificado['diff_defunciones'] > 100]\n",
    "\n",
    "print(f\"üìä A√±os con inconsistencias en nacimientos (>100 diferencia): {len(inconsistencias_nacimientos)}\")\n",
    "print(f\"ÔøΩÔøΩ A√±os con inconsistencias en defunciones (>100 diferencia): {len(inconsistencias_defunciones)}\")\n",
    "\n",
    "if len(inconsistencias_nacimientos) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è A√±os con inconsistencias en nacimientos:\")\n",
    "    display(inconsistencias_nacimientos[['a√±o', 'nacimientos_totales', 'suma_nacimientos_sexo', 'diff_nacimientos']])\n",
    "\n",
    "if len(inconsistencias_defunciones) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è A√±os con inconsistencias en defunciones:\")\n",
    "    display(inconsistencias_defunciones[['a√±o', 'defunciones_totales', 'suma_defunciones_sexo', 'diff_defunciones']])\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\nüìù RESUMEN DE VALIDACI√ìN:\")\n",
    "print(f\"‚úÖ Nacimientos negativos: {len(nacimientos_negativos)}\")\n",
    "print(f\"‚úÖ Defunciones negativas: {len(defunciones_negativas)}\")\n",
    "print(f\"‚úÖ Ratios extremos nacimientos: {len(ratios_nacimientos_extremos)}\")\n",
    "print(f\"‚úÖ Ratios extremos defunciones: {len(ratios_defunciones_extremos)}\")\n",
    "print(f\"‚úÖ Cambios extremos nacimientos: {len(cambios_nacimientos_extremos)}\")\n",
    "print(f\"‚úÖ Cambios extremos defunciones: {len(cambios_defunciones_extremos)}\")\n",
    "print(f\"‚úÖ Cambios grandes temporales: {len(cambios_grandes_nacimientos) + len(cambios_grandes_defunciones)}\")\n",
    "print(f\"‚úÖ Inconsistencias internas: {len(inconsistencias_nacimientos) + len(inconsistencias_defunciones)}\")\n",
    "\n",
    "if (len(nacimientos_negativos) == 0 and len(defunciones_negativas) == 0 and \n",
    "    len(ratios_nacimientos_extremos) == 0 and len(ratios_defunciones_extremos) == 0 and\n",
    "    len(cambios_nacimientos_extremos) == 0 and len(cambios_defunciones_extremos) == 0 and\n",
    "    len(cambios_grandes_nacimientos) == 0 and len(cambios_grandes_defunciones) == 0 and\n",
    "    len(inconsistencias_nacimientos) == 0 and len(inconsistencias_defunciones) == 0):\n",
    "    print(f\"\\nüéâ ¬°TODOS LOS VALORES SON L√ìGICOS Y CONSISTENTES!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Se encontraron algunos valores que requieren revisi√≥n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "114b1dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DE LA VALIDACI√ìN DE CONSISTENCIA ===\n",
      "üìã Resumen de validaciones:\n",
      "\n",
      "VERIFICACIONES REALIZADAS:\n",
      "  ‚úÖ Suma de nacimientos por sexo vs totales\n",
      "  ‚úÖ Suma de defunciones por sexo vs totales\n",
      "  ‚úÖ Suma de nacimientos por edad vs totales\n",
      "  ‚úÖ Suma de defunciones por edad vs totales\n",
      "  ‚úÖ Detecci√≥n de outliers en variables num√©ricas\n",
      "  ‚úÖ Validaci√≥n de valores l√≥gicos y rangos\n",
      "  ‚úÖ Verificaci√≥n de consistencia temporal\n",
      "\n",
      "INCONSISTENCIAS ENCONTRADAS:\n",
      "  nacimientos_por_sexo: 0\n",
      "  defunciones_por_sexo: 0\n",
      "  nacimientos_por_edad: 10\n",
      "  defunciones_por_edad: 10\n",
      "\n",
      "OUTLIERS DETECTADOS:\n",
      "  total_variables_analizadas: 11\n",
      "  variables_con_outliers: 6\n",
      "  a√±os_con_outliers: 7\n",
      "\n",
      "VALORES PROBLEM√ÅTICOS:\n",
      "  nacimientos_negativos: 0\n",
      "  defunciones_negativas: 0\n",
      "  ratios_extremos_nacimientos: 0\n",
      "  ratios_extremos_defunciones: 0\n",
      "  cambios_extremos_nacimientos: 0\n",
      "  cambios_extremos_defunciones: 0\n",
      "\n",
      "üìä PUNTUACI√ìN DE CALIDAD DE DATOS:\n",
      "Verificaciones realizadas: 788\n",
      "Problemas encontrados: 20\n",
      "Puntuaci√≥n de calidad: 97.5%\n",
      "‚úÖ CALIDAD EXCELENTE: Los datos est√°n muy bien estructurados\n",
      "\n",
      "=== RESUMEN FINAL DE LA SECCI√ìN 7 ===\n",
      "‚úÖ Validaci√≥n de consistencia completada exitosamente\n",
      "‚úÖ Todos los datasets est√°n listos para modelado\n",
      "‚úÖ Calidad de datos verificada en m√∫ltiples dimensiones\n",
      "‚úÖ Base s√≥lida para an√°lisis y machine learning\n",
      "\n",
      "‚úÖ Validaci√≥n de consistencia completada\n"
     ]
    }
   ],
   "source": [
    "# 7.7 Resumen de la validaci√≥n de consistencia\n",
    "\n",
    "print(\"=== RESUMEN DE LA VALIDACI√ìN DE CONSISTENCIA ===\")\n",
    "\n",
    "# Verificar que las variables necesarias est√©n definidas\n",
    "try:\n",
    "    a√±os_con_edad = sorted(dataset_extendido['a√±o'].tolist())\n",
    "except:\n",
    "    a√±os_con_edad = []\n",
    "\n",
    "# Crear resumen de todas las validaciones realizadas\n",
    "resumen_validaciones = {\n",
    "    \"Verificaciones realizadas\": [\n",
    "        \"Suma de nacimientos por sexo vs totales\",\n",
    "        \"Suma de defunciones por sexo vs totales\", \n",
    "        \"Suma de nacimientos por edad vs totales\",\n",
    "        \"Suma de defunciones por edad vs totales\",\n",
    "        \"Detecci√≥n de outliers en variables num√©ricas\",\n",
    "        \"Validaci√≥n de valores l√≥gicos y rangos\",\n",
    "        \"Verificaci√≥n de consistencia temporal\"\n",
    "    ],\n",
    "    \"Inconsistencias encontradas\": {\n",
    "        \"nacimientos_por_sexo\": len(inconsistencias_nacimientos),\n",
    "        \"defunciones_por_sexo\": len(inconsistencias_defunciones),\n",
    "        \"nacimientos_por_edad\": len(inconsistencias_nacimientos_edad),\n",
    "        \"defunciones_por_edad\": len(inconsistencias_defunciones_edad)\n",
    "    },\n",
    "    \"Outliers detectados\": {\n",
    "        \"total_variables_analizadas\": len(resultados_outliers),\n",
    "        \"variables_con_outliers\": len([r for r in resultados_outliers if r['cantidad_outliers'] > 0]),\n",
    "        \"a√±os_con_outliers\": len(a√±os_outliers)\n",
    "    },\n",
    "    \"Valores problem√°ticos\": {\n",
    "        \"nacimientos_negativos\": len(nacimientos_negativos),\n",
    "        \"defunciones_negativas\": len(defunciones_negativas),\n",
    "        \"ratios_extremos_nacimientos\": len(ratios_nacimientos_extremos),\n",
    "        \"ratios_extremos_defunciones\": len(ratios_defunciones_extremos),\n",
    "        \"cambios_extremos_nacimientos\": len(cambios_nacimientos_extremos),\n",
    "        \"cambios_extremos_defunciones\": len(cambios_defunciones_extremos)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Resumen de validaciones:\")\n",
    "for categoria, items in resumen_validaciones.items():\n",
    "    print(f\"\\n{categoria.upper()}:\")\n",
    "    if isinstance(items, list):\n",
    "        for item in items:\n",
    "            print(f\"  ‚úÖ {item}\")\n",
    "    else:\n",
    "        for clave, valor in items.items():\n",
    "            print(f\"  {clave}: {valor}\")\n",
    "\n",
    "# Calcular puntuaci√≥n de calidad de datos (CORREGIDO)\n",
    "total_verificaciones = 0\n",
    "total_problemas = 0\n",
    "\n",
    "# Contar problemas encontrados\n",
    "total_problemas += len(inconsistencias_nacimientos)\n",
    "total_problemas += len(inconsistencias_defunciones)\n",
    "total_problemas += len(inconsistencias_nacimientos_edad)\n",
    "total_problemas += len(inconsistencias_defunciones_edad)\n",
    "total_problemas += len(nacimientos_negativos)\n",
    "total_problemas += len(defunciones_negativas)\n",
    "total_problemas += len(ratios_nacimientos_extremos)\n",
    "total_problemas += len(ratios_defunciones_extremos)\n",
    "\n",
    "# CORRECCI√ìN: Contar verificaciones realizadas correctamente\n",
    "total_verificaciones += len(a√±os_completos) * 2  # nacimientos y defunciones por sexo\n",
    "total_verificaciones += len(a√±os_con_edad) * 2  # nacimientos y defunciones por edad\n",
    "total_verificaciones += len(dataset_unificado) * 4  # valores negativos y ratios extremos\n",
    "\n",
    "# Agregar verificaciones de outliers\n",
    "total_verificaciones += len(resultados_outliers) * len(dataset_unificado)\n",
    "\n",
    "puntuacion_calidad = ((total_verificaciones - total_problemas) / total_verificaciones) * 100\n",
    "\n",
    "print(f\"\\nüìä PUNTUACI√ìN DE CALIDAD DE DATOS:\")\n",
    "print(f\"Verificaciones realizadas: {total_verificaciones:,}\")\n",
    "print(f\"Problemas encontrados: {total_problemas:,}\")\n",
    "print(f\"Puntuaci√≥n de calidad: {puntuacion_calidad:.1f}%\")\n",
    "\n",
    "if puntuacion_calidad >= 95:\n",
    "    print(\"‚úÖ CALIDAD EXCELENTE: Los datos est√°n muy bien estructurados\")\n",
    "elif puntuacion_calidad >= 90:\n",
    "    print(\"‚úÖ CALIDAD BUENA: Los datos tienen calidad aceptable\")\n",
    "elif puntuacion_calidad >= 80:\n",
    "    print(\"‚ö†Ô∏è CALIDAD REGULAR: Se recomienda revisar algunos valores\")\n",
    "else:\n",
    "    print(\"‚ùå CALIDAD BAJA: Se requiere limpieza adicional\")\n",
    "\n",
    "# Resumen final de la secci√≥n 7\n",
    "print(f\"\\n=== RESUMEN FINAL DE LA SECCI√ìN 7 ===\")\n",
    "print(f\"‚úÖ Validaci√≥n de consistencia completada exitosamente\")\n",
    "print(f\"‚úÖ Todos los datasets est√°n listos para modelado\")\n",
    "print(f\"‚úÖ Calidad de datos verificada en m√∫ltiples dimensiones\")\n",
    "print(f\"‚úÖ Base s√≥lida para an√°lisis y machine learning\")\n",
    "\n",
    "print(f\"\\n‚úÖ Validaci√≥n de consistencia completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc46836",
   "metadata": {},
   "source": [
    "## 8. Preparaci√≥n para Modelado\n",
    "\n",
    "Esta secci√≥n se enfoca en crear variables y features necesarios para modelos de Machine Learning, incluyendo codificaciones categ√≥ricas, features temporales y variables de tendencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88625159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACI√ìN DE VARIABLES CATEG√ìRICAS ===\n",
      "üìä Dataset base para modelado: (1246200, 17)\n",
      "\n",
      "üìã Columnas disponibles en dataset_modelado:\n",
      "['a√±o', 'fecha_defuncion', 'sexo', 'tipo_edad', 'edad_cantidad', 'codigo_comuna', 'comuna', 'region', 'codigo_diagnostico', 'descripcion_diagnostico', 'a√±o_fecha', 'mes', 'dia_semana', 'trimestre', 'dia_a√±o', 'grupo_edad', 'rango_edad']\n",
      "\n",
      "üî¢ Codificando regiones...\n",
      "Regiones codificadas: 17\n",
      "  0: De Ais√©n del Gral. C. Ib√°√±ez del Campo\n",
      "  1: De Antofagasta\n",
      "  2: De Arica y Parinacota\n",
      "  3: De Atacama\n",
      "  4: De Coquimbo\n",
      "  5: De La Araucan√≠a\n",
      "  6: De Los Lagos\n",
      "  7: De Los R√≠os\n",
      "  8: De Magallanes y de La Ant√°rtica Chilena\n",
      "  9: De Tarapac√°\n",
      "  10: De Valpara√≠so\n",
      "  11: De √ëuble\n",
      "  12: Del Biob√≠o\n",
      "  13: Del Libertador General Bernardo O'Higgins\n",
      "  14: Del Maule\n",
      "  15: Ignorada\n",
      "  16: Regi√≥n Metropolitana\n",
      "\n",
      "üî¢ Codificando sexo...\n",
      "Sexo codificado: {'Hombre': 1, 'Mujer': 0}\n",
      "\n",
      "üî¢ Codificando rangos de edad...\n",
      "Rangos de edad codificados: 22\n",
      "  0: 100_mas\n",
      "  1: 10_14\n",
      "  2: 15_19\n",
      "  3: 1_4\n",
      "  4: 20_24\n",
      "  5: 25_29\n",
      "  6: 30_34\n",
      "  7: 35_39\n",
      "  8: 40_44\n",
      "  9: 45_49\n",
      "  10: 50_54\n",
      "  11: 55_59\n",
      "  12: 5_9\n",
      "  13: 60_64\n",
      "  14: 65_69\n",
      "  15: 70_74\n",
      "  16: 75_79\n",
      "  17: 80_84\n",
      "  18: 85_89\n",
      "  19: 90_94\n",
      "  20: 95_99\n",
      "  21: menores_1\n",
      "\n",
      "üî¢ Codificando c√≥digos de diagn√≥stico...\n",
      "Columnas relacionadas con diagn√≥stico: ['codigo_diagnostico', 'descripcion_diagnostico']\n",
      "Usando columna: codigo_diagnostico\n",
      "Categor√≠as de diagn√≥stico codificadas: 18\n",
      "  0: afecciones_perinatales\n",
      "  1: causas_externas\n",
      "  2: complicaciones_embarazo\n",
      "  3: enfermedades_cardiovasculares\n",
      "  4: enfermedades_digestivas\n",
      "  5: enfermedades_endocrinas\n",
      "  6: enfermedades_genitourinarias\n",
      "  7: enfermedades_infecciosas\n",
      "  8: enfermedades_mentales\n",
      "  9: enfermedades_musculoesqueleticas\n",
      "  10: enfermedades_nerviosas\n",
      "  11: enfermedades_ojos_oidos\n",
      "  12: enfermedades_piel\n",
      "  13: enfermedades_respiratorias\n",
      "  14: malformaciones_congenitas\n",
      "  15: neoplasias\n",
      "  16: sintomas_signos_anormales\n",
      "  17: traumatismos_envenenamientos\n",
      "\n",
      "üìä Dataset con variables categ√≥ricas: (1246200, 22)\n",
      "ÔøΩÔøΩ Nuevas columnas creadas:\n",
      "  ‚úÖ sexo_codificado\n",
      "  ‚úÖ rango_edad_codificado\n",
      "  ‚úÖ categoria_diagnostico\n",
      "  ‚úÖ categoria_diagnostico_codificada\n",
      "\n",
      "üîç Verificaci√≥n de valores nulos:\n",
      "  ‚ö†Ô∏è sexo_codificado: 163 valores nulos\n",
      "  ‚úÖ rango_edad_codificado: Sin valores nulos\n",
      "  ‚úÖ categoria_diagnostico: Sin valores nulos\n",
      "  ‚úÖ categoria_diagnostico_codificada: Sin valores nulos\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Crear variables categ√≥ricas para el dataset de defunciones detalladas\n",
    "\n",
    "print(\"=== CREACI√ìN DE VARIABLES CATEG√ìRICAS ===\")\n",
    "\n",
    "# Crear dataset preparado para modelado basado en defunciones detalladas\n",
    "dataset_modelado = defunciones_estandarizado.copy()\n",
    "print(f\"üìä Dataset base para modelado: {dataset_modelado.shape}\")\n",
    "\n",
    "# Verificar columnas disponibles\n",
    "print(f\"\\nüìã Columnas disponibles en dataset_modelado:\")\n",
    "print(dataset_modelado.columns.tolist())\n",
    "\n",
    "# 1. Codificaci√≥n de regiones (Label Encoding)\n",
    "print(\"\\nüî¢ Codificando regiones...\")\n",
    "if 'region' in dataset_modelado.columns:\n",
    "    regiones_unicas = sorted(dataset_modelado['region'].unique())\n",
    "    mapeo_regiones = {region: i for i, region in enumerate(regiones_unicas)}\n",
    "    dataset_modelado['region_codificada'] = dataset_modelado['region'].map(mapeo_regiones)\n",
    "    \n",
    "    print(f\"Regiones codificadas: {len(regiones_unicas)}\")\n",
    "    for region, codigo in mapeo_regiones.items():\n",
    "        print(f\"  {codigo}: {region}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna 'region' no encontrada\")\n",
    "\n",
    "# 2. Codificaci√≥n de sexo (Binary Encoding)\n",
    "print(\"\\nüî¢ Codificando sexo...\")\n",
    "if 'sexo' in dataset_modelado.columns:\n",
    "    mapeo_sexo = {'Hombre': 1, 'Mujer': 0}\n",
    "    dataset_modelado['sexo_codificado'] = dataset_modelado['sexo'].map(mapeo_sexo)\n",
    "    print(f\"Sexo codificado: {mapeo_sexo}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna 'sexo' no encontrada\")\n",
    "\n",
    "# 3. Codificaci√≥n de rangos de edad (ya tenemos la columna 'rango_edad')\n",
    "print(\"\\nüî¢ Codificando rangos de edad...\")\n",
    "if 'rango_edad' in dataset_modelado.columns:\n",
    "    rangos_edad_unicos = sorted(dataset_modelado['rango_edad'].unique())\n",
    "    mapeo_rangos_edad = {rango: i for i, rango in enumerate(rangos_edad_unicos)}\n",
    "    dataset_modelado['rango_edad_codificado'] = dataset_modelado['rango_edad'].map(mapeo_rangos_edad)\n",
    "    \n",
    "    print(f\"Rangos de edad codificados: {len(rangos_edad_unicos)}\")\n",
    "    for rango, codigo in mapeo_rangos_edad.items():\n",
    "        print(f\"  {codigo}: {rango}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna 'rango_edad' no encontrada\")\n",
    "\n",
    "# 4. Codificaci√≥n de c√≥digos de diagn√≥stico (agrupar por categor√≠as principales)\n",
    "print(\"\\nüî¢ Codificando c√≥digos de diagn√≥stico...\")\n",
    "\n",
    "# Verificar si existe columna de diagn√≥stico\n",
    "columnas_diagnostico = [col for col in dataset_modelado.columns if 'diagnostico' in col.lower() or 'cie' in col.lower()]\n",
    "print(f\"Columnas relacionadas con diagn√≥stico: {columnas_diagnostico}\")\n",
    "\n",
    "if columnas_diagnostico:\n",
    "    columna_diagnostico = columnas_diagnostico[0]  # Usar la primera encontrada\n",
    "    print(f\"Usando columna: {columna_diagnostico}\")\n",
    "    \n",
    "    # Crear funci√≥n para categorizar c√≥digos CIE-10\n",
    "    def categorizar_diagnostico(codigo):\n",
    "        \"\"\"\n",
    "        Categoriza c√≥digos CIE-10 en grupos principales\n",
    "        \"\"\"\n",
    "        if pd.isna(codigo):\n",
    "            return 'desconocido'\n",
    "        \n",
    "        codigo_str = str(codigo)\n",
    "        \n",
    "        # Categor√≠as principales basadas en c√≥digos CIE-10\n",
    "        if codigo_str.startswith('A') or codigo_str.startswith('B'):\n",
    "            return 'enfermedades_infecciosas'\n",
    "        elif codigo_str.startswith('C') or codigo_str.startswith('D'):\n",
    "            return 'neoplasias'\n",
    "        elif codigo_str.startswith('E'):\n",
    "            return 'enfermedades_endocrinas'\n",
    "        elif codigo_str.startswith('F'):\n",
    "            return 'enfermedades_mentales'\n",
    "        elif codigo_str.startswith('G'):\n",
    "            return 'enfermedades_nerviosas'\n",
    "        elif codigo_str.startswith('H'):\n",
    "            return 'enfermedades_ojos_oidos'\n",
    "        elif codigo_str.startswith('I'):\n",
    "            return 'enfermedades_cardiovasculares'\n",
    "        elif codigo_str.startswith('J'):\n",
    "            return 'enfermedades_respiratorias'\n",
    "        elif codigo_str.startswith('K'):\n",
    "            return 'enfermedades_digestivas'\n",
    "        elif codigo_str.startswith('L'):\n",
    "            return 'enfermedades_piel'\n",
    "        elif codigo_str.startswith('M'):\n",
    "            return 'enfermedades_musculoesqueleticas'\n",
    "        elif codigo_str.startswith('N'):\n",
    "            return 'enfermedades_genitourinarias'\n",
    "        elif codigo_str.startswith('O'):\n",
    "            return 'complicaciones_embarazo'\n",
    "        elif codigo_str.startswith('P'):\n",
    "            return 'afecciones_perinatales'\n",
    "        elif codigo_str.startswith('Q'):\n",
    "            return 'malformaciones_congenitas'\n",
    "        elif codigo_str.startswith('R'):\n",
    "            return 'sintomas_signos_anormales'\n",
    "        elif codigo_str.startswith('S') or codigo_str.startswith('T'):\n",
    "            return 'traumatismos_envenenamientos'\n",
    "        elif codigo_str.startswith('U'):\n",
    "            return 'causas_externas'\n",
    "        elif codigo_str.startswith('V') or codigo_str.startswith('W') or codigo_str.startswith('X') or codigo_str.startswith('Y'):\n",
    "            return 'causas_externas_accidentes'\n",
    "        elif codigo_str.startswith('Z'):\n",
    "            return 'factores_influencia_salud'\n",
    "        else:\n",
    "            return 'otros'\n",
    "\n",
    "    # Aplicar categorizaci√≥n\n",
    "    dataset_modelado['categoria_diagnostico'] = dataset_modelado[columna_diagnostico].apply(categorizar_diagnostico)\n",
    "    \n",
    "    # Codificar categor√≠as de diagn√≥stico\n",
    "    categorias_diagnostico = sorted(dataset_modelado['categoria_diagnostico'].unique())\n",
    "    mapeo_categorias_diagnostico = {cat: i for i, cat in enumerate(categorias_diagnostico)}\n",
    "    dataset_modelado['categoria_diagnostico_codificada'] = dataset_modelado['categoria_diagnostico'].map(mapeo_categorias_diagnostico)\n",
    "    \n",
    "    print(f\"Categor√≠as de diagn√≥stico codificadas: {len(categorias_diagnostico)}\")\n",
    "    for categoria, codigo in mapeo_categorias_diagnostico.items():\n",
    "        print(f\"  {codigo}: {categoria}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron columnas de diagn√≥stico\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(f\"\\nüìä Dataset con variables categ√≥ricas: {dataset_modelado.shape}\")\n",
    "print(f\"ÔøΩÔøΩ Nuevas columnas creadas:\")\n",
    "nuevas_columnas = [col for col in dataset_modelado.columns if col.endswith('_codificado') or col.startswith('categoria_')]\n",
    "for col in nuevas_columnas:\n",
    "    print(f\"  ‚úÖ {col}\")\n",
    "\n",
    "# Verificar que no hay valores nulos en las nuevas columnas\n",
    "print(f\"\\nüîç Verificaci√≥n de valores nulos:\")\n",
    "for col in nuevas_columnas:\n",
    "    nulos = dataset_modelado[col].isnull().sum()\n",
    "    if nulos > 0:\n",
    "        print(f\"  ‚ö†Ô∏è {col}: {nulos} valores nulos\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ {col}: Sin valores nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93c933d7-7cee-4cfd-9592-e7dfb61cb5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset despu√©s de limpieza: (1246037, 22)\n"
     ]
    }
   ],
   "source": [
    "# Limpiar valores nulos en sexo_codificado\n",
    "dataset_modelado = dataset_modelado.dropna(subset=['sexo_codificado'])\n",
    "print(f\"üìä Dataset despu√©s de limpieza: {dataset_modelado.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2789bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERACI√ìN DE FEATURES TEMPORALES ===\n",
      "üìÖ Creando features temporales adicionales...\n",
      "\n",
      "üìã Columnas temporales disponibles:\n",
      "  ['mes', 'dia_semana', 'trimestre', 'dia_a√±o']\n",
      "\n",
      "ÔøΩÔøΩ Creando features c√≠clicos...\n",
      "‚úÖ Features c√≠clicos de mes creados\n",
      "‚úÖ Features c√≠clicos de d√≠a del a√±o creados\n",
      "‚úÖ Features c√≠clicos de trimestre creados\n",
      "\n",
      "üìÖ Codificando d√≠a de la semana...\n",
      "Valores √∫nicos en dia_semana: ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']\n",
      "‚úÖ D√≠a de la semana codificado: {'Friday': 0, 'Monday': 1, 'Saturday': 2, 'Sunday': 3, 'Thursday': 4, 'Tuesday': 5, 'Wednesday': 6}\n",
      "\n",
      "ÔøΩÔøΩ Creando features de d√≠as especiales...\n",
      "‚úÖ Feature 'es_fin_semana' creado\n",
      "‚úÖ Features 'es_invierno' y 'es_verano' creados\n",
      "‚úÖ Feature 'trimestre_fiscal' creado\n",
      "\n",
      "üìÖ Creando features de √©poca del a√±o...\n",
      "‚úÖ √âpoca del a√±o codificada\n",
      "\n",
      "üìä Dataset con features temporales: (1246037, 37)\n",
      " Nuevas columnas temporales creadas: 12\n",
      "  ‚úÖ sexo_codificado\n",
      "  ‚úÖ rango_edad_codificado\n",
      "  ‚úÖ mes_sin\n",
      "  ‚úÖ mes_cos\n",
      "  ‚úÖ dia_a√±o_sin\n",
      "  ‚úÖ dia_a√±o_cos\n",
      "  ‚úÖ trimestre_sin\n",
      "  ‚úÖ trimestre_cos\n",
      "  ‚úÖ dia_semana_codificado\n",
      "  ‚úÖ dia_semana_sin\n",
      "  ‚úÖ dia_semana_cos\n",
      "  ‚úÖ trimestre_fiscal\n",
      "\n",
      "‚úÖ Features temporales completados\n"
     ]
    }
   ],
   "source": [
    "# 8.2 Generar features temporales para an√°lisis estacional\n",
    "\n",
    "print(\"=== GENERACI√ìN DE FEATURES TEMPORALES ===\")\n",
    "\n",
    "# Ya tenemos algunas variables temporales b√°sicas, vamos a crear m√°s features √∫tiles\n",
    "print(\"üìÖ Creando features temporales adicionales...\")\n",
    "\n",
    "# Verificar columnas temporales disponibles\n",
    "print(f\"\\nüìã Columnas temporales disponibles:\")\n",
    "columnas_temporales = [col for col in dataset_modelado.columns if col in ['mes', 'dia_a√±o', 'trimestre', 'dia_semana']]\n",
    "print(f\"  {columnas_temporales}\")\n",
    "\n",
    "# 1. Features c√≠clicos para capturar estacionalidad\n",
    "print(\"\\nÔøΩÔøΩ Creando features c√≠clicos...\")\n",
    "\n",
    "if 'mes' in dataset_modelado.columns:\n",
    "    # Mes c√≠clico (sinusoidal y cosinusoidal)\n",
    "    dataset_modelado['mes_sin'] = np.sin(2 * np.pi * dataset_modelado['mes'] / 12)\n",
    "    dataset_modelado['mes_cos'] = np.cos(2 * np.pi * dataset_modelado['mes'] / 12)\n",
    "    print(\"‚úÖ Features c√≠clicos de mes creados\")\n",
    "\n",
    "if 'dia_a√±o' in dataset_modelado.columns:\n",
    "    # D√≠a del a√±o c√≠clico\n",
    "    dataset_modelado['dia_a√±o_sin'] = np.sin(2 * np.pi * dataset_modelado['dia_a√±o'] / 365.25)\n",
    "    dataset_modelado['dia_a√±o_cos'] = np.cos(2 * np.pi * dataset_modelado['dia_a√±o'] / 365.25)\n",
    "    print(\"‚úÖ Features c√≠clicos de d√≠a del a√±o creados\")\n",
    "\n",
    "if 'trimestre' in dataset_modelado.columns:\n",
    "    # Trimestre c√≠clico\n",
    "    dataset_modelado['trimestre_sin'] = np.sin(2 * np.pi * dataset_modelado['trimestre'] / 4)\n",
    "    dataset_modelado['trimestre_cos'] = np.cos(2 * np.pi * dataset_modelado['trimestre'] / 4)\n",
    "    print(\"‚úÖ Features c√≠clicos de trimestre creados\")\n",
    "\n",
    "# 2. Features de d√≠a de la semana (ya tenemos 'dia_semana', vamos a codificarlo)\n",
    "print(\"\\nüìÖ Codificando d√≠a de la semana...\")\n",
    "\n",
    "if 'dia_semana' in dataset_modelado.columns:\n",
    "    # Verificar valores √∫nicos en dia_semana\n",
    "    valores_dia_semana = sorted(dataset_modelado['dia_semana'].unique())\n",
    "    print(f\"Valores √∫nicos en dia_semana: {valores_dia_semana}\")\n",
    "    \n",
    "    # Crear mapeo din√°mico basado en valores reales\n",
    "    mapeo_dias_semana = {dia: i for i, dia in enumerate(valores_dia_semana)}\n",
    "    dataset_modelado['dia_semana_codificado'] = dataset_modelado['dia_semana'].map(mapeo_dias_semana)\n",
    "    \n",
    "    # Features c√≠clicos para d√≠a de la semana\n",
    "    dataset_modelado['dia_semana_sin'] = np.sin(2 * np.pi * dataset_modelado['dia_semana_codificado'] / 7)\n",
    "    dataset_modelado['dia_semana_cos'] = np.cos(2 * np.pi * dataset_modelado['dia_semana_codificado'] / 7)\n",
    "    \n",
    "    print(f\"‚úÖ D√≠a de la semana codificado: {mapeo_dias_semana}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna 'dia_semana' no encontrada\")\n",
    "\n",
    "# 3. Features de fin de semana y d√≠as especiales\n",
    "print(\"\\nÔøΩÔøΩ Creando features de d√≠as especiales...\")\n",
    "\n",
    "if 'dia_semana' in dataset_modelado.columns:\n",
    "    # Fin de semana (0 = d√≠a laboral, 1 = fin de semana)\n",
    "    # CORRECCI√ìN: Usar valores reales encontrados\n",
    "    fin_semana_valores = ['Saturday', 'Sunday', 'S√°bado', 'Domingo', 'saturday', 'sunday']\n",
    "    dataset_modelado['es_fin_semana'] = dataset_modelado['dia_semana'].isin(fin_semana_valores).astype(int)\n",
    "    print(\"‚úÖ Feature 'es_fin_semana' creado\")\n",
    "\n",
    "if 'mes' in dataset_modelado.columns:\n",
    "    # Meses de invierno/verano (para Chile: invierno = Jun-Aug, verano = Dec-Feb)\n",
    "    dataset_modelado['es_invierno'] = dataset_modelado['mes'].isin([6, 7, 8]).astype(int)\n",
    "    dataset_modelado['es_verano'] = dataset_modelado['mes'].isin([12, 1, 2]).astype(int)\n",
    "    print(\"‚úÖ Features 'es_invierno' y 'es_verano' creados\")\n",
    "    \n",
    "    # CORRECCI√ìN: Trimestre del a√±o fiscal (para an√°lisis de pol√≠ticas)\n",
    "    dataset_modelado['trimestre_fiscal'] = ((dataset_modelado['mes'] - 1) // 3) + 1\n",
    "    print(\"‚úÖ Feature 'trimestre_fiscal' creado\")\n",
    "\n",
    "# 4. Features de √©poca del a√±o\n",
    "print(\"\\nüìÖ Creando features de √©poca del a√±o...\")\n",
    "\n",
    "if 'mes' in dataset_modelado.columns:\n",
    "    def obtener_epoca_a√±o(mes):\n",
    "        \"\"\"\n",
    "        Determina la √©poca del a√±o basada en el mes\n",
    "        \"\"\"\n",
    "        if mes in [12, 1, 2]:\n",
    "            return 'verano'\n",
    "        elif mes in [3, 4, 5]:\n",
    "            return 'oto√±o'\n",
    "        elif mes in [6, 7, 8]:\n",
    "            return 'invierno'\n",
    "        else:  # 9, 10, 11\n",
    "            return 'primavera'\n",
    "\n",
    "    dataset_modelado['epoca_a√±o'] = dataset_modelado['mes'].apply(obtener_epoca_a√±o)\n",
    "    \n",
    "    # Codificar √©poca del a√±o\n",
    "    epocas_a√±o = ['primavera', 'verano', 'oto√±o', 'invierno']\n",
    "    mapeo_epocas = {epoca: i for i, epoca in enumerate(epocas_a√±o)}\n",
    "    dataset_modelado['epoca_a√±o_codificada'] = dataset_modelado['epoca_a√±o'].map(mapeo_epocas)\n",
    "    \n",
    "    print(\"‚úÖ √âpoca del a√±o codificada\")\n",
    "\n",
    "# Mostrar resumen de features creados\n",
    "print(f\"\\nüìä Dataset con features temporales: {dataset_modelado.shape}\")\n",
    "\n",
    "# Mostrar nuevas columnas creadas\n",
    "nuevas_columnas_temporales = [col for col in dataset_modelado.columns if col.endswith(('_sin', '_cos', '_codificado', 'es_', 'epoca_', 'trimestre_fiscal'))]\n",
    "print(f\" Nuevas columnas temporales creadas: {len(nuevas_columnas_temporales)}\")\n",
    "for col in nuevas_columnas_temporales:\n",
    "    print(f\"  ‚úÖ {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Features temporales completados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30d8dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACI√ìN DE VARIABLES DE TENDENCIA ===\n",
      "ÔøΩÔøΩ Dataset base para tendencias: (50, 23)\n",
      "\n",
      "üìà Calculando promedios m√≥viles...\n",
      "‚úÖ Promedios m√≥viles creados: MA3 y MA5 para nacimientos y defunciones\n",
      "\n",
      "üìà Calculando diferencias adicionales...\n",
      "‚úÖ Diferencias con promedios m√≥viles creadas\n",
      "\n",
      "üìà Calculando tasas de crecimiento...\n",
      "‚úÖ Tasas de crecimiento calculadas\n",
      "\n",
      "ÔøΩÔøΩ Calculando tendencias a largo plazo...\n",
      "‚úÖ Tendencias calculadas\n",
      "\n",
      "üìà Calculando volatilidad...\n",
      "‚úÖ Volatilidad calculada\n",
      "\n",
      "üìä Dataset con variables de tendencia: (50, 39)\n",
      "ÔøΩÔøΩ Nuevas columnas de tendencia creadas: 10\n",
      "  ‚úÖ nacimientos_ma3\n",
      "  ‚úÖ nacimientos_ma5\n",
      "  ‚úÖ defunciones_ma3\n",
      "  ‚úÖ defunciones_ma5\n",
      "  ‚úÖ dif_nacimientos_ma3\n",
      "  ‚úÖ dif_nacimientos_ma5\n",
      "  ‚úÖ dif_defunciones_ma3\n",
      "  ‚úÖ dif_defunciones_ma5\n",
      "  ‚úÖ pct_cambio_nacimientos_ma3\n",
      "  ‚úÖ pct_cambio_defunciones_ma3\n",
      "\n",
      "‚úÖ Variables de tendencia completadas\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Crear variables de tendencia para el dataset temporal unificado\n",
    "\n",
    "print(\"=== CREACI√ìN DE VARIABLES DE TENDENCIA ===\")\n",
    "\n",
    "# Crear dataset de tendencias basado en el dataset unificado temporal\n",
    "dataset_tendencias = dataset_unificado.copy()\n",
    "print(f\"ÔøΩÔøΩ Dataset base para tendencias: {dataset_tendencias.shape}\")\n",
    "\n",
    "# 1. Promedios m√≥viles\n",
    "print(\"\\nüìà Calculando promedios m√≥viles...\")\n",
    "\n",
    "# Promedio m√≥vil de 3 a√±os para nacimientos\n",
    "dataset_tendencias['nacimientos_ma3'] = dataset_tendencias['nacimientos_totales'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Promedio m√≥vil de 5 a√±os para nacimientos\n",
    "dataset_tendencias['nacimientos_ma5'] = dataset_tendencias['nacimientos_totales'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Promedio m√≥vil de 3 a√±os para defunciones\n",
    "dataset_tendencias['defunciones_ma3'] = dataset_tendencias['defunciones_totales'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Promedio m√≥vil de 5 a√±os para defunciones\n",
    "dataset_tendencias['defunciones_ma5'] = dataset_tendencias['defunciones_totales'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "print(\"‚úÖ Promedios m√≥viles creados: MA3 y MA5 para nacimientos y defunciones\")\n",
    "\n",
    "# 2. Diferencias a√±o a a√±o (ya las tenemos, pero vamos a crear m√°s)\n",
    "print(\"\\nüìà Calculando diferencias adicionales...\")\n",
    "\n",
    "# Diferencia con promedio m√≥vil\n",
    "dataset_tendencias['dif_nacimientos_ma3'] = dataset_tendencias['nacimientos_totales'] - dataset_tendencias['nacimientos_ma3']\n",
    "dataset_tendencias['dif_nacimientos_ma5'] = dataset_tendencias['nacimientos_totales'] - dataset_tendencias['nacimientos_ma5']\n",
    "dataset_tendencias['dif_defunciones_ma3'] = dataset_tendencias['defunciones_totales'] - dataset_tendencias['defunciones_ma3']\n",
    "dataset_tendencias['dif_defunciones_ma5'] = dataset_tendencias['defunciones_totales'] - dataset_tendencias['defunciones_ma5']\n",
    "\n",
    "print(\"‚úÖ Diferencias con promedios m√≥viles creadas\")\n",
    "\n",
    "# 3. Tasas de crecimiento\n",
    "print(\"\\nüìà Calculando tasas de crecimiento...\")\n",
    "\n",
    "# Tasa de crecimiento promedio m√≥vil (CORREGIDO: evitar divisi√≥n por cero)\n",
    "dataset_tendencias['pct_cambio_nacimientos_ma3'] = np.where(\n",
    "    dataset_tendencias['nacimientos_ma3'] != 0,\n",
    "    (dataset_tendencias['dif_nacimientos_ma3'] / dataset_tendencias['nacimientos_ma3']) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "dataset_tendencias['pct_cambio_defunciones_ma3'] = np.where(\n",
    "    dataset_tendencias['defunciones_ma3'] != 0,\n",
    "    (dataset_tendencias['dif_defunciones_ma3'] / dataset_tendencias['defunciones_ma3']) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tasas de crecimiento calculadas\")\n",
    "\n",
    "# 4. Variables de tendencia a largo plazo (SIMPLIFICADO)\n",
    "print(\"\\nÔøΩÔøΩ Calculando tendencias a largo plazo...\")\n",
    "\n",
    "# Tendencia simple (diferencia entre valores extremos de ventana)\n",
    "def calcular_tendencia_simple(serie, ventana=10):\n",
    "    \"\"\"\n",
    "    Calcula tendencia simple usando diferencia entre extremos\n",
    "    \"\"\"\n",
    "    tendencias = []\n",
    "    \n",
    "    for i in range(len(serie)):\n",
    "        inicio = max(0, i - ventana + 1)\n",
    "        fin = i + 1\n",
    "        \n",
    "        if fin - inicio >= 3:\n",
    "            valores_ventana = serie.iloc[inicio:fin]\n",
    "            if len(valores_ventana) > 1:\n",
    "                tendencia = valores_ventana.iloc[-1] - valores_ventana.iloc[0]\n",
    "            else:\n",
    "                tendencia = 0\n",
    "        else:\n",
    "            tendencia = 0\n",
    "            \n",
    "        tendencias.append(tendencia)\n",
    "    \n",
    "    return pd.Series(tendencias, index=serie.index)\n",
    "\n",
    "# Calcular tendencias simples\n",
    "dataset_tendencias['tendencia_nacimientos'] = calcular_tendencia_simple(dataset_tendencias['nacimientos_totales'])\n",
    "dataset_tendencias['tendencia_defunciones'] = calcular_tendencia_simple(dataset_tendencias['defunciones_totales'])\n",
    "\n",
    "print(\"‚úÖ Tendencias calculadas\")\n",
    "\n",
    "# 5. Variables de volatilidad\n",
    "print(\"\\nüìà Calculando volatilidad...\")\n",
    "\n",
    "# Volatilidad (desviaci√≥n est√°ndar m√≥vil)\n",
    "dataset_tendencias['volatilidad_nacimientos'] = dataset_tendencias['nacimientos_totales'].rolling(window=5, min_periods=1).std()\n",
    "dataset_tendencias['volatilidad_defunciones'] = dataset_tendencias['defunciones_totales'].rolling(window=5, min_periods=1).std()\n",
    "\n",
    "# Coeficiente de variaci√≥n (CORREGIDO: evitar divisi√≥n por cero)\n",
    "dataset_tendencias['cv_nacimientos'] = np.where(\n",
    "    dataset_tendencias['nacimientos_ma5'] != 0,\n",
    "    dataset_tendencias['volatilidad_nacimientos'] / dataset_tendencias['nacimientos_ma5'],\n",
    "    0\n",
    ")\n",
    "\n",
    "dataset_tendencias['cv_defunciones'] = np.where(\n",
    "    dataset_tendencias['defunciones_ma5'] != 0,\n",
    "    dataset_tendencias['volatilidad_defunciones'] / dataset_tendencias['defunciones_ma5'],\n",
    "    0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Volatilidad calculada\")\n",
    "\n",
    "# Mostrar resumen de variables creadas\n",
    "print(f\"\\nüìä Dataset con variables de tendencia: {dataset_tendencias.shape}\")\n",
    "\n",
    "# Mostrar nuevas columnas creadas\n",
    "nuevas_columnas_tendencia = [col for col in dataset_tendencias.columns if col.endswith(('_ma3', '_ma5', '_dif_', '_pct_', '_tendencia_', '_volatilidad_', '_cv_'))]\n",
    "print(f\"ÔøΩÔøΩ Nuevas columnas de tendencia creadas: {len(nuevas_columnas_tendencia)}\")\n",
    "for col in nuevas_columnas_tendencia:\n",
    "    print(f\"  ‚úÖ {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Variables de tendencia completadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07fa8255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACI√ìN DE DATASET FINAL PARA MODELADO ===\n",
      "ÔøΩÔøΩ Combinando datasets para modelado...\n",
      "üìä Dataset de defunciones detalladas: (1246037, 37)\n",
      "üìä Dataset final para modelado de defunciones: (1246037, 23)\n",
      "üìã Columnas seleccionadas: 23\n",
      "\n",
      "üîç Verificando valores nulos:\n",
      "‚úÖ No hay valores nulos en el dataset final\n",
      "\n",
      "üìã Tipos de datos:\n",
      "  int64: 9 columnas\n",
      "  float64: 9 columnas\n",
      "  int32: 4 columnas\n",
      "  datetime64[ns]: 1 columnas\n",
      "\n",
      "üìä Estad√≠sticas b√°sicas de variables num√©ricas:\n",
      "Variables num√©ricas: 22\n",
      "              a√±o  edad_cantidad  region_codificada  sexo_codificado  \\\n",
      "count  1246037.00     1246037.00         1246037.00       1246037.00   \n",
      "mean      2019.18          72.22              11.52             0.53   \n",
      "std          3.08          18.60               4.65             0.50   \n",
      "min       2014.00           0.00               0.00             0.00   \n",
      "25%       2017.00          63.00               9.00             0.00   \n",
      "50%       2019.00          76.00              12.00             1.00   \n",
      "75%       2022.00          86.00              16.00             1.00   \n",
      "max       2024.00         118.00              16.00             1.00   \n",
      "\n",
      "       rango_edad_codificado  categoria_diagnostico_codificada         mes  \\\n",
      "count             1246037.00                        1246037.00  1246037.00   \n",
      "mean                   14.71                              9.11        6.44   \n",
      "std                     4.11                              5.66        3.32   \n",
      "min                     0.00                              0.00        1.00   \n",
      "25%                    13.00                              3.00        4.00   \n",
      "50%                    16.00                             10.00        6.00   \n",
      "75%                    18.00                             15.00        9.00   \n",
      "max                    21.00                             17.00       12.00   \n",
      "\n",
      "        trimestre     dia_a√±o     mes_sin     mes_cos  dia_a√±o_sin  \\\n",
      "count  1246037.00  1246037.00  1246037.00  1246037.00   1246037.00   \n",
      "mean         2.48      180.54       -0.02       -0.07         0.01   \n",
      "std          1.08      101.34        0.70        0.71         0.70   \n",
      "min          1.00        1.00       -1.00       -1.00        -1.00   \n",
      "25%          2.00       96.00       -0.87       -0.87        -0.69   \n",
      "50%          2.00      181.00        0.00       -0.00         0.03   \n",
      "75%          3.00      263.00        0.50        0.50         0.69   \n",
      "max          4.00      366.00        1.00        1.00         1.00   \n",
      "\n",
      "       dia_a√±o_cos  trimestre_sin  trimestre_cos  dia_semana_sin  \\\n",
      "count   1246037.00     1246037.00     1246037.00      1246037.00   \n",
      "mean         -0.07          -0.04          -0.05            0.00   \n",
      "std           0.71           0.71           0.70            0.71   \n",
      "min          -1.00          -1.00          -1.00           -0.97   \n",
      "25%          -0.79          -1.00          -1.00           -0.78   \n",
      "50%          -0.14           0.00          -0.00            0.00   \n",
      "75%           0.65           0.00           0.00            0.78   \n",
      "max           1.00           1.00           1.00            0.97   \n",
      "\n",
      "       dia_semana_cos  es_fin_semana  es_invierno   es_verano  \\\n",
      "count      1246037.00     1246037.00   1246037.00  1246037.00   \n",
      "mean            -0.00           0.29         0.29        0.23   \n",
      "std              0.71           0.45         0.45        0.42   \n",
      "min             -0.90           0.00         0.00        0.00   \n",
      "25%             -0.90           0.00         0.00        0.00   \n",
      "50%             -0.22           0.00         0.00        0.00   \n",
      "75%              0.62           1.00         1.00        0.00   \n",
      "max              1.00           1.00         1.00        1.00   \n",
      "\n",
      "       trimestre_fiscal  epoca_a√±o_codificada  \n",
      "count        1246037.00            1246037.00  \n",
      "mean               2.48                  1.60  \n",
      "std                1.08                  1.13  \n",
      "min                1.00                  0.00  \n",
      "25%                2.00                  1.00  \n",
      "50%                2.00                  2.00  \n",
      "75%                3.00                  3.00  \n",
      "max                4.00                  3.00  \n",
      "\n",
      "ÔøΩÔøΩ GUARDANDO DATASET FINAL PARA MODELADO...\n",
      "‚úÖ Dataset final guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_final_modelado_defunciones.csv\n",
      "üìä Dimensiones: (1246037, 23)\n",
      "‚úÖ Dataset de tendencias guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_temporales.csv\n",
      "üìä Dimensiones: (50, 39)\n",
      "‚úÖ Mapeos de codificaci√≥n guardados: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\mapeos_codificacion.json\n",
      "\n",
      "üìã RESUMEN FINAL:\n",
      "‚úÖ Dataset final para modelado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_final_modelado_defunciones.csv\n",
      "‚úÖ Dataset de tendencias: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_temporales.csv\n",
      "‚úÖ Mapeos de codificaci√≥n: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\mapeos_codificacion.json\n",
      "‚úÖ Todos los archivos guardados en: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\n",
      "\n",
      "üéØ PR√ìXIMOS PASOS RECOMENDADOS:\n",
      "  1. Usar dataset_final_modelado_defunciones.csv para modelos de clasificaci√≥n\n",
      "  2. Usar dataset_tendencias_temporales.csv para modelos de series temporales\n",
      "  3. Usar mapeos_codificacion.json para interpretar resultados\n"
     ]
    }
   ],
   "source": [
    "# 8.4 Crear dataset final para modelado con todas las features (CORREGIDO)\n",
    "\n",
    "print(\"=== CREACI√ìN DE DATASET FINAL PARA MODELADO ===\")\n",
    "\n",
    "# Crear dataset final combinando todas las features creadas\n",
    "print(\"ÔøΩÔøΩ Combinando datasets para modelado...\")\n",
    "\n",
    "# Para el dataset de defunciones detalladas (dataset_modelado)\n",
    "print(f\"üìä Dataset de defunciones detalladas: {dataset_modelado.shape}\")\n",
    "\n",
    "# Seleccionar columnas relevantes para modelado\n",
    "columnas_modelado = [\n",
    "    # Variables b√°sicas\n",
    "    'a√±o', 'fecha_defuncion', 'edad_cantidad',\n",
    "    \n",
    "    # Variables categ√≥ricas codificadas\n",
    "    'region_codificada', 'sexo_codificado', 'rango_edad_codificado', 'categoria_diagnostico_codificada',\n",
    "    \n",
    "    # Variables temporales b√°sicas\n",
    "    'mes', 'trimestre', 'dia_a√±o',\n",
    "    \n",
    "    # Features c√≠clicos\n",
    "    'mes_sin', 'mes_cos', 'dia_a√±o_sin', 'dia_a√±o_cos', 'trimestre_sin', 'trimestre_cos',\n",
    "    'dia_semana_sin', 'dia_semana_cos',\n",
    "    \n",
    "    # Features de d√≠as especiales\n",
    "    'es_fin_semana', 'es_invierno', 'es_verano', 'trimestre_fiscal', 'epoca_a√±o_codificada'\n",
    "]\n",
    "\n",
    "# Crear dataset final para modelado de defunciones\n",
    "dataset_final_modelado = dataset_modelado[columnas_modelado].copy()\n",
    "\n",
    "print(f\"üìä Dataset final para modelado de defunciones: {dataset_final_modelado.shape}\")\n",
    "print(f\"üìã Columnas seleccionadas: {len(columnas_modelado)}\")\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(f\"\\nüîç Verificando valores nulos:\")\n",
    "nulos_por_columna = dataset_final_modelado.isnull().sum()\n",
    "columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "if len(columnas_con_nulos) > 0:\n",
    "    print(\"Columnas con valores nulos:\")\n",
    "    for col, nulos in columnas_con_nulos.items():\n",
    "        print(f\"  {col}: {nulos} ({nulos/len(dataset_final_modelado)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚úÖ No hay valores nulos en el dataset final\")\n",
    "\n",
    "# Mostrar tipos de datos\n",
    "print(f\"\\nüìã Tipos de datos:\")\n",
    "tipos_datos = dataset_final_modelado.dtypes.value_counts()\n",
    "for tipo, cantidad in tipos_datos.items():\n",
    "    print(f\"  {tipo}: {cantidad} columnas\")\n",
    "\n",
    "# Mostrar estad√≠sticas b√°sicas de variables num√©ricas\n",
    "print(f\"\\nüìä Estad√≠sticas b√°sicas de variables num√©ricas:\")\n",
    "variables_numericas = dataset_final_modelado.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Variables num√©ricas: {len(variables_numericas)}\")\n",
    "print(dataset_final_modelado[variables_numericas].describe().round(2))\n",
    "\n",
    "# AGREGAR: Guardar dataset final para modelado\n",
    "print(f\"\\nÔøΩÔøΩ GUARDANDO DATASET FINAL PARA MODELADO...\")\n",
    "\n",
    "# CORRECCI√ìN: Usar la carpeta correcta (03_primary)\n",
    "import os\n",
    "carpeta_final = r\"C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\"\n",
    "if not os.path.exists(carpeta_final):\n",
    "    os.makedirs(carpeta_final)\n",
    "    print(f\"üìÅ Carpeta creada: {carpeta_final}\")\n",
    "\n",
    "# Guardar dataset final para modelado de defunciones\n",
    "ruta_dataset_final = os.path.join(carpeta_final, \"dataset_final_modelado_defunciones.csv\")\n",
    "dataset_final_modelado.to_csv(ruta_dataset_final, index=False)\n",
    "print(f\"‚úÖ Dataset final guardado: {ruta_dataset_final}\")\n",
    "print(f\"üìä Dimensiones: {dataset_final_modelado.shape}\")\n",
    "\n",
    "# AGREGAR: Tambi√©n guardar dataset de tendencias\n",
    "ruta_dataset_tendencias = os.path.join(carpeta_final, \"dataset_tendencias_temporales.csv\")\n",
    "dataset_tendencias.to_csv(ruta_dataset_tendencias, index=False)\n",
    "print(f\"‚úÖ Dataset de tendencias guardado: {ruta_dataset_tendencias}\")\n",
    "print(f\"üìä Dimensiones: {dataset_tendencias.shape}\")\n",
    "\n",
    "# AGREGAR: Guardar mapeos de codificaci√≥n\n",
    "import json\n",
    "mapeos_codificacion = {\n",
    "    \"regiones\": mapeo_regiones,\n",
    "    \"sexo\": mapeo_sexo,\n",
    "    \"rangos_edad\": mapeo_rangos_edad,\n",
    "    \"categorias_diagnostico\": mapeo_categorias_diagnostico,\n",
    "    \"dias_semana\": mapeo_dias_semana,\n",
    "    \"epocas_a√±o\": mapeo_epocas\n",
    "}\n",
    "\n",
    "ruta_mapeos = os.path.join(carpeta_final, \"mapeos_codificacion.json\")\n",
    "with open(ruta_mapeos, 'w', encoding='utf-8') as f:\n",
    "    json.dump(mapeos_codificacion, f, ensure_ascii=False, indent=2)\n",
    "print(f\"‚úÖ Mapeos de codificaci√≥n guardados: {ruta_mapeos}\")\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\nüìã RESUMEN FINAL:\")\n",
    "print(f\"‚úÖ Dataset final para modelado: {ruta_dataset_final}\")\n",
    "print(f\"‚úÖ Dataset de tendencias: {ruta_dataset_tendencias}\")\n",
    "print(f\"‚úÖ Mapeos de codificaci√≥n: {ruta_mapeos}\")\n",
    "print(f\"‚úÖ Todos los archivos guardados en: {carpeta_final}\")\n",
    "\n",
    "print(f\"\\nüéØ PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
    "print(f\"  1. Usar dataset_final_modelado_defunciones.csv para modelos de clasificaci√≥n\")\n",
    "print(f\"  2. Usar dataset_tendencias_temporales.csv para modelos de series temporales\")\n",
    "print(f\"  3. Usar mapeos_codificacion.json para interpretar resultados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4babecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN FINAL DE LA PREPARACI√ìN PARA MODELADO ===\n",
      "üìã Datasets creados para diferentes tipos de an√°lisis:\n",
      "\n",
      "DATASET_FINAL_MODELADO:\n",
      "   Dimensiones: (1246037, 23)\n",
      "   Per√≠odo temporal: 2014 - 2024\n",
      "   Columnas: 23\n",
      "\n",
      "DATASET_TENDENCIAS:\n",
      "   Dimensiones: (50, 39)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_MODELADO:\n",
      "   Dimensiones: (1246037, 37)\n",
      "   Per√≠odo temporal: 2014 - 2024\n",
      "   Columnas: 37\n",
      "\n",
      "DATASET_EXTENDIDO:\n",
      "   Dimensiones: (10, 35)\n",
      "   Per√≠odo temporal: 2014 - 2023\n",
      "   Columnas: 35\n",
      "\n",
      "DATASET_UNIFICADO:\n",
      "   Dimensiones: (50, 23)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 23\n",
      "\n",
      "=== FEATURES CREADAS PARA MODELADO ===\n",
      "ÔøΩÔøΩ Variables categ√≥ricas codificadas:\n",
      "  ‚úÖ region_codificada\n",
      "  ‚úÖ sexo_codificado\n",
      "  ‚úÖ rango_edad_codificado\n",
      "  ‚úÖ categoria_diagnostico_codificada\n",
      "  ‚úÖ epoca_a√±o_codificada\n",
      "\n",
      "üîÑ Features temporales c√≠clicos:\n",
      "  ‚úÖ mes_sin\n",
      "  ‚úÖ mes_cos\n",
      "  ‚úÖ dia_a√±o_sin\n",
      "  ‚úÖ dia_a√±o_cos\n",
      "  ‚úÖ trimestre_sin\n",
      "  ‚úÖ trimestre_cos\n",
      "  ‚úÖ dia_semana_sin\n",
      "  ‚úÖ dia_semana_cos\n",
      "\n",
      "ÔøΩÔøΩ Features de d√≠as especiales:\n",
      "  ‚úÖ es_fin_semana\n",
      "  ‚úÖ es_invierno\n",
      "  ‚úÖ es_verano\n",
      "  ‚úÖ trimestre_fiscal\n",
      "\n",
      "üìà Variables de tendencia:\n",
      "  ‚úÖ nacimientos_ma3\n",
      "  ‚úÖ nacimientos_ma5\n",
      "  ‚úÖ defunciones_ma3\n",
      "  ‚úÖ defunciones_ma5\n",
      "  ‚úÖ tendencia_nacimientos\n",
      "  ‚úÖ tendencia_defunciones\n",
      "  ‚úÖ volatilidad_nacimientos\n",
      "  ‚úÖ volatilidad_defunciones\n",
      "\n",
      "=== ARCHIVOS GENERADOS PARA MODELADO ===\n",
      "üìÅ data/03_primary/dataset_final_modelado_defunciones.csv\n",
      "üìÅ data/03_primary/dataset_tendencias_temporales.csv\n",
      "üìÅ data/03_primary/mapeos_codificacion.json\n",
      "\n",
      "=== CASOS DE USO PARA MODELADO ===\n",
      "üéØ Modelado de defunciones por regi√≥n y edad:\n",
      "   - Dataset: dataset_final_modelado_defunciones.csv\n",
      "   - Features: region, edad, sexo, √©poca del a√±o, d√≠a de la semana\n",
      "   - Objetivo: Predecir patrones de mortalidad\n",
      "\n",
      "üéØ An√°lisis de tendencias temporales:\n",
      "   - Dataset: dataset_tendencias_temporales.csv\n",
      "   - Features: promedios m√≥viles, tendencias lineales, volatilidad\n",
      "   - Objetivo: Predecir nacimientos/defunciones futuras\n",
      "\n",
      "üéØ An√°lisis estacional:\n",
      "   - Features: mes_sin/cos, d√≠a_semana_sin/cos, √©poca del a√±o\n",
      "   - Objetivo: Identificar patrones estacionales\n",
      "\n",
      "‚úÖ Preparaci√≥n para modelado completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 8.5 Resumen final de la preparaci√≥n para modelado (CORREGIDO)\n",
    "\n",
    "print(\"=== RESUMEN FINAL DE LA PREPARACI√ìN PARA MODELADO ===\")\n",
    "\n",
    "# Crear resumen de todos los datasets creados\n",
    "datasets_finales = {\n",
    "    \"dataset_final_modelado\": dataset_final_modelado,\n",
    "    \"dataset_tendencias\": dataset_tendencias,\n",
    "    \"dataset_modelado\": dataset_modelado,\n",
    "    \"dataset_extendido\": dataset_extendido,\n",
    "    \"dataset_unificado\": dataset_unificado\n",
    "}\n",
    "\n",
    "print(\"üìã Datasets creados para diferentes tipos de an√°lisis:\")\n",
    "for nombre_dataset, df in datasets_finales.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    print(f\"   Per√≠odo temporal: {df['a√±o'].min()} - {df['a√±o'].max()}\")\n",
    "    print(f\"   Columnas: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== FEATURES CREADAS PARA MODELADO ===\")\n",
    "\n",
    "# Variables categ√≥ricas codificadas\n",
    "print(\"ÔøΩÔøΩ Variables categ√≥ricas codificadas:\")\n",
    "categorias_creadas = [\n",
    "    \"region_codificada\", \"sexo_codificado\", \"rango_edad_codificado\", \n",
    "    \"categoria_diagnostico_codificada\", \"dia_semana_codificado\", \"epoca_a√±o_codificada\"\n",
    "]\n",
    "for cat in categorias_creadas:\n",
    "    if cat in dataset_final_modelado.columns:\n",
    "        print(f\"  ‚úÖ {cat}\")\n",
    "\n",
    "# Features temporales c√≠clicos\n",
    "print(\"\\nüîÑ Features temporales c√≠clicos:\")\n",
    "features_ciclicos = [\n",
    "    \"mes_sin\", \"mes_cos\", \"dia_a√±o_sin\", \"dia_a√±o_cos\", \n",
    "    \"trimestre_sin\", \"trimestre_cos\", \"dia_semana_sin\", \"dia_semana_cos\"\n",
    "]\n",
    "for feat in features_ciclicos:\n",
    "    if feat in dataset_final_modelado.columns:\n",
    "        print(f\"  ‚úÖ {feat}\")\n",
    "\n",
    "# Features de d√≠as especiales\n",
    "print(\"\\nÔøΩÔøΩ Features de d√≠as especiales:\")\n",
    "features_especiales = [\n",
    "    \"es_fin_semana\", \"es_invierno\", \"es_verano\", \"trimestre_fiscal\"\n",
    "]\n",
    "for feat in features_especiales:\n",
    "    if feat in dataset_final_modelado.columns:\n",
    "        print(f\"  ‚úÖ {feat}\")\n",
    "\n",
    "# Variables de tendencia\n",
    "print(\"\\nüìà Variables de tendencia:\")\n",
    "variables_tendencia = [\n",
    "    \"nacimientos_ma3\", \"nacimientos_ma5\", \"defunciones_ma3\", \"defunciones_ma5\",\n",
    "    \"tendencia_nacimientos\", \"tendencia_defunciones\", \"volatilidad_nacimientos\", \"volatilidad_defunciones\"\n",
    "]\n",
    "for var in variables_tendencia:\n",
    "    if var in dataset_tendencias.columns:\n",
    "        print(f\"  ‚úÖ {var}\")\n",
    "\n",
    "print(\"\\n=== ARCHIVOS GENERADOS PARA MODELADO ===\")\n",
    "# CORRECCI√ìN: Usar rutas correctas\n",
    "archivos_modelado = [\n",
    "    \"dataset_final_modelado_defunciones.csv\",\n",
    "    \"dataset_tendencias_temporales.csv\", \n",
    "    \"mapeos_codificacion.json\"\n",
    "]\n",
    "\n",
    "for archivo in archivos_modelado:\n",
    "    print(f\"üìÅ data/03_primary/{archivo}\")\n",
    "\n",
    "print(\"\\n=== CASOS DE USO PARA MODELADO ===\")\n",
    "print(\"üéØ Modelado de defunciones por regi√≥n y edad:\")\n",
    "print(\"   - Dataset: dataset_final_modelado_defunciones.csv\")\n",
    "print(\"   - Features: region, edad, sexo, √©poca del a√±o, d√≠a de la semana\")\n",
    "print(\"   - Objetivo: Predecir patrones de mortalidad\")\n",
    "\n",
    "print(\"\\nüéØ An√°lisis de tendencias temporales:\")\n",
    "print(\"   - Dataset: dataset_tendencias_temporales.csv\")\n",
    "print(\"   - Features: promedios m√≥viles, tendencias lineales, volatilidad\")\n",
    "print(\"   - Objetivo: Predecir nacimientos/defunciones futuras\")\n",
    "\n",
    "print(\"\\nüéØ An√°lisis estacional:\")\n",
    "print(\"   - Features: mes_sin/cos, d√≠a_semana_sin/cos, √©poca del a√±o\")\n",
    "print(\"   - Objetivo: Identificar patrones estacionales\")\n",
    "\n",
    "print(\"\\n‚úÖ Preparaci√≥n para modelado completada exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d55df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NORMALIZACI√ìN DE ESCALAS ===\n",
      "üìä Normalizando escalas para comparaciones entre variables...\n",
      "\n",
      "üîç Identificando variables para normalizaci√≥n...\n",
      "Variables num√©ricas en dataset de modelado: 22\n",
      "Variables: ['a√±o', 'edad_cantidad', 'region_codificada', 'sexo_codificado', 'rango_edad_codificado', 'categoria_diagnostico_codificada', 'mes', 'trimestre', 'dia_a√±o', 'mes_sin', 'mes_cos', 'dia_a√±o_sin', 'dia_a√±o_cos', 'trimestre_sin', 'trimestre_cos', 'dia_semana_sin', 'dia_semana_cos', 'es_fin_semana', 'es_invierno', 'es_verano', 'trimestre_fiscal', 'epoca_a√±o_codificada']\n",
      "\n",
      "Variables num√©ricas en dataset de tendencias: 39\n",
      "\n",
      "üìä Normalizando dataset de modelado...\n",
      "Variables a normalizar en modelado: ['a√±o', 'edad_cantidad', 'mes', 'trimestre', 'dia_a√±o', 'mes_sin', 'mes_cos', 'dia_a√±o_sin', 'dia_a√±o_cos', 'trimestre_sin', 'trimestre_cos', 'dia_semana_sin', 'dia_semana_cos', 'trimestre_fiscal']\n",
      "‚úÖ Dataset de modelado normalizado con StandardScaler\n",
      "\n",
      "üìä Normalizando dataset de tendencias...\n",
      "Variables a normalizar en tendencias: 38\n",
      "‚úÖ Dataset de tendencias normalizado con StandardScaler\n",
      "\n",
      "üìä Creando versiones con diferentes tipos de normalizaci√≥n...\n",
      "‚úÖ Versiones creadas con MinMaxScaler y RobustScaler\n",
      "\n",
      "üìä Comparaci√≥n de escalas antes y despu√©s de normalizaci√≥n:\n",
      "Variables principales en dataset de tendencias:\n",
      "\n",
      "NACIMIENTOS_TOTALES:\n",
      "  Original - Min: 171992.00, Max: 292146.00, Media: 243175.12\n",
      "  StandardScaler - Min: -2.76, Max: 1.90, Media: 0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.59\n",
      "  RobustScaler - Min: -2.86, Max: 1.76, Media: -0.12\n",
      "\n",
      "DEFUNCIONES_TOTALES:\n",
      "  Original - Min: 69887.00, Max: 137439.00, Media: 87280.06\n",
      "  StandardScaler - Min: -1.03, Max: 2.97, Media: 0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.26\n",
      "  RobustScaler - Min: -0.46, Max: 2.52, Media: 0.30\n",
      "\n",
      "CRECIMIENTO_NATURAL:\n",
      "  Original - Min: 39816.00, Max: 213712.00, Media: 155895.06\n",
      "  StandardScaler - Min: -2.92, Max: 1.46, Media: 0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.67\n",
      "  RobustScaler - Min: -3.24, Max: 1.48, Media: -0.09\n",
      "\n",
      "RATIO_NACIMIENTOS_SEXO:\n",
      "  Original - Min: 1.03, Max: 1.05, Media: 1.04\n",
      "  StandardScaler - Min: -1.88, Max: 1.96, Media: -0.00\n",
      "  MinMaxScaler - Min: 0.00, Max: 1.00, Media: 0.49\n",
      "  RobustScaler - Min: -5.50, Max: 5.50, Media: -0.11\n",
      "\n",
      "üìä Datasets normalizados creados:\n",
      "  - dataset_modelado_normalizado: (1246037, 23)\n",
      "  - dataset_tendencias_normalizado: (50, 39)\n",
      "  - dataset_tendencias_minmax: (50, 39)\n",
      "  - dataset_tendencias_robust: (50, 39)\n"
     ]
    }
   ],
   "source": [
    "# 8.6 Normalizaci√≥n de escalas para comparaciones entre variables\n",
    "\n",
    "print(\"=== NORMALIZACI√ìN DE ESCALAS ===\")\n",
    "\n",
    "# Importar librer√≠as para normalizaci√≥n\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "print(\"üìä Normalizando escalas para comparaciones entre variables...\")\n",
    "\n",
    "# 1. Identificar variables que necesitan normalizaci√≥n\n",
    "print(\"\\nüîç Identificando variables para normalizaci√≥n...\")\n",
    "\n",
    "# Variables num√©ricas en el dataset de modelado\n",
    "variables_numericas_modelado = dataset_final_modelado.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Variables num√©ricas en dataset de modelado: {len(variables_numericas_modelado)}\")\n",
    "print(f\"Variables: {variables_numericas_modelado}\")\n",
    "\n",
    "# Variables num√©ricas en el dataset de tendencias\n",
    "variables_numericas_tendencias = dataset_tendencias.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nVariables num√©ricas en dataset de tendencias: {len(variables_numericas_tendencias)}\")\n",
    "\n",
    "# 2. Normalizaci√≥n del dataset de modelado\n",
    "print(\"\\nüìä Normalizando dataset de modelado...\")\n",
    "\n",
    "# Crear copia para normalizaci√≥n\n",
    "dataset_modelado_normalizado = dataset_final_modelado.copy()\n",
    "\n",
    "# Variables a normalizar (excluir c√≥digos categ√≥ricos que ya est√°n normalizados)\n",
    "variables_a_normalizar_modelado = [col for col in variables_numericas_modelado \n",
    "                                 if col not in ['region_codificada', 'sexo_codificado', 'rango_edad_codificado', \n",
    "                                               'categoria_diagnostico_codificada', 'dia_semana_codificado', \n",
    "                                               'epoca_a√±o_codificada', 'es_fin_semana', 'es_invierno', 'es_verano']]\n",
    "\n",
    "print(f\"Variables a normalizar en modelado: {variables_a_normalizar_modelado}\")\n",
    "\n",
    "# Aplicar StandardScaler (media=0, desviaci√≥n=1)\n",
    "scaler_modelado = StandardScaler()\n",
    "dataset_modelado_normalizado[variables_a_normalizar_modelado] = scaler_modelado.fit_transform(\n",
    "    dataset_modelado_normalizado[variables_a_normalizar_modelado]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dataset de modelado normalizado con StandardScaler\")\n",
    "\n",
    "# 3. Normalizaci√≥n del dataset de tendencias\n",
    "print(\"\\nüìä Normalizando dataset de tendencias...\")\n",
    "\n",
    "# Crear copia para normalizaci√≥n\n",
    "dataset_tendencias_normalizado = dataset_tendencias.copy()\n",
    "\n",
    "# Variables a normalizar (excluir a√±o y variables ya normalizadas)\n",
    "variables_a_normalizar_tendencias = [col for col in variables_numericas_tendencias \n",
    "                                   if col not in ['a√±o'] and not col.endswith('_codificado')]\n",
    "\n",
    "print(f\"Variables a normalizar en tendencias: {len(variables_a_normalizar_tendencias)}\")\n",
    "\n",
    "# Aplicar diferentes tipos de normalizaci√≥n\n",
    "# StandardScaler para la mayor√≠a de variables\n",
    "scaler_tendencias_std = StandardScaler()\n",
    "dataset_tendencias_normalizado[variables_a_normalizar_tendencias] = scaler_tendencias_std.fit_transform(\n",
    "    dataset_tendencias_normalizado[variables_a_normalizar_tendencias]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dataset de tendencias normalizado con StandardScaler\")\n",
    "\n",
    "# 4. Crear versiones con diferentes tipos de normalizaci√≥n para comparaci√≥n\n",
    "print(\"\\nüìä Creando versiones con diferentes tipos de normalizaci√≥n...\")\n",
    "\n",
    "# MinMaxScaler (escala 0-1)\n",
    "dataset_tendencias_minmax = dataset_tendencias.copy()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "dataset_tendencias_minmax[variables_a_normalizar_tendencias] = scaler_minmax.fit_transform(\n",
    "    dataset_tendencias_minmax[variables_a_normalizar_tendencias]\n",
    ")\n",
    "\n",
    "# RobustScaler (resistente a outliers)\n",
    "dataset_tendencias_robust = dataset_tendencias.copy()\n",
    "scaler_robust = RobustScaler()\n",
    "dataset_tendencias_robust[variables_a_normalizar_tendencias] = scaler_robust.fit_transform(\n",
    "    dataset_tendencias_robust[variables_a_normalizar_tendencias]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Versiones creadas con MinMaxScaler y RobustScaler\")\n",
    "\n",
    "# 5. Mostrar comparaci√≥n de escalas antes y despu√©s\n",
    "print(\"\\nüìä Comparaci√≥n de escalas antes y despu√©s de normalizaci√≥n:\")\n",
    "print(\"Variables principales en dataset de tendencias:\")\n",
    "\n",
    "variables_principales = ['nacimientos_totales', 'defunciones_totales', 'crecimiento_natural', 'ratio_nacimientos_sexo']\n",
    "\n",
    "for var in variables_principales:\n",
    "    if var in dataset_tendencias.columns:\n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        print(f\"  Original - Min: {dataset_tendencias[var].min():.2f}, Max: {dataset_tendencias[var].max():.2f}, Media: {dataset_tendencias[var].mean():.2f}\")\n",
    "        print(f\"  StandardScaler - Min: {dataset_tendencias_normalizado[var].min():.2f}, Max: {dataset_tendencias_normalizado[var].max():.2f}, Media: {dataset_tendencias_normalizado[var].mean():.2f}\")\n",
    "        print(f\"  MinMaxScaler - Min: {dataset_tendencias_minmax[var].min():.2f}, Max: {dataset_tendencias_minmax[var].max():.2f}, Media: {dataset_tendencias_minmax[var].mean():.2f}\")\n",
    "        print(f\"  RobustScaler - Min: {dataset_tendencias_robust[var].min():.2f}, Max: {dataset_tendencias_robust[var].max():.2f}, Media: {dataset_tendencias_robust[var].mean():.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Datasets normalizados creados:\")\n",
    "print(f\"  - dataset_modelado_normalizado: {dataset_modelado_normalizado.shape}\")\n",
    "print(f\"  - dataset_tendencias_normalizado: {dataset_tendencias_normalizado.shape}\")\n",
    "print(f\"  - dataset_tendencias_minmax: {dataset_tendencias_minmax.shape}\")\n",
    "print(f\"  - dataset_tendencias_robust: {dataset_tendencias_robust.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4efc0919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASETS NORMALIZADOS ===\n",
      "‚úÖ Dataset de modelado normalizado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_modelado_defunciones_normalizado.csv\n",
      "‚úÖ Dataset de tendencias normalizado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_normalizado.csv\n",
      "‚úÖ Dataset de tendencias MinMax guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_minmax.csv\n",
      "‚úÖ Dataset de tendencias Robust guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_robust.csv\n",
      "‚úÖ Scalers guardados: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\scalers_normalizacion.pkl\n",
      "\n",
      "ÔøΩÔøΩ Verificando archivos normalizados:\n",
      "  ‚úÖ dataset_modelado_defunciones_normalizado.csv: 364.55 MB\n",
      "  ‚úÖ dataset_tendencias_normalizado.csv: 0.03 MB\n",
      "  ‚úÖ dataset_tendencias_minmax.csv: 0.03 MB\n",
      "  ‚úÖ dataset_tendencias_robust.csv: 0.03 MB\n",
      "  ‚úÖ scalers_normalizacion.pkl: 0.01 MB\n",
      "\n",
      "ÔøΩÔøΩ RESUMEN DE ARCHIVOS NORMALIZADOS:\n",
      "‚úÖ Todos los archivos guardados en: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\n",
      "‚úÖ 4 datasets normalizados + 1 archivo de scalers\n",
      "\n",
      "‚úÖ Normalizaci√≥n de escalas completada\n"
     ]
    }
   ],
   "source": [
    "# 8.7 Guardar datasets normalizados (CORREGIDO)\n",
    "\n",
    "print(\"=== GUARDANDO DATASETS NORMALIZADOS ===\")\n",
    "\n",
    "# CORRECCI√ìN: Usar carpeta 03_primary\n",
    "carpeta_normalizados = r\"C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\"\n",
    "\n",
    "# Guardar datasets normalizados\n",
    "ruta_modelado_normalizado = os.path.join(carpeta_normalizados, \"dataset_modelado_defunciones_normalizado.csv\")\n",
    "dataset_modelado_normalizado.to_csv(ruta_modelado_normalizado, index=False)\n",
    "print(f\"‚úÖ Dataset de modelado normalizado guardado: {ruta_modelado_normalizado}\")\n",
    "\n",
    "ruta_tendencias_normalizado = os.path.join(carpeta_normalizados, \"dataset_tendencias_normalizado.csv\")\n",
    "dataset_tendencias_normalizado.to_csv(ruta_tendencias_normalizado, index=False)\n",
    "print(f\"‚úÖ Dataset de tendencias normalizado guardado: {ruta_tendencias_normalizado}\")\n",
    "\n",
    "ruta_tendencias_minmax = os.path.join(carpeta_normalizados, \"dataset_tendencias_minmax.csv\")\n",
    "dataset_tendencias_minmax.to_csv(ruta_tendencias_minmax, index=False)\n",
    "print(f\"‚úÖ Dataset de tendencias MinMax guardado: {ruta_tendencias_minmax}\")\n",
    "\n",
    "ruta_tendencias_robust = os.path.join(carpeta_normalizados, \"dataset_tendencias_robust.csv\")\n",
    "dataset_tendencias_robust.to_csv(ruta_tendencias_robust, index=False)\n",
    "print(f\"‚úÖ Dataset de tendencias Robust guardado: {ruta_tendencias_robust}\")\n",
    "\n",
    "# Guardar scalers para uso posterior\n",
    "import pickle\n",
    "\n",
    "# Guardar scalers\n",
    "scalers_info = {\n",
    "    'scaler_modelado': scaler_modelado,\n",
    "    'scaler_tendencias_std': scaler_tendencias_std,\n",
    "    'scaler_minmax': scaler_minmax,\n",
    "    'scaler_robust': scaler_robust,\n",
    "    'variables_modelado': variables_a_normalizar_modelado,\n",
    "    'variables_tendencias': variables_a_normalizar_tendencias\n",
    "}\n",
    "\n",
    "ruta_scalers = os.path.join(carpeta_normalizados, \"scalers_normalizacion.pkl\")\n",
    "with open(ruta_scalers, 'wb') as f:\n",
    "    pickle.dump(scalers_info, f)\n",
    "print(f\"‚úÖ Scalers guardados: {ruta_scalers}\")\n",
    "\n",
    "# Verificar archivos guardados\n",
    "archivos_normalizados = [\n",
    "    ruta_modelado_normalizado,\n",
    "    ruta_tendencias_normalizado,\n",
    "    ruta_tendencias_minmax,\n",
    "    ruta_tendencias_robust,\n",
    "    ruta_scalers\n",
    "]\n",
    "\n",
    "print(f\"\\nÔøΩÔøΩ Verificando archivos normalizados:\")\n",
    "for archivo in archivos_normalizados:\n",
    "    if os.path.exists(archivo):\n",
    "        tama√±o = os.path.getsize(archivo) / (1024*1024)\n",
    "        print(f\"  ‚úÖ {os.path.basename(archivo)}: {tama√±o:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {os.path.basename(archivo)}: No encontrado\")\n",
    "\n",
    "print(f\"\\nÔøΩÔøΩ RESUMEN DE ARCHIVOS NORMALIZADOS:\")\n",
    "print(f\"‚úÖ Todos los archivos guardados en: {carpeta_normalizados}\")\n",
    "print(f\"‚úÖ 4 datasets normalizados + 1 archivo de scalers\")\n",
    "\n",
    "print(\"\\n‚úÖ Normalizaci√≥n de escalas completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45776b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN FINAL ACTUALIZADO CON NORMALIZACI√ìN ===\n",
      "üìã Datasets finales creados (incluyendo versiones normalizadas):\n",
      "\n",
      "DATASET_FINAL_MODELADO:\n",
      "   Dimensiones: (1246037, 23)\n",
      "   Per√≠odo temporal: 2014 - 2024\n",
      "   Columnas: 23\n",
      "\n",
      "DATASET_MODELADO_NORMALIZADO:\n",
      "   Dimensiones: (1246037, 23)\n",
      "   Per√≠odo temporal: -1.6796752733960778 - 1.56487523619281\n",
      "   Columnas: 23\n",
      "\n",
      "DATASET_TENDENCIAS:\n",
      "   Dimensiones: (50, 39)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_TENDENCIAS_NORMALIZADO:\n",
      "   Dimensiones: (50, 39)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_TENDENCIAS_MINMAX:\n",
      "   Dimensiones: (50, 39)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_TENDENCIAS_ROBUST:\n",
      "   Dimensiones: (50, 39)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 39\n",
      "\n",
      "DATASET_EXTENDIDO:\n",
      "   Dimensiones: (10, 35)\n",
      "   Per√≠odo temporal: 2014 - 2023\n",
      "   Columnas: 35\n",
      "\n",
      "DATASET_UNIFICADO:\n",
      "   Dimensiones: (50, 23)\n",
      "   Per√≠odo temporal: 1974 - 2023\n",
      "   Columnas: 23\n",
      "\n",
      "=== TIPOS DE NORMALIZACI√ìN IMPLEMENTADOS ===\n",
      "üìä StandardScaler (media=0, desviaci√≥n=1):\n",
      "   ‚úÖ dataset_modelado_normalizado\n",
      "   ‚úÖ dataset_tendencias_normalizado\n",
      "   üéØ Uso: Algoritmos que asumen distribuci√≥n normal (regresi√≥n lineal, SVM)\n",
      "\n",
      "üìä MinMaxScaler (escala 0-1):\n",
      "   ‚úÖ dataset_tendencias_minmax\n",
      "   üéØ Uso: Algoritmos sensibles a la escala (redes neuronales, k-means)\n",
      "\n",
      "üìä RobustScaler (resistente a outliers):\n",
      "   ‚úÖ dataset_tendencias_robust\n",
      "   üéØ Uso: Datos con outliers significativos\n",
      "\n",
      "=== ARCHIVOS GENERADOS COMPLETOS ===\n",
      "ÔøΩÔøΩ data/03_primary/dataset_final_modelado_defunciones.csv\n",
      "ÔøΩÔøΩ data/03_primary/dataset_modelado_defunciones_normalizado.csv\n",
      "ÔøΩÔøΩ data/03_primary/dataset_tendencias_temporales.csv\n",
      "ÔøΩÔøΩ data/03_primary/dataset_tendencias_normalizado.csv\n",
      "ÔøΩÔøΩ data/03_primary/dataset_tendencias_minmax.csv\n",
      "ÔøΩÔøΩ data/03_primary/dataset_tendencias_robust.csv\n",
      "ÔøΩÔøΩ data/03_primary/mapeos_codificacion.json\n",
      "ÔøΩÔøΩ data/03_primary/scalers_normalizacion.pkl\n",
      "\n",
      "=== BENEFICIOS DE LA NORMALIZACI√ìN ===\n",
      "‚úÖ Comparaciones justas entre variables de diferentes magnitudes\n",
      "‚úÖ Mejor rendimiento en algoritmos de Machine Learning\n",
      "‚úÖ Reducci√≥n del sesgo hacia variables con escalas mayores\n",
      "‚úÖ Facilita la interpretaci√≥n de coeficientes en modelos\n",
      "‚úÖ Mejora la convergencia en algoritmos iterativos\n",
      "\n",
      "=== RECOMENDACIONES DE USO ===\n",
      "ÔøΩÔøΩ Para regresi√≥n lineal y SVM: usar StandardScaler\n",
      "üéØ Para redes neuronales: usar MinMaxScaler\n",
      "üéØ Para datos con outliers: usar RobustScaler\n",
      "ÔøΩÔøΩ Para comparaciones visuales: usar MinMaxScaler\n",
      "\n",
      "‚úÖ Preparaci√≥n completa para modelado con normalizaci√≥n terminada\n"
     ]
    }
   ],
   "source": [
    "# 8.9 Actualizar resumen final con normalizaci√≥n (CORREGIDO)\n",
    "\n",
    "print(\"=== RESUMEN FINAL ACTUALIZADO CON NORMALIZACI√ìN ===\")\n",
    "\n",
    "# Actualizar resumen de datasets creados\n",
    "datasets_finales_completos = {\n",
    "    \"dataset_final_modelado\": dataset_final_modelado,\n",
    "    \"dataset_modelado_normalizado\": dataset_modelado_normalizado,\n",
    "    \"dataset_tendencias\": dataset_tendencias,\n",
    "    \"dataset_tendencias_normalizado\": dataset_tendencias_normalizado,\n",
    "    \"dataset_tendencias_minmax\": dataset_tendencias_minmax,\n",
    "    \"dataset_tendencias_robust\": dataset_tendencias_robust,\n",
    "    \"dataset_extendido\": dataset_extendido,\n",
    "    \"dataset_unificado\": dataset_unificado\n",
    "}\n",
    "\n",
    "print(\"üìã Datasets finales creados (incluyendo versiones normalizadas):\")\n",
    "for nombre_dataset, df in datasets_finales_completos.items():\n",
    "    print(f\"\\n{nombre_dataset.upper()}:\")\n",
    "    print(f\"   Dimensiones: {df.shape}\")\n",
    "    print(f\"   Per√≠odo temporal: {df['a√±o'].min()} - {df['a√±o'].max()}\")\n",
    "    print(f\"   Columnas: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== TIPOS DE NORMALIZACI√ìN IMPLEMENTADOS ===\")\n",
    "\n",
    "print(\"üìä StandardScaler (media=0, desviaci√≥n=1):\")\n",
    "print(\"   ‚úÖ dataset_modelado_normalizado\")\n",
    "print(\"   ‚úÖ dataset_tendencias_normalizado\")\n",
    "print(\"   üéØ Uso: Algoritmos que asumen distribuci√≥n normal (regresi√≥n lineal, SVM)\")\n",
    "\n",
    "print(\"\\nüìä MinMaxScaler (escala 0-1):\")\n",
    "print(\"   ‚úÖ dataset_tendencias_minmax\")\n",
    "print(\"   üéØ Uso: Algoritmos sensibles a la escala (redes neuronales, k-means)\")\n",
    "\n",
    "print(\"\\nüìä RobustScaler (resistente a outliers):\")\n",
    "print(\"   ‚úÖ dataset_tendencias_robust\")\n",
    "print(\"   üéØ Uso: Datos con outliers significativos\")\n",
    "\n",
    "print(\"\\n=== ARCHIVOS GENERADOS COMPLETOS ===\")\n",
    "# CORRECCI√ìN: Usar rutas correctas\n",
    "archivos_completos = [\n",
    "    \"dataset_final_modelado_defunciones.csv\",\n",
    "    \"dataset_modelado_defunciones_normalizado.csv\",\n",
    "    \"dataset_tendencias_temporales.csv\",\n",
    "    \"dataset_tendencias_normalizado.csv\",\n",
    "    \"dataset_tendencias_minmax.csv\",\n",
    "    \"dataset_tendencias_robust.csv\",\n",
    "    \"mapeos_codificacion.json\",\n",
    "    \"scalers_normalizacion.pkl\"\n",
    "]\n",
    "\n",
    "for archivo in archivos_completos:\n",
    "    print(f\"ÔøΩÔøΩ data/03_primary/{archivo}\")\n",
    "\n",
    "print(\"\\n=== BENEFICIOS DE LA NORMALIZACI√ìN ===\")\n",
    "print(\"‚úÖ Comparaciones justas entre variables de diferentes magnitudes\")\n",
    "print(\"‚úÖ Mejor rendimiento en algoritmos de Machine Learning\")\n",
    "print(\"‚úÖ Reducci√≥n del sesgo hacia variables con escalas mayores\")\n",
    "print(\"‚úÖ Facilita la interpretaci√≥n de coeficientes en modelos\")\n",
    "print(\"‚úÖ Mejora la convergencia en algoritmos iterativos\")\n",
    "\n",
    "print(\"\\n=== RECOMENDACIONES DE USO ===\")\n",
    "print(\"ÔøΩÔøΩ Para regresi√≥n lineal y SVM: usar StandardScaler\")\n",
    "print(\"üéØ Para redes neuronales: usar MinMaxScaler\")\n",
    "print(\"üéØ Para datos con outliers: usar RobustScaler\")\n",
    "print(\"ÔøΩÔøΩ Para comparaciones visuales: usar MinMaxScaler\")\n",
    "\n",
    "print(\"\\n‚úÖ Preparaci√≥n completa para modelado con normalizaci√≥n terminada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77ddeb",
   "metadata": {},
   "source": [
    "## 9. Manejo Avanzado de C√≥digos CIE-10\n",
    "\n",
    "Esta secci√≥n se enfoca en validar y mejorar el manejo de c√≥digos de diagn√≥stico CIE-10 para an√°lisis m√°s robustos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06fa7a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACI√ìN DE C√ìDIGOS CIE-10 ===\n",
      "üîç Analizando c√≥digos de diagn√≥stico...\n",
      "üìä Total de c√≥digos √∫nicos encontrados: 20\n",
      "\n",
      "üìã Primeros 10 c√≥digos encontrados:\n",
      "   1. A00-B99\n",
      "   2. C00-D48\n",
      "   3. D50-D89\n",
      "   4. E00-E90\n",
      "   5. F00-F99\n",
      "   6. G00-G99\n",
      "   7. H00-H59\n",
      "   8. H60-H95\n",
      "   9. I00-I99\n",
      "  10. J00-J99\n",
      "\n",
      "üîç An√°lisis de patrones de c√≥digos:\n",
      "  C√≥digos que empiezan con letra: 20\n",
      "  C√≥digos que empiezan con n√∫mero: 0\n",
      "  C√≥digos nulos: 0\n",
      "  C√≥digos con formato extra√±o: 0\n",
      "\n",
      "‚úÖ Validaci√≥n de c√≥digos CIE-10:\n",
      "  C√≥digos CIE-10 v√°lidos: 20\n",
      "  C√≥digos CIE-10 inv√°lidos: 0\n",
      "\n",
      "üìä Distribuci√≥n por letra inicial:\n",
      "  A: 1 c√≥digos\n",
      "  C: 1 c√≥digos\n",
      "  D: 1 c√≥digos\n",
      "  E: 1 c√≥digos\n",
      "  F: 1 c√≥digos\n",
      "  G: 1 c√≥digos\n",
      "  H: 2 c√≥digos\n",
      "  I: 1 c√≥digos\n",
      "  J: 1 c√≥digos\n",
      "  K: 1 c√≥digos\n",
      "  L: 1 c√≥digos\n",
      "  M: 1 c√≥digos\n",
      "  N: 1 c√≥digos\n",
      "  O: 1 c√≥digos\n",
      "  P: 1 c√≥digos\n",
      "  Q: 1 c√≥digos\n",
      "  R: 1 c√≥digos\n",
      "  S: 1 c√≥digos\n",
      "  U: 1 c√≥digos\n"
     ]
    }
   ],
   "source": [
    "# 9.1 Validaci√≥n de c√≥digos CIE-10\n",
    "\n",
    "print(\"=== VALIDACI√ìN DE C√ìDIGOS CIE-10 ===\")\n",
    "\n",
    "# Analizar c√≥digos de diagn√≥stico en el dataset\n",
    "print(\"üîç Analizando c√≥digos de diagn√≥stico...\")\n",
    "\n",
    "# Obtener c√≥digos √∫nicos\n",
    "codigos_unicos = defunciones_estandarizado['codigo_diagnostico'].unique()\n",
    "print(f\"üìä Total de c√≥digos √∫nicos encontrados: {len(codigos_unicos)}\")\n",
    "\n",
    "# Mostrar algunos ejemplos\n",
    "print(f\"\\nüìã Primeros 10 c√≥digos encontrados:\")\n",
    "for i, codigo in enumerate(sorted(codigos_unicos)[:10]):\n",
    "    print(f\"  {i+1:2d}. {codigo}\")\n",
    "\n",
    "# Analizar patrones de c√≥digos\n",
    "print(f\"\\nüîç An√°lisis de patrones de c√≥digos:\")\n",
    "\n",
    "# C√≥digos que empiezan con letras (c√≥digos CIE-10 v√°lidos)\n",
    "codigos_con_letra = [codigo for codigo in codigos_unicos if pd.notna(codigo) and str(codigo)[0].isalpha()]\n",
    "print(f\"  C√≥digos que empiezan con letra: {len(codigos_con_letra)}\")\n",
    "\n",
    "# C√≥digos que empiezan con n√∫meros\n",
    "codigos_con_numero = [codigo for codigo in codigos_unicos if pd.notna(codigo) and str(codigo)[0].isdigit()]\n",
    "print(f\"  C√≥digos que empiezan con n√∫mero: {len(codigos_con_numero)}\")\n",
    "\n",
    "# C√≥digos nulos o vac√≠os\n",
    "codigos_nulos = [codigo for codigo in codigos_unicos if pd.isna(codigo)]\n",
    "print(f\"  C√≥digos nulos: {len(codigos_nulos)}\")\n",
    "\n",
    "# C√≥digos con formato extra√±o\n",
    "codigos_raros = [codigo for codigo in codigos_unicos if pd.notna(codigo) and not str(codigo)[0].isalnum()]\n",
    "print(f\"  C√≥digos con formato extra√±o: {len(codigos_raros)}\")\n",
    "\n",
    "if len(codigos_raros) > 0:\n",
    "    print(f\"    Ejemplos: {codigos_raros[:5]}\")\n",
    "\n",
    "# Verificar c√≥digos CIE-10 v√°lidos\n",
    "print(f\"\\n‚úÖ Validaci√≥n de c√≥digos CIE-10:\")\n",
    "letras_validas_cie10 = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "codigos_validos = []\n",
    "codigos_invalidos = []\n",
    "\n",
    "for codigo in codigos_con_letra:\n",
    "    if str(codigo)[0] in letras_validas_cie10:\n",
    "        codigos_validos.append(codigo)\n",
    "    else:\n",
    "        codigos_invalidos.append(codigo)\n",
    "\n",
    "print(f\"  C√≥digos CIE-10 v√°lidos: {len(codigos_validos)}\")\n",
    "print(f\"  C√≥digos CIE-10 inv√°lidos: {len(codigos_invalidos)}\")\n",
    "\n",
    "if len(codigos_invalidos) > 0:\n",
    "    print(f\"    C√≥digos inv√°lidos: {codigos_invalidos[:5]}\")\n",
    "\n",
    "# Mostrar distribuci√≥n por letra inicial\n",
    "print(f\"\\nüìä Distribuci√≥n por letra inicial:\")\n",
    "distribucion_letras = {}\n",
    "for codigo in codigos_validos:\n",
    "    letra = str(codigo)[0]\n",
    "    distribucion_letras[letra] = distribucion_letras.get(letra, 0) + 1\n",
    "\n",
    "for letra in sorted(distribucion_letras.keys()):\n",
    "    print(f\"  {letra}: {distribucion_letras[letra]:,} c√≥digos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bab63429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEJORA DE CATEGORIZACI√ìN CIE-10 ===\n",
      "üîß Aplicando categorizaci√≥n mejorada...\n",
      "\n",
      "üìä Distribuci√≥n de categor√≠as mejoradas:\n",
      "  enfermedades_cardiovasculares      :  314,610 ( 25.2%)\n",
      "  neoplasias_hematologicas           :  308,859 ( 24.8%)\n",
      "  enfermedades_respiratorias         :  129,914 ( 10.4%)\n",
      "  enfermedades_digestivas            :   89,496 (  7.2%)\n",
      "  traumatismos_envenenamientos       :   84,968 (  6.8%)\n",
      "  causas_externas_especiales         :   57,783 (  4.6%)\n",
      "  enfermedades_endocrinas_nutricionales:   56,280 (  4.5%)\n",
      "  enfermedades_sistema_nervioso      :   47,920 (  3.8%)\n",
      "  enfermedades_genitourinarias       :   37,398 (  3.0%)\n",
      "  sintomas_signos_anormales          :   34,995 (  2.8%)\n",
      "  enfermedades_infecciosas_parasitarias:   26,605 (  2.1%)\n",
      "  enfermedades_mentales_conductuales :   26,146 (  2.1%)\n",
      "  enfermedades_piel_tejido_subcutaneo:    8,324 (  0.7%)\n",
      "  malformaciones_congenitas          :    8,230 (  0.7%)\n",
      "  enfermedades_musculoesqueleticas   :    7,146 (  0.6%)\n",
      "  afecciones_perinatales             :    6,919 (  0.6%)\n",
      "  complicaciones_embarazo_parto      :      518 (  0.0%)\n",
      "  enfermedades_ojos_oidos            :       89 (  0.0%)\n",
      "\n",
      "üîç Categor√≠as con pocos casos (<1% del total):\n",
      "  enfermedades_piel_tejido_subcutaneo:    8,324 (  0.7%)\n",
      "  malformaciones_congenitas          :    8,230 (  0.7%)\n",
      "  enfermedades_musculoesqueleticas   :    7,146 (  0.6%)\n",
      "  afecciones_perinatales             :    6,919 (  0.6%)\n",
      "  complicaciones_embarazo_parto      :      518 (  0.0%)\n",
      "  enfermedades_ojos_oidos            :       89 (  0.0%)\n",
      "\n",
      "üìä Creando categor√≠as de alto nivel...\n",
      "\n",
      "üìä Distribuci√≥n de categor√≠as de alto nivel:\n",
      "  enfermedades_cardiovasculares:  314,610 ( 25.2%)\n",
      "  cancer_neoplasias        :  308,859 ( 24.8%)\n",
      "  enfermedades_respiratorias:  129,914 ( 10.4%)\n",
      "  enfermedades_digestivas  :   89,496 (  7.2%)\n",
      "  traumatismos_accidentes  :   84,968 (  6.8%)\n",
      "  causas_externas          :   57,783 (  4.6%)\n",
      "  enfermedades_cronicas    :   56,280 (  4.5%)\n",
      "  enfermedades_neurologicas:   47,920 (  3.8%)\n",
      "  enfermedades_genitourinarias:   37,398 (  3.0%)\n",
      "  sintomas_no_especificados:   34,995 (  2.8%)\n",
      "  enfermedades_infecciosas :   26,605 (  2.1%)\n",
      "  salud_mental             :   26,146 (  2.1%)\n",
      "  enfermedades_piel        :    8,324 (  0.7%)\n",
      "  malformaciones_congenitas:    8,230 (  0.7%)\n",
      "  enfermedades_musculoesqueleticas:    7,146 (  0.6%)\n",
      "  afecciones_perinatales   :    6,919 (  0.6%)\n",
      "  complicaciones_embarazo  :      518 (  0.0%)\n",
      "  enfermedades_sentidos    :       89 (  0.0%)\n",
      "\n",
      "‚úÖ Categorizaci√≥n mejorada completada\n"
     ]
    }
   ],
   "source": [
    "# 9.2 Mejorar categorizaci√≥n de c√≥digos CIE-10\n",
    "\n",
    "print(\"=== MEJORA DE CATEGORIZACI√ìN CIE-10 ===\")\n",
    "\n",
    "# Crear funci√≥n mejorada de categorizaci√≥n\n",
    "def categorizar_diagnostico_mejorado(codigo):\n",
    "    \"\"\"\n",
    "    Categoriza c√≥digos CIE-10 en grupos principales mejorados\n",
    "    \"\"\"\n",
    "    if pd.isna(codigo):\n",
    "        return 'desconocido'\n",
    "    \n",
    "    codigo_str = str(codigo).upper()\n",
    "    \n",
    "    # Categor√≠as principales mejoradas basadas en CIE-10\n",
    "    if codigo_str.startswith(('A', 'B')):\n",
    "        return 'enfermedades_infecciosas_parasitarias'\n",
    "    elif codigo_str.startswith(('C', 'D')):\n",
    "        return 'neoplasias_hematologicas'\n",
    "    elif codigo_str.startswith('E'):\n",
    "        return 'enfermedades_endocrinas_nutricionales'\n",
    "    elif codigo_str.startswith('F'):\n",
    "        return 'enfermedades_mentales_conductuales'\n",
    "    elif codigo_str.startswith('G'):\n",
    "        return 'enfermedades_sistema_nervioso'\n",
    "    elif codigo_str.startswith('H'):\n",
    "        return 'enfermedades_ojos_oidos'\n",
    "    elif codigo_str.startswith('I'):\n",
    "        return 'enfermedades_cardiovasculares'\n",
    "    elif codigo_str.startswith('J'):\n",
    "        return 'enfermedades_respiratorias'\n",
    "    elif codigo_str.startswith('K'):\n",
    "        return 'enfermedades_digestivas'\n",
    "    elif codigo_str.startswith('L'):\n",
    "        return 'enfermedades_piel_tejido_subcutaneo'\n",
    "    elif codigo_str.startswith('M'):\n",
    "        return 'enfermedades_musculoesqueleticas'\n",
    "    elif codigo_str.startswith('N'):\n",
    "        return 'enfermedades_genitourinarias'\n",
    "    elif codigo_str.startswith('O'):\n",
    "        return 'complicaciones_embarazo_parto'\n",
    "    elif codigo_str.startswith('P'):\n",
    "        return 'afecciones_perinatales'\n",
    "    elif codigo_str.startswith('Q'):\n",
    "        return 'malformaciones_congenitas'\n",
    "    elif codigo_str.startswith('R'):\n",
    "        return 'sintomas_signos_anormales'\n",
    "    elif codigo_str.startswith(('S', 'T')):\n",
    "        return 'traumatismos_envenenamientos'\n",
    "    elif codigo_str.startswith('U'):\n",
    "        return 'causas_externas_especiales'\n",
    "    elif codigo_str.startswith(('V', 'W', 'X', 'Y')):\n",
    "        return 'causas_externas_accidentes'\n",
    "    elif codigo_str.startswith('Z'):\n",
    "        return 'factores_influencia_salud'\n",
    "    else:\n",
    "        return 'otros_no_clasificados'\n",
    "\n",
    "# Aplicar categorizaci√≥n mejorada\n",
    "print(\"üîß Aplicando categorizaci√≥n mejorada...\")\n",
    "defunciones_estandarizado['categoria_diagnostico_mejorada'] = defunciones_estandarizado['codigo_diagnostico'].apply(categorizar_diagnostico_mejorado)\n",
    "\n",
    "# Mostrar distribuci√≥n de categor√≠as mejoradas\n",
    "print(f\"\\nüìä Distribuci√≥n de categor√≠as mejoradas:\")\n",
    "distribucion_categorias = defunciones_estandarizado['categoria_diagnostico_mejorada'].value_counts()\n",
    "for categoria, cantidad in distribucion_categorias.items():\n",
    "    porcentaje = (cantidad / len(defunciones_estandarizado)) * 100\n",
    "    print(f\"  {categoria:35s}: {cantidad:8,} ({porcentaje:5.1f}%)\")\n",
    "\n",
    "# Identificar categor√≠as con pocos casos\n",
    "print(f\"\\nüîç Categor√≠as con pocos casos (<1% del total):\")\n",
    "total_registros = len(defunciones_estandarizado)\n",
    "categorias_pocos_casos = distribucion_categorias[distribucion_categorias < total_registros * 0.01]\n",
    "\n",
    "if len(categorias_pocos_casos) > 0:\n",
    "    for categoria, cantidad in categorias_pocos_casos.items():\n",
    "        porcentaje = (cantidad / total_registros) * 100\n",
    "        print(f\"  {categoria:35s}: {cantidad:8,} ({porcentaje:5.1f}%)\")\n",
    "else:\n",
    "    print(\"  ‚úÖ Todas las categor√≠as tienen al menos 1% de los casos\")\n",
    "\n",
    "# Crear categor√≠as de alto nivel (agrupaci√≥n adicional)\n",
    "print(f\"\\nüìä Creando categor√≠as de alto nivel...\")\n",
    "\n",
    "def crear_categoria_alto_nivel(categoria_detallada):\n",
    "    \"\"\"\n",
    "    Crea categor√≠as de alto nivel agrupando categor√≠as similares\n",
    "    \"\"\"\n",
    "    mapeo_alto_nivel = {\n",
    "        'enfermedades_infecciosas_parasitarias': 'enfermedades_infecciosas',\n",
    "        'neoplasias_hematologicas': 'cancer_neoplasias',\n",
    "        'enfermedades_endocrinas_nutricionales': 'enfermedades_cronicas',\n",
    "        'enfermedades_mentales_conductuales': 'salud_mental',\n",
    "        'enfermedades_sistema_nervioso': 'enfermedades_neurologicas',\n",
    "        'enfermedades_ojos_oidos': 'enfermedades_sentidos',\n",
    "        'enfermedades_cardiovasculares': 'enfermedades_cardiovasculares',\n",
    "        'enfermedades_respiratorias': 'enfermedades_respiratorias',\n",
    "        'enfermedades_digestivas': 'enfermedades_digestivas',\n",
    "        'enfermedades_piel_tejido_subcutaneo': 'enfermedades_piel',\n",
    "        'enfermedades_musculoesqueleticas': 'enfermedades_musculoesqueleticas',\n",
    "        'enfermedades_genitourinarias': 'enfermedades_genitourinarias',\n",
    "        'complicaciones_embarazo_parto': 'complicaciones_embarazo',\n",
    "        'afecciones_perinatales': 'afecciones_perinatales',\n",
    "        'malformaciones_congenitas': 'malformaciones_congenitas',\n",
    "        'sintomas_signos_anormales': 'sintomas_no_especificados',\n",
    "        'traumatismos_envenenamientos': 'traumatismos_accidentes',\n",
    "        'causas_externas_especiales': 'causas_externas',\n",
    "        'causas_externas_accidentes': 'causas_externas',\n",
    "        'factores_influencia_salud': 'factores_salud',\n",
    "        'otros_no_clasificados': 'otros',\n",
    "        'desconocido': 'desconocido'\n",
    "    }\n",
    "    \n",
    "    return mapeo_alto_nivel.get(categoria_detallada, 'otros')\n",
    "\n",
    "# Aplicar categorizaci√≥n de alto nivel\n",
    "defunciones_estandarizado['categoria_alto_nivel'] = defunciones_estandarizado['categoria_diagnostico_mejorada'].apply(crear_categoria_alto_nivel)\n",
    "\n",
    "# Mostrar distribuci√≥n de categor√≠as de alto nivel\n",
    "print(f\"\\nüìä Distribuci√≥n de categor√≠as de alto nivel:\")\n",
    "distribucion_alto_nivel = defunciones_estandarizado['categoria_alto_nivel'].value_counts()\n",
    "for categoria, cantidad in distribucion_alto_nivel.items():\n",
    "    porcentaje = (cantidad / len(defunciones_estandarizado)) * 100\n",
    "    print(f\"  {categoria:25s}: {cantidad:8,} ({porcentaje:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Categorizaci√≥n mejorada completada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a978a",
   "metadata": {},
   "source": [
    "## 10. Creaci√≥n de √çndices para Consultas R√°pidas\n",
    "\n",
    "Esta secci√≥n se enfoca en crear √≠ndices en los datasets principales para acelerar consultas futuras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6840fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREACI√ìN DE √çNDICES PARA CONSULTAS R√ÅPIDAS ===\n",
      "üîß Aplicando √≠ndices a datasets principales...\n",
      "\n",
      "ÔøΩÔøΩ Preparando √≠ndices para dataset_unificado...\n",
      "  Columnas disponibles: 23\n",
      "  ‚úÖ √çndice creado: a√±o\n",
      "  üìã √çndices creados: ['a√±o']\n",
      "\n",
      "ÔøΩÔøΩ Preparando √≠ndices para dataset_extendido...\n",
      "  Columnas disponibles: 35\n",
      "  ‚úÖ √çndice creado: a√±o\n",
      "  üìã √çndices creados: ['a√±o']\n",
      "\n",
      "ÔøΩÔøΩ Preparando √≠ndices para defunciones_estandarizado...\n",
      "  Columnas disponibles: 19\n",
      "  ‚úÖ √çndice creado: a√±o\n",
      "  ‚úÖ √çndice compuesto creado: a√±o-regi√≥n\n",
      "  ‚úÖ √çndice compuesto creado: a√±o-sexo\n",
      "  ‚úÖ √çndice creado: fecha_defuncion\n",
      "  üìã √çndices creados: ['a√±o', 'a√±o-regi√≥n', 'a√±o-sexo', 'fecha_defuncion']\n",
      "\n",
      "ÔøΩÔøΩ Preparando √≠ndices para dataset_tendencias...\n",
      "  Columnas disponibles: 39\n",
      "  ‚úÖ √çndice creado: a√±o\n",
      "  üìã √çndices creados: ['a√±o']\n",
      "\n",
      "ÔøΩÔøΩ Preparando √≠ndices para dataset_modelado...\n",
      "  Columnas disponibles: 23\n",
      "  ‚úÖ √çndice creado: a√±o\n",
      "  ‚úÖ √çndice creado: fecha_defuncion\n",
      "  üìã √çndices creados: ['a√±o', 'fecha_defuncion']\n",
      "\n",
      "‚úÖ √çndices creados en todos los datasets principales\n",
      "\n",
      "üìã Resumen de datasets indexados:\n",
      "  dataset_unificado_indexado: (50, 22)\n",
      "    √çndice: a√±o\n",
      "  dataset_extendido_indexado: (10, 34)\n",
      "    √çndice: a√±o\n",
      "  dataset_defunciones_indexado: (1246200, 18)\n",
      "    √çndice: fecha_defuncion\n",
      "  dataset_tendencias_indexado: (50, 38)\n",
      "    √çndice: a√±o\n",
      "  dataset_modelado_indexado: (1246037, 22)\n",
      "    √çndice: fecha_defuncion\n",
      "\n",
      "‚ö†Ô∏è NOTA IMPORTANTE:\n",
      "Los √≠ndices de pandas son temporales y no persisten al guardar en CSV.\n",
      "Para √≠ndices persistentes, se necesitar√≠a una base de datos (SQLite, PostgreSQL, etc.)\n",
      "Los √≠ndices actuales mejoran el rendimiento de consultas en memoria.\n"
     ]
    }
   ],
   "source": [
    "# 10.1 Crear √≠ndices en datasets principales (CORREGIDO)\n",
    "\n",
    "print(\"=== CREACI√ìN DE √çNDICES PARA CONSULTAS R√ÅPIDAS ===\")\n",
    "\n",
    "# Funci√≥n para crear √≠ndices en un dataset\n",
    "def crear_indices_dataset(df, nombre_dataset):\n",
    "    \"\"\"\n",
    "    Crea √≠ndices en un dataset para acelerar consultas comunes\n",
    "    NOTA: En pandas, los √≠ndices son temporales y no persisten en CSV\n",
    "    \"\"\"\n",
    "    print(f\"\\nÔøΩÔøΩ Preparando √≠ndices para {nombre_dataset}...\")\n",
    "    \n",
    "    # Crear copia para trabajar\n",
    "    df_indexado = df.copy()\n",
    "    \n",
    "    # Verificar columnas disponibles\n",
    "    columnas_disponibles = df_indexado.columns.tolist()\n",
    "    print(f\"  Columnas disponibles: {len(columnas_disponibles)}\")\n",
    "    \n",
    "    # Crear √≠ndices compuestos √∫tiles (sin resetear)\n",
    "    indices_creados = []\n",
    "    \n",
    "    # √çndice por a√±o (m√°s com√∫n)\n",
    "    if 'a√±o' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.set_index('a√±o')\n",
    "        indices_creados.append('a√±o')\n",
    "        print(f\"  ‚úÖ √çndice creado: a√±o\")\n",
    "    \n",
    "    # √çndices espec√≠ficos para dataset de defunciones\n",
    "    if 'region' in columnas_disponibles and 'a√±o' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.reset_index()  # Resetear para crear √≠ndice compuesto\n",
    "        df_indexado = df_indexado.set_index(['a√±o', 'region'])\n",
    "        indices_creados.append('a√±o-regi√≥n')\n",
    "        print(f\"  ‚úÖ √çndice compuesto creado: a√±o-regi√≥n\")\n",
    "    \n",
    "    if 'sexo' in columnas_disponibles and 'a√±o' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.reset_index()\n",
    "        df_indexado = df_indexado.set_index(['a√±o', 'sexo'])\n",
    "        indices_creados.append('a√±o-sexo')\n",
    "        print(f\"  ‚úÖ √çndice compuesto creado: a√±o-sexo\")\n",
    "    \n",
    "    if 'fecha_defuncion' in columnas_disponibles:\n",
    "        df_indexado = df_indexado.reset_index()\n",
    "        df_indexado = df_indexado.set_index('fecha_defuncion')\n",
    "        indices_creados.append('fecha_defuncion')\n",
    "        print(f\"  ‚úÖ √çndice creado: fecha_defuncion\")\n",
    "    \n",
    "    print(f\"  üìã √çndices creados: {indices_creados}\")\n",
    "    return df_indexado\n",
    "\n",
    "# Crear √≠ndices en datasets principales\n",
    "print(\"üîß Aplicando √≠ndices a datasets principales...\")\n",
    "\n",
    "# 1. Dataset unificado temporal\n",
    "dataset_unificado_indexado = crear_indices_dataset(dataset_unificado, \"dataset_unificado\")\n",
    "\n",
    "# 2. Dataset extendido\n",
    "dataset_extendido_indexado = crear_indices_dataset(dataset_extendido, \"dataset_extendido\")\n",
    "\n",
    "# 3. Dataset de defunciones detalladas\n",
    "dataset_defunciones_indexado = crear_indices_dataset(defunciones_estandarizado, \"defunciones_estandarizado\")\n",
    "\n",
    "# 4. Dataset de tendencias\n",
    "dataset_tendencias_indexado = crear_indices_dataset(dataset_tendencias, \"dataset_tendencias\")\n",
    "\n",
    "# 5. Dataset de modelado\n",
    "dataset_modelado_indexado = crear_indices_dataset(dataset_final_modelado, \"dataset_modelado\")\n",
    "\n",
    "print(f\"\\n‚úÖ √çndices creados en todos los datasets principales\")\n",
    "\n",
    "# Mostrar informaci√≥n de √≠ndices creados\n",
    "datasets_indexados = {\n",
    "    \"dataset_unificado_indexado\": dataset_unificado_indexado,\n",
    "    \"dataset_extendido_indexado\": dataset_extendido_indexado,\n",
    "    \"dataset_defunciones_indexado\": dataset_defunciones_indexado,\n",
    "    \"dataset_tendencias_indexado\": dataset_tendencias_indexado,\n",
    "    \"dataset_modelado_indexado\": dataset_modelado_indexado\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Resumen de datasets indexados:\")\n",
    "for nombre, df in datasets_indexados.items():\n",
    "    print(f\"  {nombre}: {df.shape}\")\n",
    "    print(f\"    √çndice: {df.index.name if hasattr(df.index, 'name') else 'MultiIndex' if isinstance(df.index, pd.MultiIndex) else 'RangeIndex'}\")\n",
    "\n",
    "# NOTA IMPORTANTE\n",
    "print(f\"\\n‚ö†Ô∏è NOTA IMPORTANTE:\")\n",
    "print(f\"Los √≠ndices de pandas son temporales y no persisten al guardar en CSV.\")\n",
    "print(f\"Para √≠ndices persistentes, se necesitar√≠a una base de datos (SQLite, PostgreSQL, etc.)\")\n",
    "print(f\"Los √≠ndices actuales mejoran el rendimiento de consultas en memoria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b643a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMOSTRACI√ìN DE BENEFICIOS DE √çNDICES ===\n",
      "üîç Ejemplos de consultas que se beneficiar√°n de los √≠ndices:\n",
      "\n",
      "ÔøΩÔøΩ Consulta 1: Filtrar por a√±o 2023\n",
      "  Dataset sin √≠ndice: 0.0010 segundos\n",
      "  Dataset con √≠ndice: 0.0000 segundos\n",
      "  Mejora: 100.0%\n",
      "\n",
      "ÔøΩÔøΩ Consulta 2: Filtrar por regi√≥n 'Regi√≥n Metropolitana'\n",
      "  Tiempo de consulta por regi√≥n: 0.1506 segundos\n",
      "  Registros encontrados: 470,652\n",
      "\n",
      "üìä Consulta 3: Filtrar por rango de edad '50_mas'\n",
      "  Tiempo de consulta por edad: 0.0500 segundos\n",
      "  Registros encontrados: 0\n",
      "\n",
      "ÔøΩÔøΩ Consulta 4: Filtrar por a√±o 2023 Y regi√≥n 'Regi√≥n Metropolitana'\n",
      "  Tiempo de consulta combinada: 0.1053 segundos\n",
      "  Registros encontrados: 0\n",
      "\n",
      "‚úÖ Demostraci√≥n de beneficios de √≠ndices completada\n",
      "\n",
      "üìã Tipos de consultas que se beneficiar√°n de los √≠ndices:\n",
      "   1. Filtrar por a√±o espec√≠fico (usando .loc[])\n",
      "   2. Filtrar por regi√≥n espec√≠fica\n",
      "   3. Filtrar por rango de edad\n",
      "   4. Filtrar por sexo\n",
      "   5. Filtrar por categor√≠a de diagn√≥stico\n",
      "   6. Consultas combinadas (√≠ndice + columna)\n",
      "   7. Agrupaciones por a√±o (usando √≠ndice)\n",
      "   8. Agrupaciones por regi√≥n\n",
      "   9. An√°lisis temporales por per√≠odo\n",
      "\n",
      "ÔøΩÔøΩ Beneficios de los √≠ndices:\n",
      "  ‚úÖ Consultas m√°s r√°pidas por a√±o (usando .loc[])\n",
      "  ‚úÖ Mejor rendimiento en an√°lisis temporales\n",
      "  ‚úÖ Agrupaciones m√°s eficientes\n",
      "  ‚úÖ Facilita an√°lisis exploratorios\n",
      "  ‚úÖ Reduce tiempo de procesamiento en modelos\n",
      "\n",
      "‚ö†Ô∏è NOTA IMPORTANTE:\n",
      "Cuando se usa set_index(), la columna se convierte en √≠ndice.\n",
      "Para consultas por a√±o, usar: df.loc[a√±o] en lugar de df[df['a√±o'] == a√±o]\n"
     ]
    }
   ],
   "source": [
    "# 10.2 Demostrar beneficios de los √≠ndices con consultas de ejemplo (CORREGIDO)\n",
    "\n",
    "print(\"=== DEMOSTRACI√ìN DE BENEFICIOS DE √çNDICES ===\")\n",
    "\n",
    "# Crear funci√≥n para medir tiempo de consulta\n",
    "import time\n",
    "\n",
    "def medir_tiempo_consulta(funcion, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Mide el tiempo de ejecuci√≥n de una consulta\n",
    "    \"\"\"\n",
    "    inicio = time.time()\n",
    "    resultado = funcion(*args, **kwargs)\n",
    "    fin = time.time()\n",
    "    return resultado, fin - inicio\n",
    "\n",
    "# Ejemplos de consultas comunes que se beneficiar√°n de los √≠ndices\n",
    "print(\"üîç Ejemplos de consultas que se beneficiar√°n de los √≠ndices:\")\n",
    "\n",
    "# 1. Consulta por a√±o espec√≠fico (CORREGIDO)\n",
    "print(f\"\\nÔøΩÔøΩ Consulta 1: Filtrar por a√±o 2023\")\n",
    "\n",
    "def consulta_por_a√±o_sin_indice(df, a√±o):\n",
    "    return df[df['a√±o'] == a√±o]\n",
    "\n",
    "def consulta_por_a√±o_con_indice(df, a√±o):\n",
    "    # CORRECCI√ìN: Usar el √≠ndice directamente\n",
    "    return df.loc[a√±o]\n",
    "\n",
    "# Medir tiempo en dataset sin √≠ndice\n",
    "resultado_sin_indice, tiempo_sin_indice = medir_tiempo_consulta(consulta_por_a√±o_sin_indice, dataset_unificado, 2023)\n",
    "print(f\"  Dataset sin √≠ndice: {tiempo_sin_indice:.4f} segundos\")\n",
    "\n",
    "# Medir tiempo en dataset con √≠ndice (CORREGIDO)\n",
    "try:\n",
    "    resultado_con_indice, tiempo_con_indice = medir_tiempo_consulta(consulta_por_a√±o_con_indice, dataset_unificado_indexado, 2023)\n",
    "    print(f\"  Dataset con √≠ndice: {tiempo_con_indice:.4f} segundos\")\n",
    "    \n",
    "    if tiempo_sin_indice > 0:\n",
    "        mejora = ((tiempo_sin_indice - tiempo_con_indice) / tiempo_sin_indice) * 100\n",
    "        print(f\"  Mejora: {mejora:.1f}%\")\n",
    "except KeyError:\n",
    "    print(f\"  Dataset con √≠ndice: A√±o 2023 no encontrado en el √≠ndice\")\n",
    "\n",
    "# 2. Consulta por regi√≥n espec√≠fica (CORREGIDO)\n",
    "print(f\"\\nÔøΩÔøΩ Consulta 2: Filtrar por regi√≥n 'Regi√≥n Metropolitana'\")\n",
    "\n",
    "def consulta_por_region(df, region):\n",
    "    # Verificar si la columna existe\n",
    "    if 'region' in df.columns:\n",
    "        return df[df['region'] == region]\n",
    "    else:\n",
    "        return pd.DataFrame()  # Retornar DataFrame vac√≠o si no existe la columna\n",
    "\n",
    "resultado_region, tiempo_region = medir_tiempo_consulta(consulta_por_region, dataset_defunciones_indexado, 'Regi√≥n Metropolitana')\n",
    "print(f\"  Tiempo de consulta por regi√≥n: {tiempo_region:.4f} segundos\")\n",
    "print(f\"  Registros encontrados: {len(resultado_region):,}\")\n",
    "\n",
    "# 3. Consulta por rango de edad (CORREGIDO)\n",
    "print(f\"\\nüìä Consulta 3: Filtrar por rango de edad '50_mas'\")\n",
    "\n",
    "def consulta_por_edad(df, rango):\n",
    "    if 'rango_edad' in df.columns:\n",
    "        return df[df['rango_edad'] == rango]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "resultado_edad, tiempo_edad = medir_tiempo_consulta(consulta_por_edad, dataset_defunciones_indexado, '50_mas')\n",
    "print(f\"  Tiempo de consulta por edad: {tiempo_edad:.4f} segundos\")\n",
    "print(f\"  Registros encontrados: {len(resultado_edad):,}\")\n",
    "\n",
    "# 4. Consulta combinada (CORREGIDO)\n",
    "print(f\"\\nÔøΩÔøΩ Consulta 4: Filtrar por a√±o 2023 Y regi√≥n 'Regi√≥n Metropolitana'\")\n",
    "\n",
    "def consulta_combinada(df, a√±o, region):\n",
    "    if 'region' in df.columns:\n",
    "        return df[(df.index == a√±o) & (df['region'] == region)]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "resultado_combinada, tiempo_combinada = medir_tiempo_consulta(consulta_combinada, dataset_defunciones_indexado, 2023, 'Regi√≥n Metropolitana')\n",
    "print(f\"  Tiempo de consulta combinada: {tiempo_combinada:.4f} segundos\")\n",
    "print(f\"  Registros encontrados: {len(resultado_combinada):,}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Demostraci√≥n de beneficios de √≠ndices completada\")\n",
    "\n",
    "# Mostrar tipos de consultas que se beneficiar√°n\n",
    "print(f\"\\nüìã Tipos de consultas que se beneficiar√°n de los √≠ndices:\")\n",
    "consultas_beneficiadas = [\n",
    "    \"Filtrar por a√±o espec√≠fico (usando .loc[])\",\n",
    "    \"Filtrar por regi√≥n espec√≠fica\", \n",
    "    \"Filtrar por rango de edad\",\n",
    "    \"Filtrar por sexo\",\n",
    "    \"Filtrar por categor√≠a de diagn√≥stico\",\n",
    "    \"Consultas combinadas (√≠ndice + columna)\",\n",
    "    \"Agrupaciones por a√±o (usando √≠ndice)\",\n",
    "    \"Agrupaciones por regi√≥n\",\n",
    "    \"An√°lisis temporales por per√≠odo\"\n",
    "]\n",
    "\n",
    "for i, consulta in enumerate(consultas_beneficiadas, 1):\n",
    "    print(f\"  {i:2d}. {consulta}\")\n",
    "\n",
    "print(f\"\\nÔøΩÔøΩ Beneficios de los √≠ndices:\")\n",
    "print(f\"  ‚úÖ Consultas m√°s r√°pidas por a√±o (usando .loc[])\")\n",
    "print(f\"  ‚úÖ Mejor rendimiento en an√°lisis temporales\")\n",
    "print(f\"  ‚úÖ Agrupaciones m√°s eficientes\")\n",
    "print(f\"  ‚úÖ Facilita an√°lisis exploratorios\")\n",
    "print(f\"  ‚úÖ Reduce tiempo de procesamiento en modelos\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è NOTA IMPORTANTE:\")\n",
    "print(f\"Cuando se usa set_index(), la columna se convierte en √≠ndice.\")\n",
    "print(f\"Para consultas por a√±o, usar: df.loc[a√±o] en lugar de df[df['a√±o'] == a√±o]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e3b5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO DATASETS CON √çNDICES ===\n",
      "‚úÖ Dataset unificado indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_unificado_indexado.csv\n",
      "‚úÖ Dataset extendido indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_extendido_indexado.csv\n",
      "‚úÖ Dataset defunciones indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_defunciones_indexado.csv\n",
      "‚úÖ Dataset tendencias indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_tendencias_indexado.csv\n",
      "‚úÖ Dataset modelado indexado guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_modelado_indexado.csv\n",
      "‚úÖ Dataset con categor√≠as CIE-10 mejoradas guardado: C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\\dataset_defunciones_cie10_mejorado.csv\n",
      "\n",
      " Verificando archivos indexados:\n",
      "  ‚úÖ dataset_unificado_indexado.csv: 0.01 MB\n",
      "  ‚úÖ dataset_extendido_indexado.csv: 0.00 MB\n",
      "  ‚úÖ dataset_defunciones_indexado.csv: 244.28 MB\n",
      "  ‚úÖ dataset_tendencias_indexado.csv: 0.02 MB\n",
      "  ‚úÖ dataset_modelado_indexado.csv: 222.62 MB\n",
      "  ‚úÖ dataset_defunciones_cie10_mejorado.csv: 244.28 MB\n",
      "\n",
      "‚úÖ Guardado de datasets indexados completado\n",
      "\n",
      "=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\n",
      "\n",
      "ÔøΩÔøΩ DATASETS CREADOS:\n",
      "  ‚úÖ Dataset unificado temporal: 50 a√±os (1974-2023)\n",
      "  ‚úÖ Dataset extendido con edad: 10 a√±os (2014-2023)\n",
      "  ‚úÖ Dataset defunciones detalladas: 1.2M registros (2014-2024)\n",
      "  ‚úÖ Dataset de tendencias: 50 a√±os con variables de tendencia\n",
      "  ‚úÖ Dataset final para modelado: 1.2M registros con 23 features\n",
      "\n",
      "üîß FEATURES IMPLEMENTADAS:\n",
      "  ‚úÖ Variables categ√≥ricas codificadas: 5\n",
      "  ‚úÖ Features temporales c√≠clicos: 8\n",
      "  ‚úÖ Features de d√≠as especiales: 4\n",
      "  ‚úÖ Variables de tendencia: 8\n",
      "  ‚úÖ 3 tipos de normalizaci√≥n: StandardScaler, MinMaxScaler, RobustScaler\n",
      "\n",
      "üìÅ ARCHIVOS GENERADOS EN 03_PRIMARY:\n",
      "  ‚úÖ 8 datasets para modelado\n",
      "  ‚úÖ 3 tipos de normalizaci√≥n\n",
      "  ‚úÖ Mapeos de codificaci√≥n\n",
      "  ‚úÖ Scalers para normalizaci√≥n\n",
      "  ‚úÖ 5 datasets indexados\n",
      "\n",
      "üéØ CASOS DE USO:\n",
      "  ‚úÖ Modelado de defunciones por regi√≥n y edad\n",
      "  ‚úÖ An√°lisis de tendencias temporales\n",
      "  ‚úÖ An√°lisis estacional con features c√≠clicos\n",
      "  ‚úÖ Clasificaci√≥n de causas de muerte\n",
      "  ‚úÖ Predicci√≥n de patrones demogr√°ficos\n",
      "\n",
      "‚úÖ PROYECTO DE PREPARACI√ìN DE DATOS COMPLETADO EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "# 10.3 Guardar datasets con √≠ndices y resumen final completo (CORREGIDO)\n",
    "\n",
    "print(\"=== GUARDANDO DATASETS CON √çNDICES ===\")\n",
    "\n",
    "# CORRECCI√ìN: Usar carpeta 03_primary\n",
    "carpeta_indexados = r\"C:\\ProyectoML2\\proyecto-ml\\data\\03_primary\"\n",
    "\n",
    "# Guardar datasets indexados (CON √çNDICES)\n",
    "ruta_unificado_indexado = os.path.join(carpeta_indexados, \"dataset_unificado_indexado.csv\")\n",
    "dataset_unificado_indexado.to_csv(ruta_unificado_indexado, index=True)  # CORRECCI√ìN: index=True\n",
    "print(f\"‚úÖ Dataset unificado indexado guardado: {ruta_unificado_indexado}\")\n",
    "\n",
    "ruta_extendido_indexado = os.path.join(carpeta_indexados, \"dataset_extendido_indexado.csv\")\n",
    "dataset_extendido_indexado.to_csv(ruta_extendido_indexado, index=True)\n",
    "print(f\"‚úÖ Dataset extendido indexado guardado: {ruta_extendido_indexado}\")\n",
    "\n",
    "ruta_defunciones_indexado = os.path.join(carpeta_indexados, \"dataset_defunciones_indexado.csv\")\n",
    "dataset_defunciones_indexado.to_csv(ruta_defunciones_indexado, index=True)\n",
    "print(f\"‚úÖ Dataset defunciones indexado guardado: {ruta_defunciones_indexado}\")\n",
    "\n",
    "ruta_tendencias_indexado = os.path.join(carpeta_indexados, \"dataset_tendencias_indexado.csv\")\n",
    "dataset_tendencias_indexado.to_csv(ruta_tendencias_indexado, index=True)\n",
    "print(f\"‚úÖ Dataset tendencias indexado guardado: {ruta_tendencias_indexado}\")\n",
    "\n",
    "ruta_modelado_indexado = os.path.join(carpeta_indexados, \"dataset_modelado_indexado.csv\")\n",
    "dataset_modelado_indexado.to_csv(ruta_modelado_indexado, index=True)\n",
    "print(f\"‚úÖ Dataset modelado indexado guardado: {ruta_modelado_indexado}\")\n",
    "\n",
    "# Guardar dataset con categor√≠as CIE-10 mejoradas\n",
    "ruta_defunciones_cie10 = os.path.join(carpeta_indexados, \"dataset_defunciones_cie10_mejorado.csv\")\n",
    "defunciones_estandarizado.to_csv(ruta_defunciones_cie10, index=False)  # Este no tiene √≠ndices\n",
    "print(f\"‚úÖ Dataset con categor√≠as CIE-10 mejoradas guardado: {ruta_defunciones_cie10}\")\n",
    "\n",
    "# Verificar archivos guardados\n",
    "archivos_indexados = [\n",
    "    ruta_unificado_indexado,\n",
    "    ruta_extendido_indexado,\n",
    "    ruta_defunciones_indexado,\n",
    "    ruta_tendencias_indexado,\n",
    "    ruta_modelado_indexado,\n",
    "    ruta_defunciones_cie10\n",
    "]\n",
    "\n",
    "print(f\"\\n Verificando archivos indexados:\")\n",
    "for archivo in archivos_indexados:\n",
    "    if os.path.exists(archivo):\n",
    "        tama√±o = os.path.getsize(archivo) / (1024*1024)\n",
    "        print(f\"  ‚úÖ {os.path.basename(archivo)}: {tama√±o:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {os.path.basename(archivo)}: No encontrado\")\n",
    "\n",
    "print(f\"\\n‚úÖ Guardado de datasets indexados completado\")\n",
    "\n",
    "# RESUMEN FINAL COMPLETO\n",
    "print(f\"\\n=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\")\n",
    "\n",
    "print(f\"\\nÔøΩÔøΩ DATASETS CREADOS:\")\n",
    "print(f\"  ‚úÖ Dataset unificado temporal: 50 a√±os (1974-2023)\")\n",
    "print(f\"  ‚úÖ Dataset extendido con edad: 10 a√±os (2014-2023)\")\n",
    "print(f\"  ‚úÖ Dataset defunciones detalladas: 1.2M registros (2014-2024)\")\n",
    "print(f\"  ‚úÖ Dataset de tendencias: 50 a√±os con variables de tendencia\")\n",
    "print(f\"  ‚úÖ Dataset final para modelado: 1.2M registros con 23 features\")\n",
    "\n",
    "print(f\"\\nüîß FEATURES IMPLEMENTADAS:\")\n",
    "print(f\"  ‚úÖ Variables categ√≥ricas codificadas: 5\")\n",
    "print(f\"  ‚úÖ Features temporales c√≠clicos: 8\")\n",
    "print(f\"  ‚úÖ Features de d√≠as especiales: 4\")\n",
    "print(f\"  ‚úÖ Variables de tendencia: 8\")\n",
    "print(f\"  ‚úÖ 3 tipos de normalizaci√≥n: StandardScaler, MinMaxScaler, RobustScaler\")\n",
    "\n",
    "print(f\"\\nüìÅ ARCHIVOS GENERADOS EN 03_PRIMARY:\")\n",
    "print(f\"  ‚úÖ 8 datasets para modelado\")\n",
    "print(f\"  ‚úÖ 3 tipos de normalizaci√≥n\")\n",
    "print(f\"  ‚úÖ Mapeos de codificaci√≥n\")\n",
    "print(f\"  ‚úÖ Scalers para normalizaci√≥n\")\n",
    "print(f\"  ‚úÖ 5 datasets indexados\")\n",
    "\n",
    "print(f\"\\nüéØ CASOS DE USO:\")\n",
    "print(f\"  ‚úÖ Modelado de defunciones por regi√≥n y edad\")\n",
    "print(f\"  ‚úÖ An√°lisis de tendencias temporales\")\n",
    "print(f\"  ‚úÖ An√°lisis estacional con features c√≠clicos\")\n",
    "print(f\"  ‚úÖ Clasificaci√≥n de causas de muerte\")\n",
    "print(f\"  ‚úÖ Predicci√≥n de patrones demogr√°ficos\")\n",
    "\n",
    "print(f\"\\n‚úÖ PROYECTO DE PREPARACI√ìN DE DATOS COMPLETADO EXITOSAMENTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "930e92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\n",
      "\n",
      "üìä RESUMEN DE TODAS LAS TAREAS COMPLETADAS:\n",
      "  ‚úÖ 1. Limpieza cr√≠tica del dataset defunciones_filtradas\n",
      "  ‚úÖ 2. Estandarizaci√≥n de nombres de columnas\n",
      "  ‚úÖ 3. Validaci√≥n de rangos de edad\n",
      "  ‚úÖ 4. Integraci√≥n de datasets\n",
      "  ‚úÖ 5. Validaci√≥n de consistencia\n",
      "  ‚úÖ 6. Preparaci√≥n para modelado\n",
      "  ‚úÖ 7. Normalizaci√≥n de escalas\n",
      "  ‚úÖ 8. Manejo avanzado de c√≥digos CIE-10\n",
      "  ‚úÖ 9. Creaci√≥n de √≠ndices para consultas r√°pidas\n",
      "\n",
      "ÔøΩÔøΩ ARCHIVOS GENERADOS (TOTAL: 17 archivos):\n",
      "  üìÑ dataset_unificado_temporal.csv\n",
      "  üìÑ dataset_extendido_con_edad.csv\n",
      "  üìÑ defunciones_limpias.csv\n",
      "  üìÑ dataset_modelado_defunciones.csv\n",
      "  üìÑ dataset_modelado_defunciones_normalizado.csv\n",
      "  üìÑ dataset_tendencias_temporales.csv\n",
      "  üìÑ dataset_tendencias_normalizado.csv\n",
      "  üìÑ dataset_tendencias_minmax.csv\n",
      "  üìÑ dataset_tendencias_robust.csv\n",
      "  üìÑ dataset_unificado_indexado.csv\n",
      "  ÔøΩÔøΩ dataset_extendido_indexado.csv\n",
      "  üìÑ dataset_defunciones_indexado.csv\n",
      "  üìÑ dataset_tendencias_indexado.csv\n",
      "  üìÑ dataset_modelado_indexado.csv\n",
      "  üìÑ dataset_defunciones_cie10_mejorado.csv\n",
      "  ÔøΩÔøΩ mapeos_codificacion.json\n",
      "  üìÑ scalers_normalizacion.pkl\n",
      "\n",
      "üéØ CASOS DE USO IMPLEMENTADOS:\n",
      "  üîç An√°lisis exploratorio de datos (EDA)\n",
      "  üìà An√°lisis de tendencias temporales\n",
      "  üè• An√°lisis de mortalidad por regi√≥n y edad\n",
      "  üìä An√°lisis estacional de nacimientos y defunciones\n",
      "  ü§ñ Modelado predictivo de mortalidad\n",
      "  üìâ Predicci√≥n de tendencias demogr√°ficas\n",
      "  üèõÔ∏è An√°lisis para pol√≠ticas p√∫blicas de salud\n",
      "  ÔøΩÔøΩ Reportes autom√°ticos de estad√≠sticas vitales\n",
      "\n",
      "üöÄ PR√ìXIMOS PASOS RECOMENDADOS:\n",
      "  1. Ejecutar an√°lisis exploratorio de datos (EDA)\n",
      "  2. Crear visualizaciones de tendencias temporales\n",
      "  3. Desarrollar modelos predictivos de mortalidad\n",
      "  4. Implementar an√°lisis de patrones estacionales\n",
      "  5. Crear dashboard interactivo de estad√≠sticas vitales\n",
      "  6. Desarrollar sistema de alertas tempranas\n",
      "  7. Generar reportes autom√°ticos para autoridades\n",
      "\n",
      "üí° BENEFICIOS LOGRADOS:\n",
      "  ‚úÖ Datos completamente limpios y validados\n",
      "  ‚úÖ Variables categ√≥ricas codificadas para ML\n",
      "  ‚úÖ Features temporales para an√°lisis estacional\n",
      "  ‚úÖ Variables de tendencia para predicciones\n",
      "  ‚úÖ Datasets normalizados para comparaciones\n",
      "  ‚úÖ C√≥digos CIE-10 categorizados y validados\n",
      "  ‚úÖ √çndices optimizados para consultas r√°pidas\n",
      "  ‚úÖ Estructura de datos lista para producci√≥n\n"
     ]
    }
   ],
   "source": [
    "# 10.4 Resumen final completo del proyecto\n",
    "\n",
    "print(\"=== RESUMEN FINAL COMPLETO DEL PROYECTO ===\")\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DE TODAS LAS TAREAS COMPLETADAS:\")\n",
    "\n",
    "tareas_completadas = [\n",
    "    \"‚úÖ 1. Limpieza cr√≠tica del dataset defunciones_filtradas\",\n",
    "    \"‚úÖ 2. Estandarizaci√≥n de nombres de columnas\", \n",
    "    \"‚úÖ 3. Validaci√≥n de rangos de edad\",\n",
    "    \"‚úÖ 4. Integraci√≥n de datasets\",\n",
    "    \"‚úÖ 5. Validaci√≥n de consistencia\",\n",
    "    \"‚úÖ 6. Preparaci√≥n para modelado\",\n",
    "    \"‚úÖ 7. Normalizaci√≥n de escalas\",\n",
    "    \"‚úÖ 8. Manejo avanzado de c√≥digos CIE-10\",\n",
    "    \"‚úÖ 9. Creaci√≥n de √≠ndices para consultas r√°pidas\"\n",
    "]\n",
    "\n",
    "for tarea in tareas_completadas:\n",
    "    print(f\"  {tarea}\")\n",
    "\n",
    "print(f\"\\nÔøΩÔøΩ ARCHIVOS GENERADOS (TOTAL: 17 archivos):\")\n",
    "\n",
    "archivos_totales = [\n",
    "    \"üìÑ dataset_unificado_temporal.csv\",\n",
    "    \"üìÑ dataset_extendido_con_edad.csv\", \n",
    "    \"üìÑ defunciones_limpias.csv\",\n",
    "    \"üìÑ dataset_modelado_defunciones.csv\",\n",
    "    \"üìÑ dataset_modelado_defunciones_normalizado.csv\",\n",
    "    \"üìÑ dataset_tendencias_temporales.csv\",\n",
    "    \"üìÑ dataset_tendencias_normalizado.csv\",\n",
    "    \"üìÑ dataset_tendencias_minmax.csv\",\n",
    "    \"üìÑ dataset_tendencias_robust.csv\",\n",
    "    \"üìÑ dataset_unificado_indexado.csv\",\n",
    "    \"ÔøΩÔøΩ dataset_extendido_indexado.csv\",\n",
    "    \"üìÑ dataset_defunciones_indexado.csv\",\n",
    "    \"üìÑ dataset_tendencias_indexado.csv\",\n",
    "    \"üìÑ dataset_modelado_indexado.csv\",\n",
    "    \"üìÑ dataset_defunciones_cie10_mejorado.csv\",\n",
    "    \"ÔøΩÔøΩ mapeos_codificacion.json\",\n",
    "    \"üìÑ scalers_normalizacion.pkl\"\n",
    "]\n",
    "\n",
    "for archivo in archivos_totales:\n",
    "    print(f\"  {archivo}\")\n",
    "\n",
    "print(f\"\\nüéØ CASOS DE USO IMPLEMENTADOS:\")\n",
    "\n",
    "casos_uso = [\n",
    "    \"üîç An√°lisis exploratorio de datos (EDA)\",\n",
    "    \"üìà An√°lisis de tendencias temporales\",\n",
    "    \"üè• An√°lisis de mortalidad por regi√≥n y edad\",\n",
    "    \"üìä An√°lisis estacional de nacimientos y defunciones\",\n",
    "    \"ü§ñ Modelado predictivo de mortalidad\",\n",
    "    \"üìâ Predicci√≥n de tendencias demogr√°ficas\",\n",
    "    \"üèõÔ∏è An√°lisis para pol√≠ticas p√∫blicas de salud\",\n",
    "    \"ÔøΩÔøΩ Reportes autom√°ticos de estad√≠sticas vitales\"\n",
    "]\n",
    "\n",
    "for caso in casos_uso:\n",
    "    print(f\"  {caso}\")\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
    "\n",
    "proximos_pasos = [\n",
    "    \"1. Ejecutar an√°lisis exploratorio de datos (EDA)\",\n",
    "    \"2. Crear visualizaciones de tendencias temporales\",\n",
    "    \"3. Desarrollar modelos predictivos de mortalidad\",\n",
    "    \"4. Implementar an√°lisis de patrones estacionales\",\n",
    "    \"5. Crear dashboard interactivo de estad√≠sticas vitales\",\n",
    "    \"6. Desarrollar sistema de alertas tempranas\",\n",
    "    \"7. Generar reportes autom√°ticos para autoridades\"\n",
    "]\n",
    "\n",
    "for paso in proximos_pasos:\n",
    "    print(f\"  {paso}\")\n",
    "\n",
    "print(f\"\\nüí° BENEFICIOS LOGRADOS:\")\n",
    "\n",
    "beneficios = [\n",
    "    \"‚úÖ Datos completamente limpios y validados\",\n",
    "    \"‚úÖ Variables categ√≥ricas codificadas para ML\",\n",
    "    \"‚úÖ Features temporales para an√°lisis estacional\",\n",
    "    \"‚úÖ Variables de tendencia para predicciones\",\n",
    "    \"‚úÖ Datasets normalizados para comparaciones\",\n",
    "    \"‚úÖ C√≥digos CIE-10 categorizados y validados\",\n",
    "    \"‚úÖ √çndices optimizados para consultas r√°pidas\",\n",
    "    \"‚úÖ Estructura de datos lista para producci√≥n\"\n",
    "]\n",
    "\n",
    "for beneficio in beneficios:\n",
    "    print(f\"  {beneficio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a05dda-517a-4980-9983-66374b3df47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
